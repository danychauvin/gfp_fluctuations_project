---
title: "Concentration and production of synthetic promoters in 96 well plates experiments"
author: "Dany Chauvin"
date: "4/1/2021"
output: html_document
---

# PREPARING MOTHER MACHINE DATA

Importing data.

```{r message=FALSE,warning=FALSE}
path_to_data_summary <- "/scicore/home/nimwegen/rocasu25/Documents/Projects/biozentrum/ouInference_bjoern/constitexprData.csv"
#Calling functions and packages
source("/scicore/home/nimwegen/rocasu25/Documents/Projects/biozentrum/ouInference_bjoern/loadFunctionsAndPackages.R")
#Import data
source("/scicore/home/nimwegen/rocasu25/Documents/Projects/biozentrum/ouInference_bjoern/deepMomaToDf.R")

myframes_to_mycells <- myframes_to_mycells %>% 
   mutate(strain='MG1655')
   
myframes_to_mycells <- myframes_to_mycells %>%
  # append relevant conversion parameters
  mutate(autofluo_predict=NA, fp_per_dn=NA,
         # case of GFPmut2 (from zaslaver library)
         autofluo_predict = ifelse(strain!='asc662', 133.6, autofluo_predict),
         fp_per_dn = ifelse(strain!='asc662', 0.198, fp_per_dn),
         # case of asc662
         autofluo_predict = ifelse(strain=='asc662', 422.8, autofluo_predict),
         fp_per_dn = ifelse(strain=='asc662', 0.0361 * 4, fp_per_dn)) %>% 
  # convert to gfp units (after subtracting autofluorescence)
  mutate(fluogfp_amplitude = fluo_amplitude - autofluo_predict * length_um,
         gfp_nb = fluogfp_amplitude * fp_per_dn ) %>% 
  group_by(cell) %>% 
  arrange(time_sec) %>% 
  mutate(g_birth=first(gfp_nb)) %>% 
  mutate(g_div=last(gfp_nb)) %>% 
  ungroup() %>% 
  mutate(concentration_volume=gfp_nb/volume_um)

cell_fluo_info <- myframes_to_mycells %>% 
  distinct(cell,g_birth,g_div)

mycells <- mycells %>% 
  left_join(cell_fluo_info,by=c("cell")) %>% 
  mutate(v_birth=compute_vol(l_birth,w_birth),
         v_div=compute_vol(l_div,w_div),
    c_birth=g_birth/l_birth,
         c_div=g_div/l_div,
    c_birth_v=g_birth/volume_birth,
         c_div_v=g_div/volume_div,
         dg=g_div - g_birth,
         dcdt=(g_div/l_div - g_birth/l_birth) / div_time,
         dcdt=(g_div/volume_div - g_birth/volume_birth) / div_time,
         g=log(g_div/g_birth) / div_time, # would be cleaner from a fit but difficult to compare
         gamma=dg/dl,
         gamma_v=dg/dv,
         q=dg/dl*alpha,
         q_v=dg/dv*alpha)

# Change factor values

mycells$condition <- factor(mycells$condition,levels=c("acetate","glycerol","glucose","glucoseaa"))
myframes_to_mycells$condition <- factor(myframes_to_mycells$condition,levels=c("acetate","glycerol","glucose","glucoseaa"))

# Add promoters to mycells
cell_to_promoter <- myframes_to_mycells %>% 
  distinct(cell,promoter,vector)

#Computing strain (vector + promoter)
myframes_to_mycells <- myframes_to_mycells %>%
  mutate(strain=paste(vector,promoter,sep="-"))

mycells <- mycells %>% 
  select(-c(vector)) %>% 
  left_join(cell_to_promoter,by=c("cell")) %>%
  mutate(strain=paste(vector,promoter,sep="-"))
```

# CHECKING DIFFERENCE BETWEEN ALPHA BASED ON VOLUME AND ALPHA BASED ON LENGTH

```{r}
mycells %>%
  ggplot()+
  stat_ecdf(aes(alpha*3600/log(2),col=condition))+
  #facet_wrap(~condition)+
  theme_cowplot()+
  coord_cartesian(xlim=c(0,5))+
  labs(subtitle="Volume based, fit")+
  xlab("Growth-rate (h-1)")+
  ylab("Fraction")
```
Comparison with growth rates inferred from division time?

```{r}
mycells %>%
  ggplot()+
  stat_ecdf(aes(1/(div_time/3600),col=condition))+
  #facet_wrap(~condition)+
  theme_cowplot()+
  coord_cartesian(xlim=c(0,5))+
  labs(subtitle="Based on division time")+
  xlab("Growth-rate (h-1)")+
  ylab("Fraction")
```

# COMPUTING PSEUDO-BULK AND PSEUDO BULK ERROR BARS

With generation times, the growth rate appears sensibly smaller! Let's compute pseudo-bulk growth rates.
I use the following function for dichotomic search.

NB, two possible options: using distribution of generation times or single cell doubling time.

```{r}
dichotomic_search_growth_rate <- function(.var,.option){
  if(.option=="div_time"){
  .doubling_time <- .var # As a doubling times I am using first, the div times.
  .gr <- log(2)/mean(.var,na.rm=TRUE)
    }else if(.option=="alpha"){
  .doubling_time <- log(2)/.var # As a doubling times I am using first, the div times.
  .gr <- mean(.var,na.rm=TRUE)
    }
  p <- length(.var) #number of observations
   # As a first approximation for the population exponential growth rate, I am using mean(log(2)/.div_time), but I could also use .gr <- mean(alpha). 
  .approx_inf <- 1/2*mean(.gr,na.rm=TRUE) #low initial value
  .approx_sup <- 3*mean(.gr,na.rm=TRUE) #high initial value
  .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2 #Corresponding the function value
  .delta_sup <- sum(exp(-.approx_sup*.doubling_time))-p/2 #Corresponding the function value
  while(.delta_inf<0){
  .approx_inf <- 1/2*.approx_inf
  .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2} #This value should be POSITIVE to start with
  while(.delta_sup>0){
  .approx_sup <- 2*.approx_sup
  .delta_sup <- sum(exp(-.approx_sup*.doubling_time))-p/2} #This value should be NEGATIVE to start with
  # Simple dichotomic search for root
  .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf #New growth rate value
  .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2 #New function value
  while((.approx_sup-.approx_inf)>0.00000001){ #Search should stop when difference between .approx_sup and .approx_inf becomes too small
    #print(.approx_sup)
    #print(.approx_inf)
    if(.delta_new<0){ # If function is negative, the intermediate value becomes the upper value, a new intermediate value is computed.
      .approx_sup <- .approx_new
      .delta_sup <- .delta_new
      .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
      .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2}
    else{ # Otherwise, the intermediate value becomes the inf value. New intermediate is computed.
      .approx_inf <- .approx_new
      .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2
      .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
      .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2}}
  #print(c(.approx_inf,.delta_inf,.approx_sup,.delta_sup))
  return(rep(c(.approx_sup+.approx_inf)/2,times=p))
}
```

```{r}
mycells %>% 
  group_by(condition) %>% 
  mutate(gr_elongation=mean(alpha*3600/log(2)),
         gr_generation=1/mean(div_time/3600,na.rm = TRUE),
         pred_gr_div=dichotomic_search_growth_rate(div_time,"div_time")*3600/log(2),
         pred_gr_alpha=dichotomic_search_growth_rate(alpha,"alpha")*3600/log(2)) %>% 
  ungroup() %>% 
  distinct(condition,gr_elongation,gr_generation,pred_gr_div,pred_gr_alpha) %>% 
  arrange(gr_elongation)
```

These values seem to be satisfying. Let's add that to mycells.
How to compute error bars? I propose to take div_time - deltat and div_time + delta, then look at the error bars that I am getting.

```{r}
time_interval_df <- myframes_to_mycells %>% 
  mutate(t_interval=t_interval*60) %>% 
  distinct(condition,t_interval)

#Old version
#mycells <- mycells %>% 
#  left_join(time_interval_df,by=c("condition")) %>% 
#  mutate(upper_div_time=div_time+t_interval) %>% 
#  mutate(lower_div_time=div_time-t_interval) %>% 
#  group_by(condition,strain) %>% 
#  mutate(gr_elongation=mean(alpha*3600/log(2)),
#         gr_generation=1/mean(div_time/3600,na.rm = TRUE),
#         pred_gr=dichotomic_search_growth_rate(div_time)*3600/log(2),
#         upper_pred_gr=dichotomic_search_growth_rate(upper_div_time)*3600/log(2),
#         lower_pred_gr=dichotomic_search_growth_rate(lower_div_time)*3600/log(2)) %>% 
#  mutate(sd_pred_gr=1/2*(lower_pred_gr-upper_pred_gr)) %>%
#  ungroup()

mycells <- mycells %>% 
  group_by(condition,strain) %>% 
  mutate(gr_elongation=mean(alpha*3600/log(2)),
         gr_generation=1/mean(div_time/3600,na.rm = TRUE),
         pred_gr=dichotomic_search_growth_rate(alpha,"alpha")*3600/log(2)) %>% 
  mutate(sd_pred_gr=mean(sd_alpha,na.rm=TRUE)) %>%
  ungroup()

```

I could also compute the standard error on the div time... My intuition is that this is going to be small compared to the error bar I defined above...

# COMPUTING PSEUDO CONCENTRATION 

I am assuming here that, the concentration in constant during a single cell cycle.
Therefore I first compute the mean concentration during one cell cycle. And then I compute the mean concentration overall cells.
Each cell gets an error bar which is the sd computed over all frames.

```{r}
myconcentrations <- myframes_to_mycells %>% 
  group_by(cell) %>% 
  mutate(mean_concentration=mean(gfp_nb/volume_um),
         sd_concentration=sd(gfp_nb/volume_um)) %>% 
  ungroup() %>% 
  distinct(cell,mean_concentration,sd_concentration)

mycells <- mycells %>% 
  left_join(myconcentrations,by=c("cell"))

mycells <- mycells %>% 
  group_by(condition,promoter,vector) %>% 
  mutate(mean_concentration_condition=mean(mean_concentration)) %>% 
  mutate(sd_concentration_condition=sd(mean_concentration)/n()) %>% 
  ungroup()
```

Let's look at the results now, for each promoter, for chromosomal strains, and plasmid strains

```{r}
library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
nb.cols <- 4
mycolors <- colorRampPalette(brewer.pal(4, "Set1"))(nb.cols)

mycells %>% 
  ggplot(aes(log(mean_concentration),col=condition))+
  stat_ecdf()+
  facet_wrap(~interaction(vector,promoter))+
  scale_color_manual(values = mycolors)+
  xlab("Mean GFP concentration (#GFP/um3)")+
  ylab("CDF")+
  labs(subtitle="Mother Machine Data")+
  coord_cartesian(xlim=c(2.5,14))

mycells %>% 
  distinct(condition,promoter,vector,.keep_all=TRUE) %>% 
  ggplot()+
  geom_point(aes(log(pred_gr),log(mean_concentration_condition),col=condition))+
  geom_linerange(aes(x=log(pred_gr),ymin=log(mean_concentration_condition-sd_concentration_condition),ymax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_errorbarh(aes(y=log(mean_concentration_condition),xmin=log(pred_gr-sd_pred_gr),xmax=log(pred_gr+sd_pred_gr)))+
  facet_wrap(~interaction(vector,promoter),scale="free")+
  scale_color_manual(values = mycolors)+
  xlab("log(Pseudo bulk growth rate)")+
  ylab("log(mean GFP concentration)")+
  labs(subtitle="Mother Machine Data")
  #coord_cartesian(xlim=c(2.5,14))

mycells %>% 
  distinct(condition,promoter,vector,.keep_all=TRUE) %>% 
  ggplot()+
  geom_point(aes(pred_gr,log(mean_concentration_condition),col=condition))+
  geom_linerange(aes(x=pred_gr,ymin=log(mean_concentration_condition-sd_concentration_condition),ymax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_errorbarh(aes(y=log(mean_concentration_condition),xmin=pred_gr-sd_pred_gr,xmax=pred_gr+sd_pred_gr))+
  facet_wrap(~interaction(vector,promoter),scale="free")+
  scale_color_manual(values = mycolors)+
  xlab("Pseudo bulk growth rate")+
  ylab("log(mean GFP concentration)")+
  labs(subtitle="Mother Machine Data")
  #coord_cartesian(xlim=c(2.5,14))
```

# CALIBRATION

Finally here we are: the goal of this part is to focus on the calibration of the data.
We'll focus on single conditions. And from there, we'll establish the relationship between mother machine data and the bulk data.
First, we need to load the 96 well plates data.

# IMPORTING BULK DATA

We assume manual curation has already been done.

# LOADING PACKAGES AND FUNCTIONS

```{r message=FALSE, warning=FALSE}
source("./code/load_packages_functions.R")
source("./code/modeling_functions.R")
source("./code/inference_functions.R")
```

# IMPORTING DATA FROM BULK EXPERIMENTS

```{r message=FALSE, warning=FALSE}
path_to_data_list <- "./dataList.csv"
source("./code/import_data.R")

mydata <- mydata %>% 
  mutate(valid=NA) %>% 
  mutate(well=paste(plate,row,column,strain,sep="_"))

mean_blank_od <- 0.03840125 #Determined in a previous experiment where we looked ad OD of empty wells for entire plates
mydata <- mydata %>% 
  mutate(corrected_od=od-mean_blank_od)

mean_blank_fluo <- 35.3075 #Idem
mydata <- mydata %>% 
  mutate(corrected_fluo=fluo-mean_blank_fluo) %>% 
  filter(!grepl("H_7",well)) #Discarding this well which was problematic anyway

mydata_bad <- readr::read_csv("./manualCuration.csv") #Wells with obviously wrong results (cells not growing, or outliers)
mydata <- mydata %>% 
  mutate(rowcol=paste(row,column,sep=""))

replica_df <- tibble(description=c("20210312constitexpr3.0","20210316constitexpr3.1","20210204Testrun2",
                                   "20210430constitexpr3.2",
                                   "20210504constitexpr3.3",
                                   "20210507constitexpr3.4",
                                   "20210512constitexpr3.5"),
                     replica=c(2,3,1,4,5,6,7))
promoters_of_interest <- list("hi1","hi3","med2","med3","rpsB","rpmB","rplN","rrnB")

mydata_curated <-mydata %>% 
  anti_join(mydata_bad,by=c("description","plate","rowcol")) %>% 
  left_join(replica_df,by=c("description")) %>% 
  mutate(well_rep=paste(well,replica,sep="-"))

mydata_curated <- rbind(
  mydata_curated %>% 
    filter((strain %in% c("MG1655","empty"))) %>% 
    mutate(promoter="nopromoter") %>% 
    mutate(vector="novector"),
  
  mydata_curated %>% 
    filter(!(strain %in% c("MG1655","empty"))) %>% 
    group_by(strain) %>% 
    mutate(prom_part1=stringr::str_split(strain,"-")[[1]][[1]],
         prom_part2=stringr::str_split(strain,"-")[[1]][[2]]) %>% 
  mutate(promoter=ifelse(prom_part2 %in% promoters_of_interest,prom_part2,paste(prom_part1,prom_part2,sep=""))) %>% 
  mutate(vector=ifelse(prom_part2 %in% promoters_of_interest,prom_part1,"pl")) %>%
  select(-c(prom_part1,prom_part2,strain)) %>% 
  mutate(strain=paste(vector,promoter,sep="-")) %>% 
    ungroup())
```

# INFERRING SLOPES AND INTERCEPT OF FLUO VS OD

We have defined arbitrarily corrected OD ranges where we fit a linear model (two parameters, slope: $\alpha_{tot}$ and intercept" $\beta$). $\alpha_{tot}$ takes into account the contribution of both GFP and autofluorescence.

```{r}
od_range_df <- tibble(condition=c("acetate","glycerol","glucose","glucoseaa"),
                      min_corrected_od=c(0.05,0.05,0.05,0.05),
                      max_corrected_od=c(0.15,0.2,0.4,0.6))
```

Different wells are characterized by different promoter strength, high ("hi") and medium ("med").

```{r}
hi_or_med_p2 <- tibble(plate=rep(c("pl1","pl3","pl5","pl7"),each=6),strength=rep(rep(c("med","hi"),each=3),times=4),column=rep(c(7,8,9,10,11,12),times=4))
hi_or_med_p3 <- tibble(plate=rep(c("pl2","pl4","pl6","pl8"),each=12),strength=rep(rep(c("med","hi"),each=3),times=8),column=rep(c(1,2,3,4,5,6,7,8,9,10,11,12),times=4))
hi_or_med <- rbind(hi_or_med_p2,hi_or_med_p3)
```

Inferring slopes and intercepts. Output: data_frame with condition,strain (id est, promoter and vector), replica, well, alpha_tot, sd_alpha, beta, strength. One line per well.

Now we can properly infer the slopes of the fluo vs od relationships. We assume some noise both on:
- od measurement
- fluo measurement

```{r}
mydata_summary_od <- mydata_curated %>% 
    ungroup() %>%
    left_join(hi_or_med,by=c("plate","column")) %>% 
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>%
    group_by(description,well) %>%
    mutate(p=n(),
           mean_od=mean(corrected_od),
           var_od=1/p*sum((corrected_od-mean_od)**2),
           mean_fluo=mean(fluo),
           var_fluo=1/p*sum((fluo-mean_fluo)**2),
           covar_od_fluo=1/p*sum(corrected_od*fluo-mean_od*mean_fluo),
           alpha_tot=(var_fluo-var_od)/(2*covar_od_fluo)+sqrt(1+((var_fluo-var_od)/(2*covar_od_fluo))**2),#assuming that this is the best slope
           sd_alpha=compute_error(alpha_tot,var_od,var_fluo,covar_od_fluo),
           beta=1/p*sum(fluo-alpha_tot*corrected_od))%>%
    ungroup() %>% 
    distinct(strain, replica, well,.keep_all=TRUE) %>% 
  select(condition,strain,replica,well,alpha_tot,sd_alpha,beta,strength,plate)
```

# COMPUTING GROWTH-RATES IN SINGLE WELLS

Here I fit log(corrected_od) vs time_min.
I am considering here that there is measurement noise only according in the y axis. Which enables me to use the functions to compute the slope of the "classical" linear regression as well as error bars on the growth rate, similarly to what I am using for single cells in mother machine data.

```{r}
mydata_growthrates_summary <- mydata_curated %>% 
    ungroup() %>%
    left_join(hi_or_med,by=c("plate","column")) %>% 
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>%
    filter(corrected_od>0) %>% 
    group_by(description,well) %>%
    mutate(
      well_gr=fit_exp_elongation_slope(time_min,corrected_od)*60/log(2), 
      sd_well_gr=fit_exp_elongation_sd_slope(time_min,corrected_od)*60/log(2)) %>%
  ungroup() %>% 
  distinct(strain, replica, well,.keep_all=TRUE) %>% 
  select(condition,strain,replica,well,well_gr,sd_well_gr,strength,plate)
```

```{r}
mydata_growthrates_summary %>% 
  distinct(condition,replica,well,.keep_all = TRUE) %>% 
  filter(!((condition=="acetate") & (replica %in% c(5,6,7)))) %>% 
  filter(!((condition=="glucoseaa") & (replica %in% c(4)))) %>% 
  group_by(condition) %>% 
  mutate(p=n()) %>% 
  mutate(mean_doubling=mean(well_gr,na.rm=TRUE)) %>% 
  mutate(sd_doubling=sd(well_gr,na.rm=TRUE)) %>% 
  mutate(mean_error_fit=mean(sd_well_gr,na.rm=TRUE)) %>% 
  ungroup() %>% 
  distinct(condition,.keep_all = TRUE) %>% 
  select(condition,mean_doubling,sd_doubling,mean_error_fit) %>% 
  arrange(mean_doubling,condition)
```

Again, error bars on single slopes are small compared to fluctuations from well to well.

Now, several things are possible: I can directly compare the fluo vs OD slopes, without taking out the auto-fluorescence dependency (which is after all, not taken into account, deferentially, in my mother machine measurement...). What do I get, if I forget about this step, and if I forget about different growth rates?

# DIRECTLY COMPARING FLUO VS OD TO CONCENTRATION

I am comparing results by conditions. And using these calibration curves, to infer "fluorescence concentration" (taking into account both autofluorescence and gfp fluorescence).

```{r}
myconcentrations_condition <- mycells %>% 
  distinct(condition,strain,mean_concentration_condition,sd_concentration_condition)

#Set strains to select for the comparison, for which I have data both in mother machine and spectro.
selected_strains_df <- mycells %>% 
  distinct(strain,condition)

library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(15, "Set1"))(nb.cols)

mydata_summary_od %>%
  left_join(mydata_growthrates_summary,by=c("condition","strain","replica","well","strength","plate")) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_tot),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_tot-sd_alpha),ymax=log(alpha_tot+sd_alpha)))+
  geom_errorbar(aes(y=log(alpha_tot),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)

nb.cols <- 4
mycolors <- colorRampPalette(brewer.pal(4, "Set1"))(nb.cols)

mydata_summary_od %>%
  left_join(mydata_growthrates_summary,by=c("condition","strain","replica","well","strength","plate")) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_tot),col=condition),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_tot-sd_alpha),ymax=log(alpha_tot+sd_alpha)),alpha=.5)+
  geom_errorbar(aes(y=log(alpha_tot),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)),alpha=.5)+
geom_smooth(aes(log(mean_concentration_condition),log(alpha_tot)),method="lm") +
  stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_tot)))+
  scale_color_manual(values = mycolors)
```

Now these scatters are not really nice. First, we can get rid of the autofluorescence coming from the 96 well plates experiments.

# SUBSTRACTING AUTOFLUORESCENCE AND PROPAGATING THE ERROR

```{r}
mydata_summary_od$replica <- factor(mydata_summary_od$replica,levels = c(1,2,3,4,5,6,7))
mydata_growthrates_summary$replica <- factor(mydata_growthrates_summary$replica,levels = c(1,2,3,4,5,6,7))

mydata_curated_cond_for_plot <- mydata_summary_od %>% 
  distinct(replica,condition,well,alpha_tot,sd_alpha,strain,plate)

mydata_curated_gr_for_plot <- mydata_growthrates_summary %>% 
  distinct(replica,condition,well,well_gr,sd_well_gr,strain,plate)

conditions <- c("acetate","glycerol","glucose","glucoseaa")

for(c in conditions){print(
mydata_gr_autofluo <- left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain","plate")) %>% 
  filter(strain=="MG1655") %>% 
  filter(alpha_tot>0) %>% 
  filter(well_gr>0.2) %>% 
  filter(!((condition=="acetate") & (alpha_tot<1000))) %>% 
  filter(condition==c) %>% 
  ggplot()+
  geom_point(aes(well_gr,alpha_tot,col=replica))+
  geom_errorbar(aes(x=well_gr,ymax=alpha_tot+sd_alpha,ymin=alpha_tot-sd_alpha,col=replica))+
  geom_errorbar(aes(y=alpha_tot,xmin=(well_gr-sd_well_gr),xmax=(well_gr+sd_well_gr),col=replica))+
  labs(subtitle=c)+
  theme_cowplot()
)}

left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain")) %>% 
  filter(strain=="MG1655") %>% 
  filter(alpha_tot>0) %>% 
  filter(well_gr>0.2) %>% 
  filter(!((condition=="acetate") & (alpha_tot<1000))) %>% 
  #filter(condition==c) %>% 
  ggplot()+
  geom_point(aes(well_gr,alpha_tot,col=replica))+
  geom_errorbar(aes(x=well_gr,ymax=alpha_tot+sd_alpha,ymin=alpha_tot-sd_alpha,col=replica))+
  geom_errorbar(aes(y=alpha_tot,xmin=(well_gr-sd_well_gr),xmax=(well_gr+sd_well_gr),col=replica))+
  labs(subtitle="all")+
  theme_cowplot()+
  xlab("Doublings per hour")+
  ylab("autofluorescence alpha")

left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain")) %>% 
  filter(strain=="MG1655") %>% 
  filter(alpha_tot>0) %>% 
  filter(well_gr>0.2) %>% 
  filter(!((condition=="acetate") & (alpha_tot<1000))) %>% 
  #filter(condition==c) %>% 
  ggplot()+
  geom_point(aes(log(well_gr),log(alpha_tot),col=replica))+
  geom_errorbar(aes(x=log(well_gr),ymax=log(alpha_tot+sd_alpha),ymin=log(alpha_tot-sd_alpha),col=replica))+
  geom_errorbar(aes(y=log(alpha_tot),xmin=log((well_gr-sd_well_gr)),xmax=log((well_gr+sd_well_gr)),col=replica))+
  labs(subtitle="all")+
  theme_cowplot()+
  xlab("log(Doublings per hour)")+
  ylab("log(autofluorescence alpha)")
```

# OD: COMPUTING RELEVANT QUANTITIES TO COMPUTE THE AUTOFLUORESCENCE IN DIFFERENT WELLS

Using Erik's notes, section 4., I should compute:
- mean of log(autofluorescence) and log(exponential growth rates)
- standard deviation of log(autofluorescence) and log(exponential growth rate)
- covariance of log(autofluorescence) and log(exponential growth rate)

```{r}
# Given what is seen above, I set a filter to get rid of unwanted data

exp_vs_gr_results_df <- left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain","plate")) %>% filter(strain=="MG1655") %>% 
  filter(alpha_tot>0) %>% 
  filter(well_gr>0.2) %>% 
  filter(!((condition=="acetate") & (alpha_tot<1000))) %>% 
  mutate(l_gr=log(well_gr)) %>% #here growth rate is in doublings per hour, which is more intuitive
  mutate(l_exp=log(alpha_tot)) %>% 
  drop_na() %>% 
  mutate(p=n(),
         m_l_gr=mean(l_gr,na.rm=TRUE),
         m_l_exp=mean(l_exp,na.rm=TRUE),
         var_l_gr=var(l_gr,na.rm=TRUE),
         var_l_exp=var(l_exp,na.rm=TRUE),
         cov_l_gr_l_exp=1/p*sum(l_exp*l_gr-m_l_gr*m_l_exp,na.rm=TRUE)) %>% 
  filter(row_number()==1) %>% 
  select(m_l_gr,m_l_exp,var_l_gr,var_l_exp,cov_l_gr_l_exp,p)

exp_vs_gr_results_df
```
# OD: SUBSTRACTING AUTOFLUORESCENCE AND COMPUTING GFP CONTRIBUTION, FOLLOWING ERIK'S NOTES

```{r}
mydata_gr_exp_summary <- left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain","plate")) %>%
  filter(!(strain %in% c("MG1655","empty"))) %>% 
  mutate(l_x=log(well_gr),
         var_l_x=((sd_well_gr)**2)/((well_gr)**2)) %>%
  mutate(m_l_gr=unique(exp_vs_gr_results_df$m_l_gr),
         var_l_gr=unique(exp_vs_gr_results_df$var_l_gr),
         m_l_exp=unique(exp_vs_gr_results_df$m_l_exp),
         var_l_exp=unique(exp_vs_gr_results_df$var_l_exp),
         cov_l_gr_l_exp=unique(exp_vs_gr_results_df$cov_l_gr_l_exp),
         p=unique(exp_vs_gr_results_df$p)) %>% 
  mutate(l_y=m_l_exp+cov_l_gr_l_exp/(var_l_gr)*(l_x-m_l_gr),
         r=cov_l_gr_l_exp/(sqrt(var_l_gr*var_l_exp)),
         var_l_y=var_l_x*(cov_l_gr_l_exp**2/(var_l_gr**2))+var_l_exp*(1-r**2)*(1+(var_l_x+(l_x-m_l_gr)**2)/p))
```

```{r}
mydata_gr_exp_summary<- mydata_gr_exp_summary %>%
  mutate(alpha_gfp=alpha_tot-exp(l_y),
         sd_alpha_autofluo=sqrt(l_y**2*var_l_y),
         sd_alpha_gfp=sqrt(sd_alpha_autofluo**2+sd_alpha**2)) %>% 
  filter(alpha_gfp>3*sd_alpha_autofluo)
```

# NOW COMPARING GFP FLUO IN BLUK VERSUS MOTHER MACHINE

The fit is performed, considering error both on x and y. We assume that we can discard error bars, which are small anyway.
We want to check that the slope is indeed close to 1 (it seems to be the case).

Naive fit.

```{r}
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(15, "Set1"))(nb.cols)

mydata_gr_exp_summary %>%
  #filter(replica==1) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=replica),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()
```
Fit taking into account errors both in y and x.

```{r}
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(15, "Set1"))(nb.cols)

mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition) %>% 
  mutate(calibration_slope=compute_slope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_intercept=compute_intercept_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_sd_slope=compute_sdslope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>%
  mutate(calibration_factor=exp(calibration_intercept)) %>% 
  ungroup() %>% 
  distinct(condition,calibration_slope,calibration_sd_slope,calibration_intercept,calibration_factor)

myslopes <- mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition) %>% 
  mutate(calibration_slope=compute_slope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_intercept=compute_intercept_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_sd_slope=compute_sdslope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>%
  mutate(calibration_factor=exp(calibration_intercept)) %>% 
  ungroup() %>% 
  distinct(condition,calibration_slope,calibration_sd_slope,calibration_intercept,calibration_factor)

# Representing the correct slopes

mydata_gr_exp_summary %>%
  left_join(myslopes,by=c("condition")) %>% 
  #filter(replica==1) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_line(aes(x=log(mean_concentration_condition),y=log(mean_concentration_condition)*calibration_slope+calibration_intercept))+
  #geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  #stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()+
  xlab("Mean concentration (Mother machine) #GFP/um3")+
  ylab("Bulk results (GFU/OD)")

```

# FITTING THESE SLOPES TO 1 AND FINDING THE CORRESPONDING CALIBRATION CONSTANT

For a slope of 1, the best intercept is:
b=<log(concentration_mm)>-<log(bulk)>

```{r}
mycalibrations <- mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition) %>% 
  mutate(intercept=mean(log(mean_concentration_condition))-mean(log(alpha_gfp))) %>% 
  ungroup() %>% 
  distinct(condition,intercept)
```

```{r}
mydata_gr_exp_summary %>%
  left_join(mycalibrations,by=c("condition")) %>% 
  #filter(replica==1) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(alpha_gfp),log(mean_concentration_condition),col=strain),size=3)+
  geom_errorbar(aes(y=log(mean_concentration_condition),xmin=log(alpha_gfp-sd_alpha_gfp),xmax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(x=log(alpha_gfp),ymin=log(mean_concentration_condition-sd_concentration_condition),ymax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_abline(aes(slope=1,intercept=intercept))+
  #geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  #stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()+
  ylab("Mean concentration (Mother machine) #GFP/um3")+
  xlab("Bulk results (GFU/OD)")
```
Now, based on this, it should be possible to determine from single bulk measurements: what is the concentration in bulk data. And what is the corresponding error bar.

```{r}
mycalibrations$condition <- factor(mycalibrations$condition, levels=c("acetate","glycerol","glucose","glucoseaa"))
mycalibrations %>% 
  arrange(condition) %>% 
  mutate(calibration_constant=exp(intercept))
```

# PREDICTING CONCENTRATION IN BULK DATA

```{r}
mydata_results <- mydata_gr_exp_summary %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(mycalibrations,by=c("condition")) %>% 
  mutate(l_pred_concentration=log(alpha_gfp)+intercept,
         max_l_pred_concentration=log(alpha_gfp+sd_alpha)+intercept,
         min_l_pred_concentration=log(alpha_gfp-sd_alpha)+intercept)
```
# NOW LET'S PLOT THEM ALL

```{r}
mydata_results %>% 
  ggplot()+
  geom_point(aes(well_gr,l_pred_concentration,col=condition))+
  theme_cowplot()+
  xlab("Well growth-rate")+
  ylab("Predicted log-concentration")
```
```{r}
hi_or_med_p2 <- tibble(plate=rep(c("pl1","pl3","pl5","pl7"),each=6),strength=rep(rep(c("med","hi"),each=3),times=4),column=rep(c(7,8,9,10,11,12),times=4))
hi_or_med_p3 <- tibble(plate=rep(c("pl2","pl4","pl6","pl8"),each=12),strength=rep(rep(c("med","hi"),each=3),times=8),column=rep(c(1,2,3,4,5,6,7,8,9,10,11,12),times=4))
hi_or_med <- rbind(hi_or_med_p2,hi_or_med_p3)



mydata_results %>% 
  separate(well,c("well_1","well_2"),sep="-") %>% 
  tidyr::extract(well_1,"column","^pl[1-8]{1}_[A-H]{1}_([0-9]{1,})_[0-9a-z]{1,}$",remove=FALSE,convert=TRUE) %>% 
  left_join(hi_or_med,by=c("plate","column")) %>% 
  filter(!is.na(strength)) %>% 
  ggplot()+
  geom_point(aes(well_gr,l_pred_concentration,col=strength))+
  theme_cowplot()+
  xlab("Well growth-rate")+
  ylab("Predicted log-concentration")

mydata_results %>% 
  separate(well,c("well_1","well_2"),sep="-") %>% 
  tidyr::extract(well_1,"column","^pl[1-8]{1}_[A-H]{1}_([0-9]{1,})_[0-9a-z]{1,}$",remove=FALSE,convert=TRUE) %>% 
  left_join(hi_or_med,by=c("plate","column")) %>% 
  filter(!is.na(strength)) %>% 
  ggplot()+
  geom_point(aes(well_gr,log(exp(l_pred_concentration)*well_gr*log(2)),col=strength))+
  theme_cowplot()+
  xlab("Well growth-rate")+
  ylab("Predicted log-production")
```
Now let's plot them all in a large PDF


```{r}
mydata_results %>% 
  ggplot()+
  geom_point(aes(well_gr,l_pred_concentration,col=condition))+
  geom_errorbar(aes(x=well_gr,ymin=min_l_pred_concentration,ymax=max_l_pred_concentration))+
  geom_errorbar(aes(y=l_pred_concentration,xmin=well_gr-sd_well_gr,xmax=well_gr+sd_well_gr))+
  facet_wrap(~strain,scale="free")+
  theme_cowplot()+
  ggsave("./all_promoters.pdf",width=30,height=20)
```
# LOOKING AT THE PRODUCTION

The question we would like to ask now:
What is happening there? Are these synthetic promoters seeing the same things or not?
First maybe... how does that relate to the production?
Production which is supposed to be at equilibrium: concentration * lambda?
Which also means that errors should multiply.

```{r}
mydata_results %>% 
  mutate(sd_l_concentration=1/2*((max_l_pred_concentration-l_pred_concentration)+(l_pred_concentration-min_l_pred_concentration))) %>% 
  mutate(sd_concentration=sd_l_concentration*l_pred_concentration) %>% 
  mutate(sd_production=sd_concentration*well_gr*log(2)+sd_well_gr*log(2)*exp(l_pred_concentration)) %>% 
  ggplot()+
  geom_point(aes(well_gr,log(exp(l_pred_concentration)*well_gr*log(2)),col=condition))+
  geom_errorbar(aes(x=well_gr,ymin=log(exp(l_pred_concentration)*well_gr*log(2)-sd_production),ymax=log(exp(l_pred_concentration)*well_gr*log(2)+sd_production)))+
  geom_errorbar(aes(y=log(exp(l_pred_concentration)*well_gr*log(2)),xmin=well_gr-sd_well_gr,xmax=well_gr+sd_well_gr))+
  facet_wrap(~strain,scale="free")+
  theme_cowplot()+
  ggsave("./all_promoters_production.pdf",width=30,height=20)
```

First, let's look only at the hi ones.

# Hi promoters

```{r}
mydata_results_hi1 <- mydata_results %>% 
  separate(well,c("well_1","well_2"),sep="-") %>% 
  tidyr::extract(well_1,"column","^pl[1-8]{1}_[A-H]{1}_([0-9]{1,})_[0-9a-z]{1,}$",remove=FALSE,convert=TRUE) %>% 
  left_join(hi_or_med,by=c("plate","column")) %>% 
  filter(strength=="hi") %>% 
  mutate(sd_l_concentration=1/2*((max_l_pred_concentration-l_pred_concentration)+(l_pred_concentration-min_l_pred_concentration))) %>% 
  mutate(sd_concentration=sd_l_concentration*l_pred_concentration) %>% 
  mutate(sd_production=sd_concentration*well_gr*log(2)+sd_well_gr*log(2)*exp(l_pred_concentration)) %>% 
  mutate(production=exp(l_pred_concentration)*well_gr*log(2))
```


```{r}
mydata_results_hi1 %>% 
  filter(log(production)>8) %>% 
  group_by(strain) %>% 
  mutate(max_production=max(production)) %>% 
  ungroup() %>% 
  mutate(production_norm=production/max_production) %>% 
  ggplot()+
  geom_line(aes(log(well_gr),log(production_norm),group=strain))

mydata_results_hi1 %>% 
  filter(log(production)>8) %>% 
  group_by(strain) %>% 
  mutate(production_factor=mean(production)) %>% 
  ungroup() %>% 
  mutate(production_norm=production/production_factor) %>% 
  ggplot()+
  geom_point(aes(log(well_gr),log(production_norm),col=condition))+
  theme_cowplot()+
  coord_cartesian(xlim=c(-2,1.5),ylim=c(-3,1))
```
# Med promoters

```{r}
mydata_results_med1 <- mydata_results %>% 
  separate(well,c("well_1","well_2"),sep="-") %>% 
  tidyr::extract(well_1,"column","^pl[1-8]{1}_[A-H]{1}_([0-9]{1,})_[0-9a-z]{1,}$",remove=FALSE,convert=TRUE) %>% 
  left_join(hi_or_med,by=c("plate","column")) %>% 
  filter(strength=="med") %>% 
  mutate(sd_l_concentration=1/2*((max_l_pred_concentration-l_pred_concentration)+(l_pred_concentration-min_l_pred_concentration))) %>% 
  mutate(sd_concentration=sd_l_concentration*l_pred_concentration) %>% 
  mutate(sd_production=sd_concentration*well_gr*log(2)+sd_well_gr*log(2)*exp(l_pred_concentration)) %>% 
  mutate(production=exp(l_pred_concentration)*well_gr*log(2))
```


```{r}
mydata_results_med1 %>% 
  filter(log(production)>4) %>% 
  group_by(strain) %>% 
  mutate(max_production=max(production)) %>% 
  ungroup() %>% 
  mutate(production_norm=production/max_production) %>% 
  ggplot()+
  geom_line(aes(log(well_gr),log(production),group=strain))

mydata_results_med1 %>% 
  filter(log(production)>4) %>% 
  group_by(strain) %>% 
  mutate(production_factor=mean(production)) %>% 
  ungroup() %>% 
  mutate(production_norm=production/production_factor) %>% 
  ggplot()+
  geom_point(aes(log(well_gr),log(production_norm),col=condition))+
  theme_cowplot()+
  coord_cartesian(xlim=c(-2,1.5),ylim=c(-3,1))


```

# Looking at med and hi promoters

```{r}
med_to_plot <- mydata_results_med1 %>% 
  filter(log(production)>4) %>% 
  group_by(strain) %>% 
  mutate(production_factor=mean(production)) %>% 
  ungroup() %>% 
  mutate(production_norm=production/production_factor) %>% 
  mutate(sd_production_norm=sd_production/production_factor)

hi_to_plot <- mydata_results_hi1 %>% 
  filter(log(production)>8) %>% 
  group_by(strain) %>% 
  mutate(production_factor=mean(production)) %>% 
  ungroup() %>% 
  mutate(production_norm=production/production_factor) %>% 
  mutate(sd_production_norm=sd_production/production_factor)

med_to_plot %>% 
  ggplot()+
  geom_point(aes(log(well_gr),log(production_norm)),col="blue",alpha=0.2)+
  geom_point(data=hi_to_plot,aes(log(well_gr),log(production_norm)),col="red",alpha=0.2)+
  theme_cowplot()

all_normalized <- rbind(
  hi_to_plot,
  med_to_plot) %>% 
  group_by(condition) %>% 
  mutate(m_production_norm=mean(production_norm)) %>% 
  mutate(m_well_gr=mean(well_gr)) %>% 
  ungroup() %>% 
  distinct(condition,m_production_norm,m_well_gr)

med_to_plot %>% 
  ggplot()+
  geom_point(aes(log(well_gr),log(production_norm)),col="blue",alpha=0.2)+
  geom_point(data=hi_to_plot,aes(log(well_gr),log(production_norm)),col="red",alpha=0.2)+
  geom_point(data=all_normalized,aes(log(m_well_gr),log(m_production_norm)),shape="+",col="black",size=10)+
  theme_cowplot()

med_to_plot %>% 
  ggplot()+
  geom_point(aes(well_gr,production_norm),col="blue",alpha=0.2)+
  geom_point(data=hi_to_plot,aes(well_gr,production_norm),col="red",alpha=0.2)+
  geom_point(data=all_normalized,aes(m_well_gr,m_production_norm),shape="+",col="black",size=10)+
  theme_cowplot()+
  coord_cartesian(ylim=c(0,2.5))
```
Adding a model.
Let's try to fit the model I came up with before.
The least square method does not work. I will try a maximum likelihood estimation.

```{r}
# Here is my function
prod <- function(pars,g){
  #extract parameters
  .p0 <- pars[1]
  .a <- pars[2]
  .g0 <-pars[3]
  .n <- pars[4]
  #prediction
  p <- .p0*g^(1.4)/(2600+7*.a*(1/(1+(.g0/g)**.n)))
  return(p)
}
```

```{r}
plot(x_data,y_data)
curve(prod(c(.p0=4500,.a = 4000 , .g0 = 3, .n = 3), x), 0, 2.5,add=TRUE)
```

Ok now we can proceed with the log-likelihood maximization. We are going to assume some gaussian noise...

```{r}
data <- data.frame(g=x_data,p=y_data)

NLL = function(pars, data) {
  # Values predicted by the model
  prod_pred = prod(pars, data$g)
  # Negative log-likelihood 
  -sum(dnorm(x = data$p, mean = prod_pred, sd = pars[5], log = TRUE))
}

par0 <- c(.p=4500,.a=4000,.g0=3,.n=3,.sd=0.3)
fit = optim(par = par0, fn = NLL, data = data, control = list(parscale = abs(par0)), 
            hessian = TRUE)

final_pars <- fit$par
```

Let's plot the results

```{r}
# Using ggplot
prod_optim <- function(.x){
  return(prod(final_pars,.x))
}

pred_prod <- sapply(x_data,prod_optim)
result_df <- tibble(well_gr=x_data,production_norm=y_data,production_norm_pred=pred_prod)

result_df %>% 
  ggplot()+
  geom_point(aes(well_gr,production_norm),alpha=0.1)+
  geom_line(aes(well_gr,production_norm_pred),col="red")+
  coord_cartesian(xlim=c(0,2.5),ylim=c(-0.1,3))+
  theme_cowplot()+
  xlab("Growth rate h-1")+
  ylab("Normalized production")
```

```{r}
all_data_residual <- all_data %>% 
  mutate(production_norm_pred=prod(final_pars,well_gr),
         residual_production=production_norm-production_norm_pred)

all_data_residual %>% 
  ggplot()+
  geom_point(aes(well_gr,residual_production),alpha=0.1)+
  #geom_line(aes(well_gr,residual_production),col="red")+
  #coord_cartesian(xlim=c(0,2.5),ylim=c(-0.1,3))+
  theme_cowplot()+
  xlab("Growth rate h-1")+
  ylab("Residual production")

```
So the higher you grow... the noisier it gets.

```{r}
all_data_residual %>% 
  ggplot()+
  geom_point(aes(well_gr,residual_production,col=condition))+
  #geom_errorbar(aes(x=well_gr,ymin=log(exp(l_pred_concentration)*well_gr*log(2)-sd_production),ymax=log(exp(l_pred_concentration)*well_gr*log(2)+sd_production)))+
  #geom_errorbar(aes(y=log(exp(l_pred_concentration)*well_gr*log(2)),xmin=well_gr-sd_well_gr,xmax=well_gr+sd_well_gr))+
  facet_wrap(~strain,scale="free")+
  theme_cowplot()+
  ggsave("./all_promoters_residual_production.pdf",width=30,height=20)
```




Ok, so it seems that, we have no real surprises there: they all behave, or almost all behave by displaying saturation...
So we have a nice picture of production for hundreds or so of "naked promoters".
What could be a good function to model the shape of these response to increasing growth rate.
Is there a correlation between these parameters, and the response?

Usually, constitutive promoters are modelled, empirically, using Mickaelis Menten Kinetics.
Such as:

v=vmax*s/(s+K)

Can we model these? Some seem to clearly show such trends.
Use broom and model to do so.

Other things?
Is there a way to superimpose these curves? Some invariance?

Simple statement that, where production is the most variable is at the beginning of the curve. No so much varying afterwards in most cases.
Production stalls, hence concentration goes down. Why is it?
Are there other signs of this pressure on the availability of the RNA polymerase?
Some might say that it is because the concentration of free RNA pol saturates...
Are there other sign of that?
Or simply... what are the chance to get a ribosomal like regulation?
Apparently quite small...

Even though these guys are supposedly empty... we still see some variations.
Why?












All promoters, even ribosome ones actually, are following this trend. Only rrnB keeps increasing.
What kind of things could I do?
First I need to derive appropriate error bars. We need to multiply error bars. Or rather:
delta(x*y) = delta(y)*x + delta(x)*y

















It's clearly within error bars.
Can we see that too?
Why is calibration factor sooooo low for glycerol?
I do not know. But that's kind of weird.

Now, I should make this plot again, and I should compute the mean for each data point in alpha_gfp, depending on the error bars.
Except that here, we want to take into account differences in terms of growth rate.
Maximization of the function that Erik wrote.

Plotting these data with the correct, slope.

```{r}
# Computing parameters
sigma_concentration <- mycells %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  mutate(sigma_cp=sd_concentration_condition/mean_concentration_condition) %>% 
  mutate(x_well=log(mean_concentration_condition)) %>% 
  mutate(mm_bulk_gr=pred_gr) %>% 
  mutate(sd_mm_bulk_gr=sd_pred_gr) %>% 
  distinct(condition,strain,sigma_cp,x_well,mm_bulk_gr,sd_mm_bulk_gr)

sigma_alphagfp <- mydata_gr_exp_summary  %>%
  filter(log(well_gr)>-2) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  mutate(sigma_alpha=sd_alpha_gfp/alpha_gfp) %>%
  mutate(y_well=log(alpha_gfp)) %>% 
  distinct(condition,strain,replica,well,sigma_alpha,y_well,well_gr,sd_well_gr)
  
cal_input_df <- left_join(sigma_concentration,sigma_alphagfp,by=c("condition","strain")) %>% 
  mutate(sigma_well=sqrt(sigma_alpha**2+sigma_cp**2)) %>% 
  mutate(delta_well=y_well-x_well) %>% 
  mutate(delta_gr=well_gr-mm_bulk_gr) %>% 
  mutate(sigma_gr=sqrt(sd_well_gr**2+sd_mm_bulk_gr**2))
```

```{r}
compute_calibration_gamma <- function(.sigma_well,.sigma_gr,.delta_well,.delta_gr){
  
  m_ll_calibration <- function(.gamma){
  .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(.delta_well-.gamma*.delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
  }
  
  gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
  return(rep(c(gamma),times=length(.sigma_well)))
}

compute_calibration_a <- function(.gamma,.sigma_well,.sigma_gr,.delta_well,.delta_gr){
  .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
  return(rep(c(.a),times=length(.sigma_well)))
}
```

```{r}
cal_output_df <- cal_input_df %>% 
  group_by(condition) %>% 
  mutate(gamma=compute_calibration_gamma(sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
  mutate(a_star=compute_calibration_a(gamma,sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
  ungroup() %>% 
  mutate(l_concentration_pred=y_well-a_star-gamma*(well_gr-mm_bulk_gr)) %>% 
  mutate(pred_concentration_w=exp(l_concentration_pred),
         mean_concentration_m=exp(x_well)) %>% 
  rename(l_concentration_m=x_well)

cal_output_df %>% 
  distinct(condition,gamma,a_star) %>% 
  arrange(gamma)
```

Representing results.
Computing best estimate for concentration, from mother machine and bulk data.

```{r}
# Now plot how the different promoters are behaving
library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
nb.cols <- 4
mycolors <- colorRampPalette(brewer.pal(4, "Set1"))(nb.cols)

mycells %>% 
  ggplot(aes(log(mean_concentration),col=condition))+
  stat_ecdf()+
  facet_wrap(~interaction(vector,promoter))+
  scale_color_manual(values = mycolors)+
  xlab("Mean GFP concentration (#GFP/um3)")+
  ylab("CDF")+
  labs(subtitle="Mother Machine Data")+
  coord_cartesian(xlim=c(2.5,14))

mycells$condition <- factor(mycells$condition,levels = c("acetate","glycerol","glucose","glucoseaa")) 

p1 <- mycells %>% 
  distinct(condition,promoter,vector,.keep_all=TRUE) %>% 
  ggplot()+
  geom_point(aes(log(pred_gr),log(mean_concentration_condition),col=condition),size=4,shape=1,alpha=0.5)+
  geom_linerange(aes(x=log(pred_gr),ymin=log(mean_concentration_condition-sd_concentration_condition),ymax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_errorbarh(aes(y=log(mean_concentration_condition),xmin=log(pred_gr-sd_pred_gr),xmax=log(pred_gr+sd_pred_gr)))+
  facet_wrap(~strain)+#,scale="free_y")+
  scale_color_manual(values = mycolors)+
  xlab("log(Pseudo bulk growth rate)")+
  ylab("log(mean GFP concentration)")+
  labs(subtitle="Mother Machine Data")
  #coord_cartesian(xlim=c(2.5,14))

cal_output_df$condition <- factor(cal_output_df$condition,levels = c("acetate","glycerol","glucose","glucoseaa")) 

cal_output_df %>% 
  ggplot()+
  geom_point(aes(log(well_gr),l_concentration_pred,col=condition))+
  facet_wrap(~strain)+#,scale="free_y")+
  scale_color_manual(values = mycolors)
  #xlab("log(Bulk growth rate)")+
  #ylab("Predicted log(GFP concentration)")+
  #labs(subtitle="Mother Machine Data")

p1 <- p1+ geom_point(data=cal_output_df,aes(log(well_gr),l_concentration_pred,col=condition))+
  geom_linerange(data=cal_output_df,aes(x=log(well_gr),ymin=l_concentration_pred-sigma_alpha,ymax=l_concentration_pred+sigma_alpha))+
  geom_errorbarh(data=cal_output_df,aes(y=l_concentration_pred,xmin=log(well_gr-sd_well_gr),xmax=log(well_gr+sd_well_gr)))
  #facet_wrap(~strain)+#,scale="free_y")+
  #scale_color_manual(values = mycolors)
  #xlab("log(Bulk growth rate)")+
  #ylab("Predicted log(GFP concentration)")+
  #labs(subtitle="Mother Machine Data")
```

# What is problematic?

The main thing probably is that, plotting delta_p versus delta_gr gives things wich are not that good.
In particular the variance in delta_p is big compared to the error in delta_p measurement.
Which could be due to strong correlation. But it does not seem to be the case.
Indeed there seems to be a strong correlation, in some cases. But not everywhere. So that in general, the overall variance in delta_p seems to be due to the some of variations of the different promoters...

Which suggests that using a single gamma for all, is not going to work.
So, what do we do? The discussion would be therefore, to geta gamma that depends on each one of these promoters?

Not so sure either. For some, correlation is clear, for some others it is much more chaotic.

So in a nutshell, I would simply propose to use the calibration we set, do the inference considering both x and y error, and to move forward with this.

If one does that, here is what we get.

```{r}
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(15, "Set1"))(nb.cols)

mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition) %>% 
  mutate(calibration_slope=compute_slope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_intercept=compute_intercept_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_sd_slope=compute_sdslope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>%
  mutate(calibration_factor=exp(calibration_intercept)) %>% 
  ungroup() %>% 
  distinct(condition,calibration_slope,calibration_sd_slope,calibration_intercept,calibration_factor)

myslopes <- mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition) %>% 
  mutate(calibration_slope=compute_slope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_intercept=compute_intercept_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_sd_slope=compute_sdslope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>%
  mutate(calibration_factor=exp(calibration_intercept)) %>% 
  ungroup() %>% 
  distinct(condition,calibration_slope,calibration_sd_slope,calibration_intercept,calibration_factor)

# Representing the correct slopes

mydata_gr_exp_summary %>%
  left_join(myslopes,by=c("condition")) %>% 
  #filter(replica==1) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_line(aes(x=log(mean_concentration_condition),y=log(mean_concentration_condition)*calibration_slope+calibration_intercept))+
  #geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  #stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()+
  xlab("Mean concentration (Mother machine) #GFP/um3")+
  ylab("Bulk results (GFU/OD)")

```

Now, let's go back a bit, and compute the average for each promoter, together with proper error bars.
Each error bar has to be replace by a correct value. We'll use sd_l_c=sd_c/c.

Then from these error bars, we can compute a weighted mean.
So that <x>=sum(xi/di)/(sum(1/di)).
And then weighted standard deviation.

The different measurements are characterized by a certain error. Computing the average correctly can be done by:

#

```{r}
mydata_gr_exp_summary_w <- mydata_gr_exp_summary %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition,strain) %>%
  mutate(p=n()) %>% 
  mutate(w_alpha_gfp=sum(alpha_gfp/sd_alpha_gfp)/sum(1/sd_alpha_gfp)) %>% 
  mutate(var_w_alpha_gfp=sum((alpha_gfp-w_alpha_gfp)**2/sd_alpha_gfp)/sum(1/sd_alpha_gfp)*p/(p-1)) %>% 
  mutate(sd_w_alpha_gfp=sqrt(var_w_alpha_gfp)) %>% 
  mutate(se_w_alpha_gfp=sqrt(var_w_alpha_gfp)) %>% 
  ungroup() %>% 
  distinct(condition,strain,.keep_all=TRUE)

myslopes <- mydata_gr_exp_summary_w %>%
  group_by(condition) %>% 
  mutate(calibration_slope=compute_slope_errxy(log(mean_concentration_condition),log(w_alpha_gfp))) %>% 
  mutate(calibration_intercept=compute_intercept_errxy(log(mean_concentration_condition),log(w_alpha_gfp))) %>% 
  mutate(calibration_sd_slope=compute_sdslope_errxy(log(mean_concentration_condition),log(w_alpha_gfp))) %>%
  mutate(calibration_factor=exp(calibration_intercept)) %>% 
  ungroup() %>% 
  distinct(condition,calibration_slope,calibration_sd_slope,calibration_intercept,calibration_factor)
  
mydata_gr_exp_summary_w %>% 
  left_join(myslopes,by=c("condition")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(w_alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(w_alpha_gfp-sd_w_alpha_gfp),ymax=log(w_alpha_gfp+sd_w_alpha_gfp)))+
  geom_errorbar(aes(y=log(w_alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_line(aes(x=log(mean_concentration_condition),y=log(mean_concentration_condition)*calibration_slope+calibration_intercept))+
  #geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  #stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()+
  xlab("Mean concentration (Mother machine) #GFP/um3")+
  ylab("Bulk results (GFU/OD)")

mydata_gr_exp_summary_w %>% 
  left_join(myslopes,by=c("condition")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(w_alpha_gfp),col=condition),size=3)+
  geom_point(data=calibration_results %>% 
               semi_join(selected_strains_df,by=c("strain","condition")), aes(.l_x,.l_y))+
  #geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(w_alpha_gfp-sd_w_alpha_gfp),ymax=log(w_alpha_gfp+sd_w_alpha_gfp)))+
  #geom_errorbar(aes(y=log(w_alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  #geom_line(aes(x=log(mean_concentration_condition),y=log(mean_concentration_condition)*calibration_slope+calibration_intercept))+
  #geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  #stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  #facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()+
  xlab("Mean concentration (Mother machine) #GFP/um3")+
  ylab("Bulk results (GFU/OD)")
```

Now, from myslopes, one has the condition and the slopes. And from mydata_gr_exp_summary_w, I have all the data.

```{r}
# Given what is seen above, I set a filter to get rid of unwanted data
calibration_curve <- mydata_gr_exp_summary_w %>% 
  group_by(condition) %>% 
  mutate(l_y=log(mean_concentration_condition)) %>%
  mutate(l_x=log(w_alpha_gfp)) %>% 
  mutate(p=n(),
         m_l_x=mean(l_x,na.rm=TRUE),
         m_l_y=mean(l_y,na.rm=TRUE),
         var_l_x=var(l_x,na.rm=TRUE),
         var_l_y=var(l_y,na.rm=TRUE),
         cov_l_x_l_y=1/p*sum(l_y*l_x-m_l_x*m_l_y,na.rm=TRUE)) %>% 
  filter(row_number()==1) %>% 
  ungroup() %>% 
  select(condition,m_l_x,m_l_y,var_l_x,var_l_y,cov_l_x_l_y,p)

calibration_curve
```
# Converting now for all strains, the desired result in terms of concentration.

```{r}
input_calibration_df <- mydata_gr_exp_summary %>% 
  select(condition,strain,replica,well,plate,alpha_gfp,sd_alpha_gfp,well_gr,sd_well_gr)
  

calibration_results <- input_calibration_df %>% 
  #anti_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  filter(!(strain %in% c("MG1655","empty"))) %>% 
  left_join(calibration_curve,by=c("condition")) %>% 
  group_by(condition,strain) %>%
  mutate(m=n()) %>% 
  mutate(w_alpha_gfp=sum(alpha_gfp/sd_alpha_gfp)/sum(1/sd_alpha_gfp)) %>% 
  mutate(var_w_alpha_gfp=sum((alpha_gfp-w_alpha_gfp)**2/sd_alpha_gfp)/sum(1/sd_alpha_gfp)*m/(m-1)) %>% 
  mutate(sd_w_alpha_gfp=sqrt(var_w_alpha_gfp)) %>% 
  mutate(se_w_alpha_gfp=sqrt(var_w_alpha_gfp)) %>% 
  ungroup() %>% 
  distinct(condition,strain,.keep_all=TRUE) %>% 
  mutate(.l_x=log(w_alpha_gfp),
         .var_l_x=((sd_w_alpha_gfp)**2)/((w_alpha_gfp)**2)) %>%
  mutate(.l_y=m_l_y+cov_l_x_l_y/(var_l_x)*(.l_x-m_l_x),
         r=cov_l_x_l_y/(sqrt(var_l_x*var_l_y)),
         .var_l_y=.var_l_x*(cov_l_x_l_y**2/(var_l_x**2))+var_l_y*(1-r**2)*(1+(.var_l_x+(.l_x-m_l_x)**2)/p))

calibration_results %>% 
  left_join(myslopes,by=c("condition")) %>% 
  ggplot()+
  geom_point(aes(.l_x,.l_y,col=condition))+
  geom_line(aes(.l_x,.l_x*calibration_slope+calibration_intercept))+
  facet_wrap(~condition)
```











# Why is it non sensical?

## Checking the derivation

Between (83) and (84): factor 1/2 that has nothing to do here. Integrating over a0, I do not know if this should be there or not. But it does not change the fact that it is pretty big.

## Checking other variables?

Parameters for the maximization?

```{r}
cal_input_df %>% 
  filter(strain=="pl-hi1",condition=="glucose") %>% 
  filter(row_number()==2) %>% 
  select(condition,strain,x_well,y_well,delta_well)

cal_input_df %>% 
  filter(strain=="pl-hi1",condition=="glucose") %>% 
  filter(row_number()==2) %>% 
  select(condition,strain,mm_bulk_gr,well_gr,delta_gr)

cal_input_df %>% 
  filter(strain=="pl-hi1",condition=="glucose") %>% 
  filter(row_number()==2) %>% 
  select(condition,strain,sigma_cp,sigma_alpha,sigma_well)

cal_input_df %>% 
  filter(strain=="pl-hi1",condition=="glucose") %>% 
  filter(row_number()==2) %>% 
  select(condition,strain,sd_mm_bulk_gr,sd_well_gr,sigma_gr)
```

## Errors in the computation?

Performing the optimization: how does the log likelihood function looks like?
What package can I use?
I first choose to compute the log likelihood function for a bunch of values. Let's write a function to compute that.

Ok, things are not pretty... Now I am wondering: do I see a systematic trend with the growth rate: meaning, do I see that the alpha, is indeed going down or up with the growth rate?

```{r}
mydata_gr_exp_summary %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  ggplot()+
  geom_point(aes(log(well_gr),log(alpha_gfp)),alpha=0.5) +
  geom_errorbar(aes(x=log(well_gr),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_gfp+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(well_gr-sd_well_gr),xmax=log(well_gr+sd_well_gr)))+
  facet_wrap(~interaction(strain,condition))+
  ggsave("./test.pdf",width=12,height=10)
```

Maybe we could look at the fluorescence instead?
We could start by...scaling it to 1, and then use to compute the growth rate?

```{r}
df <- cal_input_df %>% filter(condition=="acetate")

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return((.term1+.term2+.term3))
}

g <- seq(-100,100,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
#plot(g,ll)
plot(g,minus_ll)

best_gamma <- nloptr::cobyla(x0=1,m_ll_calibration)$par
best_gamma

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}

g <- seq(-20,20,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)

```
```{r}
df <- cal_input_df %>% filter(condition=="glycerol")

ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return((.term1+.term2+.term3))
}

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

g <- seq(-100,100,by=1)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
plot(g,ll)
plot(g,minus_ll)

best_gamma <- nloptr::cobyla(x0=1,m_ll_calibration)$par
best_gamma

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}


g <- seq(-20,20,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)
```





```{r}
df <- cal_input_df %>% filter(condition=="glycerol")

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return((.term1+.term2+.term3))
}

g <- seq(-20,20,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
plot(g,minus_ll)

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}


g <- seq(-20,20,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)


best_gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
best_gamma
```

```{r}
df <- cal_input_df %>% filter(condition=="glucose")

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return((.term1+.term2+.term3))
}

g <- seq(-10,10,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
plot(g,ll)
plot(g,minus_ll)

best_gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
best_gamma

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}


g <- seq(-20,20,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)


```

```{r}
df <- cal_input_df %>% filter(condition=="glucoseaa")

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return((.term1+.term2+.term3))
}

g <- seq(-5,5,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
plot(g,ll)
plot(g,minus_ll)

best_gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
best_gamma

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}


g <- seq(-5,5,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)

```
# a_star as a function of gamma?

```{r}
df <- cal_input_df %>% filter(condition=="acetate")

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}


g <- seq(-10,10,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)

```

# Now let's try again...

```{r}
compute_calibration_gamma <- function(.sigma_well,.sigma_gr,.delta_well,.delta_gr){
  
  m_ll_calibration <- function(.gamma){
  .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(.delta_well-.gamma*.delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
  }
  
  gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
  return(rep(c(gamma),times=length(.sigma_well)))
}

compute_calibration_a <- function(.gamma,.sigma_well,.sigma_gr,.delta_well,.delta_gr){
  .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
  return(rep(c(.a),times=length(.sigma_well)))
}
```

```{r}
cal_output_df <- cal_input_df %>% 
  group_by(condition) %>% 
  mutate(gamma=compute_calibration_gamma(sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
  mutate(a_star=compute_calibration_a(gamma,sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
  ungroup() %>% 
  mutate(l_concentration_pred=y_well-a_star-gamma*(well_gr-mm_bulk_gr)) %>% 
  mutate(pred_concentration_w=exp(l_concentration_pred),
         mean_concentration_m=exp(x_well)) %>% 
  rename(l_concentration_m=x_well)

cal_output_df %>% 
  distinct(condition,gamma,a_star) %>% 
  arrange(condition) %>% 
  arrange(gamma)
```

```{r}
# Now plot how the different promoters are behaving
library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
nb.cols <- 4
mycolors <- colorRampPalette(brewer.pal(4, "Set1"))(nb.cols)

mycells %>% 
  ggplot(aes(log(mean_concentration),col=condition))+
  stat_ecdf()+
  facet_wrap(~interaction(vector,promoter))+
  scale_color_manual(values = mycolors)+
  xlab("Mean GFP concentration (#GFP/um3)")+
  ylab("CDF")+
  labs(subtitle="Mother Machine Data")+
  coord_cartesian(xlim=c(2.5,14))

mycells$condition <- factor(mycells$condition,levels = c("acetate","glycerol","glucose","glucoseaa")) 

p1 <- mycells %>% 
  distinct(condition,promoter,vector,.keep_all=TRUE) %>% 
  ggplot()+
  geom_point(aes(log(pred_gr),log(mean_concentration_condition),col=condition),size=4,shape=1,alpha=0.5)+
  geom_linerange(aes(x=log(pred_gr),ymin=log(mean_concentration_condition-sd_concentration_condition),ymax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_errorbarh(aes(y=log(mean_concentration_condition),xmin=log(pred_gr-sd_pred_gr),xmax=log(pred_gr+sd_pred_gr)))+
  facet_wrap(~strain)+#,scale="free_y")+
  scale_color_manual(values = mycolors)+
  xlab("log(Pseudo bulk growth rate)")+
  ylab("log(mean GFP concentration)")+
  labs(subtitle="Mother Machine Data")
  #coord_cartesian(xlim=c(2.5,14))

cal_output_df$condition <- factor(cal_output_df$condition,levels = c("acetate","glycerol","glucose","glucoseaa")) 

cal_output_df %>% 
  ggplot()+
  geom_point(aes(log(well_gr),l_concentration_pred,col=condition))+
  facet_wrap(~strain)+#,scale="free_y")+
  scale_color_manual(values = mycolors)
  #xlab("log(Bulk growth rate)")+
  #ylab("Predicted log(GFP concentration)")+
  #labs(subtitle="Mother Machine Data")

p1 <- p1+ geom_point(data=cal_output_df,aes(log(well_gr),l_concentration_pred,col=condition))+
  geom_linerange(data=cal_output_df,aes(x=log(well_gr),ymin=l_concentration_pred-sigma_alpha,ymax=l_concentration_pred+sigma_alpha))+
  geom_errorbarh(data=cal_output_df,aes(y=l_concentration_pred,xmin=log(well_gr-sd_well_gr),xmax=log(well_gr+sd_well_gr)))
  #facet_wrap(~strain)+#,scale="free_y")+
  #scale_color_manual(values = mycolors)
  #xlab("log(Bulk growth rate)")+
  #ylab("Predicted log(GFP concentration)")+
  #labs(subtitle="Mother Machine Data")
```
Does it fit single cell distribution?
```{r}
mycells %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  ggplot()+
  geom_point(aes(log(alpha),log(mean_concentration),col=condition))+
  facet_wrap(~strain)
```

So the predictions are that, as the cells are growing faster, the concentration is also getting bigger. But, we know from mother machine experiments, that this is not the truth.

We know that from covariation, that's not the truth either.

So I do not believe that either.

# COMPUTING EACH TERM

# TRYING TO COMPUTE VARIANCES AND COVARIANCES

```{r}
variance_delta_p <- function(.sigma_well,.delta_well){
  .wp <- 1/(.sigma_well**2)
  .var <- sum((.delta_well-sum(.wp*.delta_well)/sum(.wp))**2)/length(.sigma_well)
  return(rep(c(.var),times=length(.delta_well)))
}

cal_output_var <- cal_input_df %>% 
  group_by(condition) %>% 
  mutate(var_delta=variance_delta_p(sigma_well,delta_well)) %>% 
  mutate(mean_var_p=mean(sigma_well**2)) %>% 
  ungroup() %>% 
  distinct(condition,var_delta,mean_var_p)

cal_output_var

```

```{r}
# Pearson correlation between \deltap and \deltagr

compute_pearson <- function(.x,.y){
  .mx <- mean(.x)
  .my <- mean(.y)
  .mxy <- mean(.x*.y)
  .mx2 <- mean(.x**2)
  .my2 <- mean(.y**2)
  r <- (.mxy-.mx*.my)/sqrt((.mx2-(.mx)**2.)*(.my2-.my**2))
  return(rep(c(r),times=length(.x)))
}

p_corr <- cal_input_df %>% 
  group_by(condition) %>% 
  mutate(pearson_correlation=round(compute_pearson(delta_gr,delta_well),2)) %>% 
  ungroup() %>% 
  distinct(condition,pearson_correlation)

library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(9, "Set1"))(nb.cols)

cal_input_df %>%
  ggplot()+
  geom_point(aes(delta_gr,delta_well,col=strain))+
  geom_linerange(aes(x=delta_gr,ymin=delta_well-sigma_well,ymax=delta_well+sigma_well,col=strain))+
  geom_errorbarh(aes(y=delta_well,xmin=delta_gr-sigma_gr,xmax=delta_gr+sigma_gr,col=strain))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  facet_wrap(~interaction(condition,strain))+
  theme_cowplot()+
  scale_color_manual(values = mycolors)

cal_input_df %>%
  ggplot()+
  geom_point(aes(delta_gr,delta_well,col=replica))+
  geom_linerange(aes(x=delta_gr,ymin=delta_well-sigma_well,ymax=delta_well+sigma_well,col=replica))+
  geom_errorbarh(aes(y=delta_well,xmin=delta_gr-sigma_gr,xmax=delta_gr+sigma_gr,col=replica))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  facet_wrap(~interaction(condition,strain),scale="free")+
  theme_cowplot()+
  scale_color_manual(values = mycolors)+
  ggsave("./delta_gr_delta_p.pdf",width=15,height=10)

cal_input_df %>%
  filter(replica!=1) %>% 
  ggplot()+
  geom_point(aes(delta_gr,delta_well,col=replica))+
  geom_linerange(aes(x=delta_gr,ymin=delta_well-sigma_well,ymax=delta_well+sigma_well,col=replica))+
  geom_errorbarh(aes(y=delta_well,xmin=delta_gr-sigma_gr,xmax=delta_gr+sigma_gr,col=replica))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  facet_wrap(~interaction(condition,strain),scale="free")+
  theme_cowplot()+
  scale_color_manual(values = mycolors)+
  ggsave("./delta_gr_delta_p_norep1.pdf",width=15,height=10)


cal_input_df %>% 
  ggplot()+
  geom_point(aes(delta_gr,delta_well))+
  geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  facet_wrap(~condition,scale="free")+
  theme_cowplot()
```

So... should we... compute gamma for all promoters? Even there, it looks crappy.

# SIMPLER

We now consider that, we have for each conditions, log(alpha)=log(c) + a0.
We some noise.

First, I will compute correctly, the average alpha that is expected + reasonnable error bars.
Then we'll use this for the calibration.

```{r}
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(15, "Set1"))(nb.cols)

mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition) %>% 
  mutate(calibration_slope=compute_slope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_intercept=compute_intercept_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_sd_slope=compute_sdslope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>%
  mutate(calibration_factor=exp(calibration_intercept)) %>% 
  ungroup() %>% 
  distinct(condition,calibration_slope,calibration_sd_slope,calibration_intercept,calibration_factor)

myslopes <- mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition) %>% 
  mutate(calibration_slope=compute_slope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_intercept=compute_intercept_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>% 
  mutate(calibration_sd_slope=compute_sdslope_errxy(log(mean_concentration_condition),log(alpha_gfp))) %>%
  mutate(calibration_factor=exp(calibration_intercept)) %>% 
  ungroup() %>% 
  distinct(condition,calibration_slope,calibration_sd_slope,calibration_intercept,calibration_factor)

# Representing the correct slopes

mydata_gr_exp_summary %>%
  left_join(myslopes,by=c("condition")) %>% 
  #filter(replica==1) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_line(aes(x=log(mean_concentration_condition),y=log(mean_concentration_condition)*calibration_slope+calibration_intercept))+
  #geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  #stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()+
  xlab("Mean concentration (Mother machine) #GFP/um3")+
  ylab("Bulk results (GFU/OD)")

```

Now, let's go back a bit, and compute the average for each promoter, together with proper error bars.
Each error bar has to be replace by a correct value. We'll use sd_l_c=sd_c/c.

Then from these error bars, we can compute a weighted mean.
So that <x>=sum(xi/di)/(sum(1/di)).
And then weighted standard deviation.

The different measurements are characterized by a certain error. Computing the average correctly can be done by:

Then, the associated error bar, should also be:

And for the error bar.

```{r}
mydata_gr_exp_summary_w <- mydata_gr_exp_summary %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition,strain) %>%
  mutate(p=n()) %>% 
  mutate(w_alpha_gfp=sum(alpha_gfp/sd_alpha_gfp)/sum(1/sd_alpha_gfp)) %>% 
  mutate(var_w_alpha_gfp=sum((alpha_gfp-w_alpha_gfp)**2/sd_alpha_gfp)/sum(1/sd_alpha_gfp)*p/(p-1)) %>% 
  mutate(sd_w_alpha_gfp=sqrt(var_w_alpha_gfp)) %>% 
  mutate(se_w_alpha_gfp=sqrt(var_w_alpha_gfp)) %>% 
  ungroup() %>% 
  distinct(condition,strain,.keep_all=TRUE)

myslopes <- mydata_gr_exp_summary_w %>%
  group_by(condition) %>% 
  mutate(calibration_slope=compute_slope_errxy(log(mean_concentration_condition),log(w_alpha_gfp))) %>% 
  mutate(calibration_intercept=compute_intercept_errxy(log(mean_concentration_condition),log(w_alpha_gfp))) %>% 
  mutate(calibration_sd_slope=compute_sdslope_errxy(log(mean_concentration_condition),log(w_alpha_gfp))) %>%
  mutate(calibration_factor=exp(calibration_intercept)) %>% 
  ungroup() %>% 
  distinct(condition,calibration_slope,calibration_sd_slope,calibration_intercept,calibration_factor)
  
mydata_gr_exp_summary_w %>% 
  left_join(myslopes,by=c("condition")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(w_alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(w_alpha_gfp-sd_w_alpha_gfp),ymax=log(w_alpha_gfp+sd_w_alpha_gfp)))+
  geom_errorbar(aes(y=log(w_alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_line(aes(x=log(mean_concentration_condition),y=log(mean_concentration_condition)*calibration_slope+calibration_intercept))+
  #geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  #stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()+
  xlab("Mean concentration (Mother machine) #GFP/um3")+
  ylab("Bulk results (GFU/OD)")

mydata_gr_exp_summary_w %>% 
  left_join(myslopes,by=c("condition")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(w_alpha_gfp),col=condition),size=3)+
  geom_point(data=calibration_results %>% 
               semi_join(selected_strains_df,by=c("strain","condition")), aes(.l_x,.l_y))+
  #geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(w_alpha_gfp-sd_w_alpha_gfp),ymax=log(w_alpha_gfp+sd_w_alpha_gfp)))+
  #geom_errorbar(aes(y=log(w_alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  #geom_line(aes(x=log(mean_concentration_condition),y=log(mean_concentration_condition)*calibration_slope+calibration_intercept))+
  #geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  #stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  #facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)+
  theme_cowplot()+
  xlab("Mean concentration (Mother machine) #GFP/um3")+
  ylab("Bulk results (GFU/OD)")
```

So even doing so, the error bars are not, touching the mean line. But that's certainly the best we can do here. Now I will use this calibration curve to predict other promoters results. I will simply repeat what I did for the autofluorescence.

Using Erik's notes, section 4., I should compute:
- mean of log(w_alpha_gfp) and log(mean_concentration_condition)
- standard deviation of log(autofluorescence) and log(exponential growth rate)
- covariance of log(autofluorescence) and log(exponential growth rate)

```{r}
# Given what is seen above, I set a filter to get rid of unwanted data

calibration_curve <- mydata_gr_exp_summary_w %>% 
  group_by(condition) %>% 
  mutate(l_y=log(mean_concentration_condition)) %>% #here growth rate is in doublings per hour, which is more intuitive
  mutate(l_x=log(w_alpha_gfp)) %>% 
  mutate(p=n(),
         m_l_x=mean(l_x,na.rm=TRUE),
         m_l_y=mean(l_y,na.rm=TRUE),
         var_l_x=var(l_x,na.rm=TRUE),
         var_l_y=var(l_y,na.rm=TRUE),
         cov_l_x_l_y=1/p*sum(l_y*l_x-m_l_x*m_l_y,na.rm=TRUE)) %>% 
  filter(row_number()==1) %>% 
  ungroup() %>% 
  select(condition,m_l_x,m_l_y,var_l_x,var_l_y,cov_l_x_l_y,p)

calibration_curve
```
# Converting now for all strains, the desired result in terms of concentration.

```{r}
calibration_results <- mydata_gr_exp_summary %>% 
  select(-c(l_x,var_l_x,l_y,var_l_y,p)) %>% 
  #anti_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  filter(!(strain %in% c("MG1655","empty"))) %>% 
  left_join(calibration_curve,by=c("condition")) %>% 
  group_by(condition,strain) %>%
  mutate(m=n()) %>% 
  mutate(w_alpha_gfp=sum(alpha_gfp/sd_alpha_gfp)/sum(1/sd_alpha_gfp)) %>% 
  mutate(var_w_alpha_gfp=sum((alpha_gfp-w_alpha_gfp)**2/sd_alpha_gfp)/sum(1/sd_alpha_gfp)*m/(m-1)) %>% 
  mutate(sd_w_alpha_gfp=sqrt(var_w_alpha_gfp)) %>% 
  mutate(se_w_alpha_gfp=sqrt(var_w_alpha_gfp)) %>% 
  ungroup() %>% 
  distinct(condition,strain,.keep_all=TRUE) %>% 
  mutate(.l_x=log(w_alpha_gfp),
         .var_l_x=((sd_w_alpha_gfp)**2)/((w_alpha_gfp)**2)) %>%
  mutate(.l_y=m_l_y+cov_l_x_l_y/(var_l_x)*(.l_x-m_l_x),
         r=cov_l_x_l_y/(sqrt(var_l_x*var_l_y)),
         .var_l_y=.var_l_x*(cov_l_x_l_y**2/(var_l_x**2))+var_l_y*(1-r**2)*(1+(.var_l_x+(.l_x-m_l_x)**2)/p))

calibration_results %>% 
  semi_join(selected_strains_df,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(.l_x,.l_y,col=condition))+
  facet_wrap(~condition)
```

# NOW LOOKING AT THE RESULTS

Now we would like to see how all these guys are behaving.

```{r}


  
  
```






```{r}
# Now plot how the different promoters are behaving
library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
nb.cols <- 4
mycolors <- colorRampPalette(brewer.pal(4, "Set1"))(nb.cols)

mycells %>% 
  ggplot(aes(log(mean_concentration),col=condition))+
  stat_ecdf()+
  facet_wrap(~interaction(vector,promoter))+
  scale_color_manual(values = mycolors)+
  xlab("Mean GFP concentration (#GFP/um3)")+
  ylab("CDF")+
  labs(subtitle="Mother Machine Data")+
  coord_cartesian(xlim=c(2.5,14))

mycells$condition <- factor(mycells$condition,levels = c("acetate","glycerol","glucose","glucoseaa")) 

p1 <- mycells %>% 
  distinct(condition,promoter,vector,.keep_all=TRUE) %>% 
  ggplot()+
  geom_point(aes(log(pred_gr),log(mean_concentration_condition),col=condition),size=4,shape=1,alpha=0.5)+
  geom_linerange(aes(x=log(pred_gr),ymin=log(mean_concentration_condition-sd_concentration_condition),ymax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_errorbarh(aes(y=log(mean_concentration_condition),xmin=log(pred_gr-sd_pred_gr),xmax=log(pred_gr+sd_pred_gr)))+
  facet_wrap(~strain)+#,scale="free_y")+
  scale_color_manual(values = mycolors)+
  xlab("log(Pseudo bulk growth rate)")+
  ylab("log(mean GFP concentration)")+
  labs(subtitle="Mother Machine Data")
  #coord_cartesian(xlim=c(2.5,14))

cal_output_df$condition <- factor(cal_output_df$condition,levels = c("acetate","glycerol","glucose","glucoseaa")) 

cal_output_df %>% 
  ggplot()+
  geom_point(aes(log(well_gr),l_concentration_pred,col=condition))+
  facet_wrap(~strain)+#,scale="free_y")+
  scale_color_manual(values = mycolors)
  #xlab("log(Bulk growth rate)")+
  #ylab("Predicted log(GFP concentration)")+
  #labs(subtitle="Mother Machine Data")

gr_df <- mycells %>% 
  distinct(condition,strain,pred_gr,sd_pred_gr)

cal_output_df_with_gr <- cal_output_df %>% 
  left_join(gr_df,by=c("condition","strain"))
  
p1 <- p1+ geom_point(data=cal_output_df_with_gr,aes(log(pred_gr),l_concentration_pred,col=condition))+
  geom_linerange(data=cal_output_df_with_gr,aes(x=log(pred_gr),ymin=l_concentration_pred-sigma_alpha,ymax=l_concentration_pred+sigma_alpha))+
  geom_errorbarh(data=cal_output_df_with_gr,aes(y=l_concentration_pred,xmin=log(pred_gr-sd_pred_gr),xmax=log(pred_gr+sd_pred_gr)))
  #facet_wrap(~strain)+#,scale="free_y")+
  #scale_color_manual(values = mycolors)
  #xlab("log(Bulk growth rate)")+
  #ylab("Predicted log(GFP concentration)")+
  #labs(subtitle="Mother Machine Data")
```

```{r}
p1 <- mycells %>% 
  distinct(condition,promoter,vector,.keep_all=TRUE) %>% 
  ggplot()+
  geom_point(aes(log(pred_gr),log(mean_concentration_condition),col=condition),size=4,shape=1,alpha=0.5)+
  geom_linerange(aes(x=log(pred_gr),ymin=log(mean_concentration_condition-sd_concentration_condition),ymax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_errorbarh(aes(y=log(mean_concentration_condition),xmin=log(pred_gr-sd_pred_gr),xmax=log(pred_gr+sd_pred_gr)))+
  facet_wrap(~strain,scale="free_y")+
  scale_color_manual(values = mycolors)+
  xlab("log(Pseudo bulk growth rate)")+
  ylab("log(mean GFP concentration)")+
  labs(subtitle="Mother Machine Data")
  #coord_cartesian(xlim=c(2.5,14))

gr_df <- mycells %>% 
  distinct(condition,strain,pred_gr,sd_pred_gr)

cal_output_df_with_gr <- cal_output_df %>% 
  left_join(gr_df,by=c("condition","strain"))
  
p1 <- p1+ geom_point(data=cal_output_df_with_gr,aes(log(pred_gr),l_concentration_pred,col=condition))+
  geom_linerange(data=cal_output_df_with_gr,aes(x=log(pred_gr),ymin=l_concentration_pred-sigma_alpha,ymax=l_concentration_pred+sigma_alpha))+
  geom_errorbarh(data=cal_output_df_with_gr,aes(y=l_concentration_pred,xmin=log(pred_gr-sd_pred_gr),xmax=log(pred_gr+sd_pred_gr)))

p1
```
# Checking the log likelihood function by submitting synthetic data

I am making a fake data set, with the following: 

For a condition C, let's imagine, P promoters.
Such that: log(ap)=log(c)+a0+gamma * delta(P)
Or: Delta_p= a0 + gamma delta gr

Each promoter is characterized by:
Mother machine

mm_gr_p: mother machine growth rate, gaussian distribution. Set to 1.
m_l_c_p: concentration seen in the mother machine, uniform distribution
sd_l_c_p: error bar on the concentration seen in the mother machine, we'll assume this is constant, and scales with sqrt(c_p)
l_c_p=m_l_c_p + noise(sd_l_c_p)

Bulk data

nr: number of replicates
gr_r: growth rate of replica r: gaussian distribution centered on mm_gr_p, with a given noise that scale like sigma_gr=0.1*mm_gr_p of the growth rate. 
sd_l_alpha=noise on the measurement of sd_l_alpha
l_alpha=l_c_p+a0+gamma*(gr_r-mm_gr_p)+noise(sd_l_alpha)

And there it is! Then apply the log-likelihood and see if I can find back a0 and gamma.

# IN SILICO TEST OF THE LOG-LIKELIHOOD FUNCTION
```{r}
# Define promoters and replicate.
N_promoter <- 10
nr <- 6
# Let's pick for everyone of them, a mother machine growth rate as well as a a mean log concentration
# In my data, log(cp) is distributed between 6 and 12.
l_c_min <- 6
l_c_max <- 12
#Let's now pick random values for these log(cp)
m_l_c_p <- l_c_min+runif(N_promoter)*(l_c_max-l_c_min)
# Now let's determine a vector of noise for each one of these promoters.
# In my mother machine data, it seems to be small.
noise_factor_mm <- 1e-5
sd_l_c_p <- noise_factor_mm*(m_l_c_p)
# Now let's produce the wanted fluctuations
noise_l_c_p <- sd_l_c_p*rnorm(N_promoter,mean=0,sd=1)
# And the final vector of measured log(concentrations) in the mm, with fluctuations is:
l_c_p <- m_l_c_p+noise_l_c_p

# We can now generate pseudo-bulk growth rates
mean_gr <- 1 #doulings/hour
sd_gr <- 0.1*mean_gr
mm_gr_p <- rnorm(N_promoter,mean=mean_gr,sd=sd_gr)

# We now focus on bulk data
# For each one of the wells, let's pick a growth rate around the mean growth rate that has been chosen
gr_r <- rnorm(nr*N_promoter,mean=mean_gr,sd=sd_gr)

# We assume there are not particular structure for the covariance between delta_gr and delta_well.
# Let's transform the mm vectors to determine bulk values
# Vector of mm growth rates
mm_gr_p_r <- rep(mm_gr_p,each=nr)
# Vector of mm log(concentrations)
l_c_p_r <- rep(l_c_p, each=nr)

# We define for the model a calibration constant a0 and a growth rate correction factor gamma
a0 <- -2
gamma <- -10

# We now compute a vector of bulk measurement, without noise.
l_alpha_no_noise <- l_c_p_r+a0+gamma*(gr_r-mm_gr_p_r)

# To which we add some random noise
noise_factor_alpha <- 0.01
sd_l_alpha <- noise_factor_alpha*l_alpha_no_noise

# And we can add this random noise to the vector of bulk measurements
l_alpha <- l_alpha_no_noise*(1+rnorm(nr*N_promoter,mean=0,sd=1)*sd_l_alpha)

# Now we also define a vector of error bars, for the mm data. Format it for the replicates.
sd_l_c_p_r <- rep(sd_l_c_p,each=nr)
# And a vector of growth rate measurement error.
sd_gr_r <- rep(sd_gr,times=nr*N_promoter) #both bulk and mother machine

#Formatting the data
synth_df <- cbind(l_c_p_r,l_alpha,sd_l_c_p_r,sd_l_alpha,sd_gr_r,mm_gr_p_r,gr_r)
colnames(synth_df) <- c("l_c_p_r","l_alpha","sd_l_c_p_r","sd_l_alpha","sd_gr_r","mm_gr_p_r","gr_r")
synth_df <- as.tibble(synth_df)
synth_df <- synth_df %>% 
  mutate(sigma_well=sqrt(sd_l_c_p_r**2+sd_l_alpha**2),
         sigma_gr=sqrt(2*sd_gr_r**2),
         delta_well=l_alpha-l_c_p_r,
         delta_gr=gr_r-mm_gr_p_r)

#log-likelihood function and optimization
compute_calibration_gamma <- function(.sigma_well,.sigma_gr,.delta_well,.delta_gr){
  
  m_ll_calibration <- function(.gamma){
  .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(.delta_well-.gamma*.delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
  }
  
  gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
  return(rep(c(gamma),times=length(.sigma_well)))
}

compute_calibration_a <- function(.gamma,.sigma_well,.sigma_gr,.delta_well,.delta_gr){
  .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
  return(rep(c(.a),times=length(.sigma_well)))
}

# Performing the optimization
synth_df_output <- synth_df %>% 
  mutate(gamma=compute_calibration_gamma(sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
  mutate(a_star=compute_calibration_a(gamma,sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
  ungroup()

synth_df_output %>% 
  distinct(gamma,a_star)
```
Plot log-likelihood function
```{r}
df <- synth_df

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term3))
}

g <- seq(-10,10,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
plot(g,minus_ll)

g <- seq(1,40,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
plot(g,minus_ll)

g <- seq(-40,-1,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
plot(g,minus_ll)

best_gamma <- nloptr::cobyla(x0=1,m_ll_calibration)$par
best_gamma

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}

g <- seq(-20,20,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)

```
The shape of the function is the same again.
So the tendency seem to be correct. When gamma is pushed to more negative value, the optimum is pushed as well. And it seems to be symmetric as well... My guess it is because of some shit in Erik's notes. Let's go back.

Write it as a function, and check results.

```{r}
run_inference <- function(a0,gamma){
    # Define promoters and replicate.
    N_promoter <- 10
    nr <- 6
    # Let's pick for everyone of them, a mother machine growth rate as well as a a mean log concentration
    # In my data, log(cp) is distributed between 6 and 12.
    l_c_min <- 6
    l_c_max <- 12
    #Let's now pick random values for these log(cp)
    m_l_c_p <- l_c_min+runif(N_promoter)*(l_c_max-l_c_min)
    # Now let's determine a vector of noise for each one of these promoters.
    # In my mother machine data, it seems to be small.
    noise_factor_mm <- 1e-5
    sd_l_c_p <- noise_factor_mm*(m_l_c_p)
    # Now let's produce the wanted fluctuations
    noise_l_c_p <- sd_l_c_p*rnorm(N_promoter,mean=0,sd=1)
    # And the final vector of measured log(concentrations) in the mm, with fluctuations is:
    l_c_p <- m_l_c_p+noise_l_c_p
    
    # We can now generate pseudo-bulk growth rates
    mean_gr <- 1 #doulings/hour
    sd_gr <- 0.1*mean_gr
    mm_gr_p <- rnorm(N_promoter,mean=mean_gr,sd=sd_gr)
    
    # We now focus on bulk data
    # For each one of the wells, let's pick a growth rate around the mean growth rate that has been chosen
    gr_r <- rnorm(nr*N_promoter,mean=mean_gr,sd=sd_gr)
    
    # We assume there are not particular structure for the covariance between delta_gr and delta_well.
    # Let's transform the mm vectors to determine bulk values
    # Vector of mm growth rates
    mm_gr_p_r <- rep(mm_gr_p,each=nr)
    # Vector of mm log(concentrations)
    l_c_p_r <- rep(l_c_p, each=nr)
    
    # We define for the model a calibration constant a0 and a growth rate correction factor gamma
    #a0 <- -2.7
    #gamma <- -2.7
    
    # We now compute a vector of bulk measurement, without noise.
    l_alpha_no_noise <- l_c_p_r+a0+gamma*(gr_r-mm_gr_p_r)
    
    # To which we add some random noise
    noise_factor_alpha <- 0.01
    sd_l_alpha <- noise_factor_alpha*l_alpha
    
    # And we can add this random noise to the vector of bulk measurements
    l_alpha <- l_alpha_no_noise*(1+rnorm(nr*N_promoter,mean=0,sd=1)*sd_l_alpha)
    
    # Now we also define a vector of error bars, for the mm data. Format it for the replicates.
    sd_l_c_p_r <- rep(sd_l_c_p,each=nr)
    # And a vector of growth rate measurement error.
    sd_gr_r <- rep(sd_gr,times=nr*N_promoter) #both bulk and mother machine
    
    #Formatting the data
    synth_df <- cbind(l_c_p_r,l_alpha,sd_l_c_p_r,sd_l_alpha,sd_gr_r,mm_gr_p_r,gr_r)
    colnames(synth_df) <- c("l_c_p_r","l_alpha","sd_l_c_p_r","sd_l_alpha","sd_gr_r","mm_gr_p_r","gr_r")
    synth_df <- as.tibble(synth_df)
    synth_df <- synth_df %>% 
      mutate(sigma_well=sqrt(sd_l_c_p_r**2+sd_l_alpha**2),
             sigma_gr=sqrt(2*sd_gr_r**2),
             delta_well=l_alpha-l_c_p_r,
             delta_gr=gr_r-mm_gr_p_r)
    
    #log-likelihood function and optimization
    compute_calibration_gamma <- function(.sigma_well,.sigma_gr,.delta_well,.delta_gr){
      
      m_ll_calibration <- function(.gamma){
      .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
      .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
      .term1 <- 1/2*(sum(log(.wp)))
      .term2 <- -1/2*log(sum(.wp))
      .term3 <- -1/2*sum(.wp*(.delta_well-.gamma*.delta_gr-.a)**2)
      return(-(.term1+.term2+.term3))
      }
      
      gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
      return(rep(c(gamma),times=length(.sigma_well)))
    }
    
    compute_calibration_a <- function(.gamma,.sigma_well,.sigma_gr,.delta_well,.delta_gr){
      .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
      .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
      return(rep(c(.a),times=length(.sigma_well)))
    }
    
    # Performing the optimization
    synth_df_output <- synth_df %>% 
      mutate(gamma=compute_calibration_gamma(sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
      mutate(a_star=compute_calibration_a(gamma,sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
      ungroup()
    
    synth_df_output %>% 
      distinct(gamma,a_star)
    
    return(tibble(a=a0,gamma=gamma,a_star=unique(synth_df_output$a_star),gamma_star=unique(synth_df_output$gamma)))
}
```

Print results


Case where a=-2.
```{r}
gamma_list <- rep(seq(-40,+40,1),each=5)
a_list <- rep(c(-2),times=length(gamma_list))

results <- mapply(run_inference,
       a_list,
       gamma_list,SIMPLIFY = FALSE)

results <- do.call("rbind",results)
results %>% 
  ggplot()+
  geom_point(aes(gamma,gamma_star))+
  geom_abline(aes(slope=1,intercept=0))
```
Case where a=-1.
```{r}
gamma_list <- rep(seq(-40,+40,1),each=5)
a_list <- rep(c(-1),times=length(gamma_list))

results <- mapply(run_inference,
       a_list,
       gamma_list,SIMPLIFY = FALSE)

results <- do.call("rbind",results)
results %>% 
  ggplot()+
  geom_point(aes(gamma,gamma_star))+
  geom_abline(aes(slope=1,intercept=0))
```
Case where a=-10 to -1, gamma set at -5
```{r}
a_list<- rep(seq(-10,+10,1),each=5)
gamma_list <- rep(c(-5),times=length(a_list))

results <- mapply(run_inference,
       a_list,
       gamma_list,SIMPLIFY = FALSE)

results <- do.call("rbind",results)
results %>% 
  ggplot()+
  geom_point(aes(a,a_star))+
  geom_abline(aes(slope=1,intercept=0))
```
gamma to -20?
```{r}
a_list<- rep(seq(-10,+10,1),each=5)
gamma_list <- rep(c(-20),times=length(a_list))

results <- mapply(run_inference,
       a_list,
       gamma_list,SIMPLIFY = FALSE)

results <- do.call("rbind",results)
results %>% 
  ggplot()+
  geom_point(aes(a,a_star))+
  geom_abline(aes(slope=1,intercept=0))
```
gamma to -40?
```{r}
a_list<- rep(seq(-10,+10,1),each=5)
gamma_list <- rep(c(-40),times=length(a_list))

results <- mapply(run_inference,
       a_list,
       gamma_list,SIMPLIFY = FALSE)

results <- do.call("rbind",results)
results %>% 
  ggplot()+
  geom_point(aes(a,a_star))+
  geom_abline(aes(slope=1,intercept=0))
```
I think this is simply saying that... a does not depend much on gamma in this equation. Is it true?

```{r}
run_inference <- function(a0,gamma){
    # Define promoters and replicate.
    N_promoter <- 10
    nr <- 6
    # Let's pick for everyone of them, a mother machine growth rate as well as a a mean log concentration
    # In my data, log(cp) is distributed between 6 and 12.
    l_c_min <- 6
    l_c_max <- 12
    #Let's now pick random values for these log(cp)
    m_l_c_p <- l_c_min+runif(N_promoter)*(l_c_max-l_c_min)
    # Now let's determine a vector of noise for each one of these promoters.
    # In my mother machine data, it seems to be small.
    noise_factor_mm <- 1e-5
    sd_l_c_p <- noise_factor_mm*(m_l_c_p)
    # Now let's produce the wanted fluctuations
    noise_l_c_p <- sd_l_c_p*rnorm(N_promoter,mean=0,sd=1)
    # And the final vector of measured log(concentrations) in the mm, with fluctuations is:
    l_c_p <- m_l_c_p+noise_l_c_p
    
    # We can now generate pseudo-bulk growth rates
    mean_gr <- 1 #doulings/hour
    sd_gr <- 0.1*mean_gr
    mm_gr_p <- rnorm(N_promoter,mean=mean_gr,sd=sd_gr)
    
    # We now focus on bulk data
    # For each one of the wells, let's pick a growth rate around the mean growth rate that has been chosen
    gr_r <- rnorm(nr*N_promoter,mean=mean_gr,sd=sd_gr)
    
    # We assume there are not particular structure for the covariance between delta_gr and delta_well.
    # Let's transform the mm vectors to determine bulk values
    # Vector of mm growth rates
    mm_gr_p_r <- rep(mm_gr_p,each=nr)
    # Vector of mm log(concentrations)
    l_c_p_r <- rep(l_c_p, each=nr)
    
    # We define for the model a calibration constant a0 and a growth rate correction factor gamma
    #a0 <- -2.7
    #gamma <- -2.7
    
    # We now compute a vector of bulk measurement, without noise.
    l_alpha_no_noise <- l_c_p_r+a0+gamma*(gr_r-mm_gr_p_r)
    
    # To which we add some random noise
    noise_factor_alpha <- 0.01
    sd_l_alpha <- noise_factor_alpha*l_alpha
    
    # And we can add this random noise to the vector of bulk measurements
    l_alpha <- l_alpha_no_noise*(1+rnorm(nr*N_promoter,mean=0,sd=1)*sd_l_alpha)
    
    # Now we also define a vector of error bars, for the mm data. Format it for the replicates.
    sd_l_c_p_r <- rep(sd_l_c_p,each=nr)
    # And a vector of growth rate measurement error.
    sd_gr_r <- rep(sd_gr,times=nr*N_promoter) #both bulk and mother machine
    
    #Formatting the data
    synth_df <- cbind(l_c_p_r,l_alpha,sd_l_c_p_r,sd_l_alpha,sd_gr_r,mm_gr_p_r,gr_r)
    colnames(synth_df) <- c("l_c_p_r","l_alpha","sd_l_c_p_r","sd_l_alpha","sd_gr_r","mm_gr_p_r","gr_r")
    synth_df <- as.tibble(synth_df)
    synth_df <- synth_df %>% 
      mutate(sigma_well=sqrt(sd_l_c_p_r**2+sd_l_alpha**2),
             sigma_gr=sqrt(2*sd_gr_r**2),
             delta_well=l_alpha-l_c_p_r,
             delta_gr=gr_r-mm_gr_p_r)
    
    #log-likelihood function and optimization
    compute_calibration_gamma <- function(.sigma_well,.sigma_gr,.delta_well,.delta_gr){
      
      m_ll_calibration <- function(.gamma){
      .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
      .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
      .term1 <- 1/2*(sum(log(.wp)))
      .term2 <- -1/2*log(sum(.wp))
      .term3 <- -1/2*sum(.wp*(.delta_well-.gamma*.delta_gr-.a)**2)
      return(-(.term1+.term2+.term3))
      }
      
      gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
      return(rep(c(gamma),times=length(.sigma_well)))
    }
    
    compute_calibration_a <- function(.gamma,.sigma_well,.sigma_gr,.delta_well,.delta_gr){
      .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
      .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
      return(rep(c(.a),times=length(.sigma_well)))
    }
    
    # Performing the optimization
    synth_df_output <- synth_df %>% 
      mutate(gamma=compute_calibration_gamma(sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
      #mutate(gamma=0) %>% 
      mutate(a_star=compute_calibration_a(gamma,sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
      ungroup()
    
    synth_df_output %>% 
      distinct(gamma,a_star)
    
    return(tibble(a=a0,gamma=gamma,a_star=unique(synth_df_output$a_star),gamma_star=unique(synth_df_output$gamma)))
}
```

```{r}
a_list<- rep(seq(-10,+10,1),each=5)
gamma_list <- rep(c(-5),times=length(a_list))

results <- mapply(run_inference,
       a_list,
       gamma_list,SIMPLIFY = FALSE)

results <- do.call("rbind",results)
results %>% 
  ggplot()+
  geom_point(aes(a,a_star))+
  geom_abline(aes(slope=1,intercept=0))
```
# DETERMINING THE VALUES OF SOME PARAMETERS
Trying to debug this problem here, I came up with the results that, the computation of a, is largely independent of gamma.
Now, I am trying to understand how that can be.

It is as if in:

.wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
.a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
So here, the computation would not depend on gamma. Let's test it

```{r}
# We define for the model a calibration constant a0 and a growth rate correction factor gamma
a0 <- -1.1
gamma <- -11.2
N_promoter <- 20
nr <- 6
# Let's pick for everyone of them, a mother machine growth rate as well as a a mean log concentration

# In my data, log(cp) is distributed between 6 and 12.
l_c_min <- 6
l_c_max <- 12
#Let's now pick random values for these log(cp)
true_l_c <- l_c_min+runif(N_promoter)*(l_c_max-l_c_min)
# Now let's determine a vector of noise for each one of these promoters.
# In my mother machine data, it seems to be small.
error_l_c <- 1e-5*true_l_c
error_l_c <- error_l_c*rnorm(N_promoter,mean=0,sd=1)
# Now let's generate a measurement based on this "small" error
l_c <- true_l_c+error_l_c
error_l_c <- abs(error_l_c)

# We can now generate pseudo-bulk growth rates
mean_gr <- 1 #doublings/hour on average
#We add some biological fluctuations
fluc_gr <- 0.1*mean_gr
true_mm_gr <- rnorm(N_promoter,mean=mean_gr,sd=fluc_gr)
# And on top of that some error on the measurement
f <- 0.01
error_mm_gr <- f*mean_gr
error_mm_gr <- error_mm_gr*rnorm(N_promoter,mean=0,sd=1)
mm_gr <- true_mm_gr+error_mm_gr
error_mm_gr <- abs(error_mm_gr)

# We now focus on bulk data
# For each one of the wells, let's pick a growth rate around the mean growth rate that has been chosen
# We generate it with some biological fluctuations
true_bulk_gr <- rnorm(nr*N_promoter,mean=mean_gr,sd=fluc_gr)
# And add some noise on top of it, due to error on measurement
error_bulk_gr <- f*mean_gr*rnorm(nr*N_promoter,mean=0,sd=1)
bulk_gr <- true_bulk_gr+error_bulk_gr
error_bulk_gr <- abs(error_bulk_gr)

# We now compute a vector of bulk measurement, without noise.
true_mm_gr <- rep(true_mm_gr,each=nr)
mm_gr <- rep(mm_gr,each=nr)
true_l_c <- rep(true_l_c,each=nr)
true_l_alpha <- true_l_c+a0+gamma*(true_bulk_gr-true_mm_gr)
#true_l_alpha_s <- true_l_c+a0+gamma()
# To which we add some error again
error_l_alpha_factor <- 0.001
error_l_alpha <- error_l_alpha_factor*true_l_alpha
error_l_alpha <- error_l_alpha*rnorm(nr*N_promoter,mean=0,sd=1)
# And we can add this random noise to the vector of bulk measurements
l_alpha <- true_l_alpha+error_l_alpha
error_l_alpha <- abs(error_l_alpha)
l_c <- rep(l_c,each=nr)

# We assume there are not particular structure for the covariance between delta_gr and delta_well.
# Let's transform the mm vectors to determine bulk values
# Vector of mm growth rates
error_l_c <- rep(error_l_c,each=nr)
error_mm_gr <- rep(error_mm_gr,each=nr)

#Formatting the data
synth_df <- cbind(l_c,l_alpha,mm_gr,bulk_gr,error_l_c,error_l_alpha,error_mm_gr,error_bulk_gr,true_l_alpha,true_l_c)
colnames(synth_df) <- c("l_c","l_alpha","mm_gr","bulk_gr","error_l_c","error_l_alpha","error_mm_gr","error_bulk_gr","true_l_alpha","true_l_c")
synth_df <- as.tibble(synth_df)
synth_df <- synth_df %>% 
  mutate(sigma_well=sqrt(error_l_c**2+error_l_alpha**2),
         sigma_gr=sqrt(error_mm_gr**2+error_bulk_gr**2),
         delta_well=l_alpha-l_c,
         delta_gr=bulk_gr-mm_gr)

check_a <- function(g){
  .sigma_well <- synth_df$sigma_well
  .sigma_gr <- synth_df$sigma_gr
  .delta_well <- synth_df$delta_well
  .delta_gr <- synth_df$delta_gr
  .wp <- 1/(.sigma_well**2+(g**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-g*.delta_gr))/(sum(.wp))
  return(.a)
}

seq_g <- seq(-50,-1,0.1)
a_s <- lapply(seq_g,check_a)
plot(seq_g,a_s)
```

```{r}
 #log-likelihood function and optimization
compute_calibration_gamma <- function(.sigma_well,.sigma_gr,.delta_well,.delta_gr){
  
  m_ll_calibration <- function(.gamma){
  .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(.delta_well-.gamma*.delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
  }
  
  gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
  return(rep(c(gamma),times=length(.sigma_well)))
}

compute_calibration_a <- function(.gamma,.sigma_well,.sigma_gr,.delta_well,.delta_gr){
  .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
  .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
  return(rep(c(.a),times=length(.sigma_well)))
}

# Performing the optimization
synth_df_output <- synth_df %>% 
  mutate(gamma=compute_calibration_gamma(sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
  #mutate(gamma=0) %>% 
  mutate(a_star=compute_calibration_a(gamma,sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
  ungroup()

synth_df_output %>% 
  distinct(gamma,a_star)
```
How does it look like? Log likelihood function.

```{r}
df <- synth_df

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term3))
}

g <- seq(-15,-5,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
plot(g,minus_ll)

best_gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
best_gamma

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}

g <- seq(-15,-5,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)

```

```{r}
# We define for the model a calibration constant a0 and a growth rate correction factor gamma
#a0 <- -1.1
#gamma <- -11.2
run_inference <- function(a0,gamma){
    N_promoter <- 20
    nr <- 6
    # Let's pick for everyone of them, a mother machine growth rate as well as a a mean log concentration
    
    # In my data, log(cp) is distributed between 6 and 12.
    l_c_min <- 6
    l_c_max <- 12
    #Let's now pick random values for these log(cp)
    true_l_c <- l_c_min+runif(N_promoter)*(l_c_max-l_c_min)
    # Now let's determine a vector of noise for each one of these promoters.
    # In my mother machine data, it seems to be small.
    error_l_c <- 1e-5*true_l_c
    error_l_c <- error_l_c*rnorm(N_promoter,mean=0,sd=1)
    # Now let's generate a measurement based on this "small" error
    l_c <- true_l_c+error_l_c
    error_l_c <- abs(error_l_c)
    
    # We can now generate pseudo-bulk growth rates
    mean_gr <- 1 #doublings/hour on average
    #We add some biological fluctuations
    fluc_gr <- 0.1*mean_gr
    true_mm_gr <- rnorm(N_promoter,mean=mean_gr,sd=fluc_gr)
    # And on top of that some error on the measurement
    f <- 0.01
    error_mm_gr <- f*mean_gr
    error_mm_gr <- error_mm_gr*rnorm(N_promoter,mean=0,sd=1)
    mm_gr <- true_mm_gr+error_mm_gr
    error_mm_gr <- abs(error_mm_gr)
    
    # We now focus on bulk data
    # For each one of the wells, let's pick a growth rate around the mean growth rate that has been chosen
    # We generate it with some biological fluctuations
    true_bulk_gr <- rnorm(nr*N_promoter,mean=mean_gr,sd=fluc_gr)
    # And add some noise on top of it, due to error on measurement
    error_bulk_gr <- f*mean_gr*rnorm(nr*N_promoter,mean=0,sd=1)
    bulk_gr <- true_bulk_gr+error_bulk_gr
    error_bulk_gr <- abs(error_bulk_gr)
    
    # We now compute a vector of bulk measurement, without noise.
    true_mm_gr <- rep(true_mm_gr,each=nr)
    mm_gr <- rep(mm_gr,each=nr)
    true_l_c <- rep(true_l_c,each=nr)
    true_l_alpha <- true_l_c+a0+gamma*(true_bulk_gr-true_mm_gr)
    #true_l_alpha_s <- true_l_c+a0+gamma()
    # To which we add some error again
    error_l_alpha_factor <- 0.001
    error_l_alpha <- error_l_alpha_factor*true_l_alpha
    error_l_alpha <- error_l_alpha*rnorm(nr*N_promoter,mean=0,sd=1)
    # And we can add this random noise to the vector of bulk measurements
    l_alpha <- true_l_alpha+error_l_alpha
    error_l_alpha <- abs(error_l_alpha)
    l_c <- rep(l_c,each=nr)
    
    # We assume there are not particular structure for the covariance between delta_gr and delta_well.
    # Let's transform the mm vectors to determine bulk values
    # Vector of mm growth rates
    error_l_c <- rep(error_l_c,each=nr)
    error_mm_gr <- rep(error_mm_gr,each=nr)
    
    #Formatting the data
    synth_df <- cbind(l_c,l_alpha,mm_gr,bulk_gr,error_l_c,error_l_alpha,error_mm_gr,error_bulk_gr,true_l_alpha,true_l_c)
    colnames(synth_df) <- c("l_c","l_alpha","mm_gr","bulk_gr","error_l_c","error_l_alpha","error_mm_gr","error_bulk_gr","true_l_alpha","true_l_c")
    synth_df <- as.tibble(synth_df)
    synth_df <- synth_df %>% 
      mutate(sigma_well=sqrt(error_l_c**2+error_l_alpha**2),
             sigma_gr=sqrt(error_mm_gr**2+error_bulk_gr**2),
             delta_well=l_alpha-l_c,
             delta_gr=bulk_gr-mm_gr)
    
    #log-likelihood function and optimization
    compute_calibration_gamma <- function(.sigma_well,.sigma_gr,.delta_well,.delta_gr){
      
      m_ll_calibration <- function(.gamma){
      .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
      .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
      .term1 <- 1/2*(sum(log(.wp)))
      .term2 <- -1/2*log(sum(.wp))
      .term3 <- -1/2*sum(.wp*(.delta_well-.gamma*.delta_gr-.a)**2)
      return(-(.term1+.term2+.term3))
      }
      
      gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
      return(rep(c(gamma),times=length(.sigma_well)))
    }
    
    compute_calibration_a <- function(.gamma,.sigma_well,.sigma_gr,.delta_well,.delta_gr){
      .wp <- 1/(.sigma_well**2+(.gamma**2)*.sigma_gr**2)
      .a <- sum(.wp*(.delta_well-.gamma*.delta_gr))/(sum(.wp))
      return(rep(c(.a),times=length(.sigma_well)))
    }
    
    # Performing the optimization
    synth_df_output <- synth_df %>% 
      mutate(gamma=compute_calibration_gamma(sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
      mutate(a_star=compute_calibration_a(gamma,sigma_well,sigma_gr,delta_well,delta_gr)) %>% 
      ungroup()
    
    synth_df_output %>% 
      distinct(gamma,a_star)
    
    return(tibble(a=a0,gamma=gamma,a_star=unique(synth_df_output$a_star),gamma_star=unique(synth_df_output$gamma)))
}
```

```{r}
a_list<- rep(seq(-10,+10,1),each=5)
gamma_list <- rep(c(-10),times=length(a_list))

results <- mapply(run_inference,
       a_list,
       gamma_list,SIMPLIFY = FALSE)

results <- do.call("rbind",results)
results %>% 
  ggplot()+
  geom_point(aes(a,a_star))+
  geom_abline(aes(slope=1,intercept=0))+
  labs(subtitle="gamma=-10")
```
```{r}
gamma_list <- rep(seq(-40,0,1),each=5)
a_list <- rep(c(-1),times=length(gamma_list))

results <- mapply(run_inference,
       a_list,
       gamma_list,SIMPLIFY = FALSE)

results <- do.call("rbind",results)
results %>% 
  ggplot()+
  geom_point(aes(gamma,gamma_star))+
  geom_abline(aes(slope=1,intercept=0))+
  labs(subtitle ="a=-1")
```
```{r}




```


```{r}
# Pearson correlation between \deltap and \deltagr

compute_pearson <- function(.x,.y){
  .mx <- mean(.x)
  .my <- mean(.y)
  .mxy <- mean(.x*.y)
  .mx2 <- mean(.x**2)
  .my2 <- mean(.y**2)
  r <- (.mxy-.mx*.my)/sqrt((.mx2-(.mx)**2.)*(.my2-.my**2))
  return(rep(c(r),times=length(.x)))
}

p_corr <- synth_df %>% 
  #group_by(condition) %>% 
  mutate(pearson_correlation=round(compute_pearson(delta_gr,delta_well),2)) %>% 
  ungroup() %>% 
  distinct(pearson_correlation)

synth_df %>% 
  ggplot()+
  geom_point(aes(delta_gr,delta_well))+
  geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  #facet_wrap(~condition,scale="free")+
  theme_cowplot()

synth_df %>% 
  ggplot()+
  geom_point(aes(delta_gr,delta_well))+
  geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  #facet_wrap(~condition,scale="free")+
  theme_cowplot()

synth_df %>% 
  ggplot()+
  geom_point(aes(bulk_gr,true_bulk_gr))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  #facet_wrap(~condition,scale="free")+
  theme_cowplot()

synth_df %>% 
  ggplot()+
  geom_point(aes(mm_gr,true_mm_gr))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  #facet_wrap(~condition,scale="free")+
  theme_cowplot()

synth_df %>% 
  ggplot()+
  geom_point(aes(l_alpha,true_l_alpha))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  #facet_wrap(~condition,scale="free")+
  theme_cowplot()

synth_df %>% 
  ggplot()+
  geom_point(aes(l_c,true_l_c))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  #facet_wrap(~condition,scale="free")+
  theme_cowplot()

synth_df %>% 
  ggplot()+
  geom_point(aes(true_l_c,true_l_alpha))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  #facet_wrap(~condition,scale="free")+
  theme_cowplot()

gamma <- -5
synth_df %>% 
  mutate(true_l_alpha=true_l_c+a0+gamma*(true_bulk_gr-true_mm_gr)) %>% 
  ggplot()+
  geom_point(aes(true_l_c,true_l_alpha))+
  #geom_text(data=p_corr,aes(x=0,y=0,label=sprintf("r=%s",pearson_correlation)))+
  #facet_wrap(~condition,scale="free")+
  theme_cowplot()



```


```



Zooming in the part of interest...
```{r}
df <- synth_df

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

g <- seq(-10,10,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
plot(g,minus_ll)

best_gamma <- nloptr::cobyla(x0=-1,m_ll_calibration)$par
best_gamma

nloptr::cobyla(x0=-1,m_ll_calibration)

m_ll_calibration(-6)
```
Ok, so... my function does not seem to provide a correct answer. The a_star is correctly predicted, but .gamma is not. Which is quite striking as... gamma is supposed to be used to predict a*! The shape of the log likelihood constant is correct too. So I can rule out that it could be due to some crazy data around...


```{r}



```





g <- seq(-100,100,by=0.01)
minus_ll <- lapply(g,m_ll_calibration)
ll <- lapply(g,ll_calibration)
#plot(g,ll)
plot(g,minus_ll)

best_gamma <- nloptr::cobyla(x0=1,m_ll_calibration)$par
best_gamma

compute_a <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.a)
}

g <- seq(-20,20,by=0.01)
a <- lapply(g,compute_a)
plot(g,a)

```










```{r}
df <- cal_input_df %>% filter(condition=="glycerol")

ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.term1+.term2+.term3)
}

g <- seq(-1,1,by=0.01)
ll <- lapply(g,ll_calibration)
plot(g,ll)

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

nloptr::cobyla(x0=1,m_ll_calibration)
```

```{r}
df <- cal_input_df %>% filter(condition=="glucose")

ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.term1+.term2+.term3)
}

g <- seq(-1,-1,by=0.01)
ll <- lapply(g,ll_calibration)
plot(g,ll)

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

nloptr::cobyla(x0=1,m_ll_calibration)
```

```{r}
df <- cal_input_df %>% filter(condition=="glucoseaa")

ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(.term1+.term2+.term3)
}

g <- seq(0,20,by=0.01)
ll <- lapply(g,ll_calibration)
plot(g,ll)

m_ll_calibration <- function(.gamma){
  .wp <- 1/(df$sigma_well**2+(.gamma**2)*df$sigma_gr**2)
  .a <- sum(.wp*(df$delta_well-.gamma*df$delta_gr))/(sum(.wp))
  .term1 <- 1/2*(sum(log(.wp)))
  .term2 <- -1/2*log(sum(.wp))
  .term3 <- -1/2*sum(.wp*(df$delta_well-.gamma*df$delta_gr-.a)**2)
  return(-(.term1+.term2+.term3))
}

nloptr::cobyla(x0=1,m_ll_calibration)
```

So that's it! We have the optimal values. Now time to look at the concentrations!
Let's write a proper function to check that out.








```{r}
# Searching the maximum of the log likelihood.
dichotomic_search_for_max_ll <- function(){
  p <- length(.div_time) #number of observations
  .doubling_time <- .div_time # As a doubling times I am using first, the div times.
  .gr <- log(2)/mean(.div_time,na.rm=TRUE) # As a first approximation for the population exponential growth rate, I am using mean(log(2)/.div_time), but I could also use .gr <- mean(alpha). 
  .approx_inf <- 1/2*mean(.gr,na.rm=TRUE) #low initial value
  .approx_sup <- 3*mean(.gr,na.rm=TRUE) #high initial value
  .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2 #Corresponding the function value
  .delta_sup <- sum(exp(-.approx_sup*.doubling_time))-p/2 #Corresponding the function value
  while(.delta_inf<0){
  .approx_inf <- 1/2*.approx_inf
  .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2} #This value should be POSITIVE to start with
  while(.delta_sup>0){
  .approx_sup <- 2*.approx_sup
  .delta_sup <- sum(exp(-.approx_sup*.doubling_time))-p/2} #This value should be NEGATIVE to start with
  # Simple dichotomic search for root
  .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf #New growth rate value
  .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2 #New function value
  while((.approx_sup-.approx_inf)>0.00000001){ #Search should stop when difference between .approx_sup and .approx_inf becomes too small
    #print(.approx_sup)
    #print(.approx_inf)
    if(.delta_new<0){ # If function is negative, the intermediate value becomes the upper value, a new intermediate value is computed.
      .approx_sup <- .approx_new
      .delta_sup <- .delta_new
      .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
      .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2}
    else{ # Otherwise, the intermediate value becomes the inf value. New intermediate is computed.
      .approx_inf <- .approx_new
      .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2
      .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
      .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2}}
  #print(c(.approx_inf,.delta_inf,.approx_sup,.delta_sup))
  return(rep(c(.approx_sup+.approx_inf)/2,times=p))
}





```







```{r}
myconcentrations_condition <- mycells %>% 
  distinct(condition,strain,mean_concentration_condition,sd_concentration_condition)

#Set strains to select for the comparison, for which I have data both in mother machine and spectro.
selected_strains_df <- mycells %>% 
  distinct(strain,condition)

library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(15, "Set1"))(nb.cols)

mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)

mydata_gr_exp_summary %>%
  filter(replica==1) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)

# Error bar on the fit

fit_result <- mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  mutate(slope=fit_exp_elongation_slope(log(mean_concentration_condition),alpha_gfp),
         sd_slope=fit_exp_elongation_sd_slope(log(mean_concentration_condition),alpha_gfp)) %>% 
  select(slope,sd_slope) %>% 
  filter(row_number()==1)
#slope = 0.889
#sd=0.0252
# Which means at best, a slope of 0.9

fit_result <- mydata_gr_exp_summary %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  group_by(condition) %>% 
  mutate(slope=fit_exp_elongation_slope(log(mean_concentration_condition),alpha_gfp),
         sd_slope=fit_exp_elongation_sd_slope(log(mean_concentration_condition),alpha_gfp)) %>% 
  select(slope,sd_slope) %>% 
  filter(row_number()==1) %>% 
  ungroup()

fit_result

nb.cols <- 4
mycolors <- colorRampPalette(brewer.pal(4, "Set1"))(nb.cols)

mydata_gr_exp_summary  %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=condition),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_gfp+sd_alpha_gfp)),alpha=.5)+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)),alpha=.5)+
  geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  #facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)

nb.cols <- 4
mycolors <- colorRampPalette(brewer.pal(4, "Set1"))(nb.cols)

mydata_gr_exp_summary  %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(mean_concentration_condition,alpha_gfp,col=condition),size=3)+
  geom_errorbar(aes(x=mean_concentration_condition,ymin=alpha_gfp-sd_alpha_gfp,ymax=alpha_gfp+sd_alpha_gfp),alpha=.5)+
  geom_errorbar(aes(y=alpha_gfp,xmin=mean_concentration_condition-sd_concentration_condition,xmax=mean_concentration_condition+sd_concentration_condition),alpha=.5)+
  geom_smooth(aes(mean_concentration_condition,alpha_gfp),method="lm") +
  stat_regline_equation(aes(mean_concentration_condition,alpha_gfp))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)

mydata_gr_exp_summary  %>%
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(mean_concentration_condition,alpha_gfp,col=condition),size=3)+
  geom_errorbar(aes(x=mean_concentration_condition,ymin=alpha_gfp-sd_alpha_gfp,ymax=alpha_gfp+sd_alpha_gfp),alpha=.5)+
  geom_errorbar(aes(y=alpha_gfp,xmin=mean_concentration_condition-sd_concentration_condition,xmax=mean_concentration_condition+sd_concentration_condition),alpha=.5)+
  geom_smooth(aes(mean_concentration_condition,alpha_gfp),method="lm") +
  stat_regline_equation(aes(mean_concentration_condition,alpha_gfp))+
  facet_wrap(~condition,scale="free")+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)
```


```{r}
#Computing correctly the slope.
#Write a function to do that properly, taking into account the uncertainty both in x and y





```



```{r}
nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(15, "Set1"))(nb.cols)

mydata_gr_exp_summary %>%
  filter(replica==2) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)
```

```{r}
# Enforce correct computation of the slope

nb.cols <- 15
mycolors <- colorRampPalette(brewer.pal(15, "Set1"))(nb.cols)

mydata_gr_exp_summary %>%
  #filter(replica==7) %>% 
  semi_join(selected_strains_df,by=c("strain","condition")) %>% 
  filter(log(well_gr)>-2) %>% 
  left_join(myconcentrations_condition,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_condition),log(alpha_gfp),col=strain),size=3)+
  geom_errorbar(aes(x=log(mean_concentration_condition),ymin=log(alpha_gfp-sd_alpha_gfp),ymax=log(alpha_tot+sd_alpha_gfp)))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log(mean_concentration_condition-sd_concentration_condition),xmax=log(mean_concentration_condition+sd_concentration_condition)))+
  geom_smooth(aes(log(mean_concentration_condition),log(alpha_gfp)),method="lm") +
  stat_regline_equation(aes(log(mean_concentration_condition),log(alpha_gfp)))+
  facet_wrap(~condition)+
  #theme_cowplot()+
  scale_color_manual(values = mycolors)
```


Let's calibrate it now, per condition.
Optimizing for gamma?
First problem: the relationship between my data and the experiment outcome does not seem to be one.
Let see if I can do something, nevertheless.

Erk's notes gave me a pretty complicated equation.
Once I have these values, I can get the corresponding concentration. The best estimate let's say.
Some replicates are doing better than others in that regard.
I could probably discard them.








# COMPUTING PSEUDO BULK GROWTH RATE FROM MOTHER MACHINE DATA AND ALPHA SEEM TO GIVE WRONG RESULTS

Two solutions: either I simply fit my distribution of doubling times to a gamma distribution, and I get two parameters.
Or, I numerically solve $\sum^{n}_{i=1}e^{-\lambda t_i}=\frac{n}{2}$.
This should be easy to solve, cause we look for $\sum^{n}_{i=1}e^{-\lambda t_i}-\frac{n}{2}$ a decreasing function of $\lambda$.
So I should be able to find it by dichotomy. We assume that the population growth rate is actually larger. Then, for an approximation chosen as mean of all growth rate the result should be negative. Is it the case?
And as a larger bound, we can take 2x this approximation.

```{r}
dichotomic_search_growth_rate <- function(.alpha){
  p <- length(.alpha) #number of observations
  .doubling_time <- log(2)/.alpha #s-1
  .gr <- .alpha
  .approx_inf <- 1/2*mean(.gr,na.rm=TRUE)
  .approx_sup <- 3*mean(.gr,na.rm=TRUE)
  .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2
  .delta_sup <- sum(exp(-.approx_sup*.doubling_time))-p/2
  while(.delta_inf<0){
  .approx_inf <- 1/2*.approx_inf
  .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2}
  while(.delta_sup>0){
  .approx_sup <- 2*.approx_sup
  .delta_sup <- sum(exp(-.approx_sup*.doubling_time))-p/2}
  #print(c(.approx_inf,.delta_inf,.approx_sup,.delta_sup))
  print(.approx_inf*3600/log(2))
  print(.approx_sup*3600/log(2))
  .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
  .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2
  while((.approx_sup-.approx_inf)>0.00000001){
    if(.delta_new<0){
      .approx_sup <- .approx_new
      .delta_sup <- .delta_new
      .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
      .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2}
    else{
      .approx_inf <- .approx_new
      .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2
      .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
      .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2}}
  #print(c(.approx_inf,.delta_inf,.approx_sup,.delta_sup))
  return(rep(c(.approx_sup+.approx_inf)/2,times=p))
}
```

```{r}
## DEBUG
.input <- mycells %>% 
  filter(condition=="glycerol") %>% 
  .$alpha
print(mean(.input)*3600/log(2))
result <- unique(dichotomic_search_growth_rate(.input))*3600/log(2)
print(result)
compute_exp_sum <- function(.l){
  doubling_time <- log(2)/.input
  .gr <- .l*log(2)/3600
  return(sum(exp(-.gr*doubling_time))-length(.input)/2)}
.x <- seq(from = 0.1, to = 2, by = 0.01)
.y <- lapply(.x,compute_exp_sum)

plot(.x,.y)+
  abline(h=0)+
  abline(v=(mean(.input)*3600/log(2)))
```

```{r}
## DEBUG
.input <- mycells %>% 
  filter(condition=="acetate") %>% 
  .$alpha
print(mean(.input)*3600/log(2))
result <- unique(dichotomic_search_growth_rate(.input))*3600/log(2)
print(result)
compute_exp_sum <- function(.l){
  doubling_time <- log(2)/.input
  .gr <- .l*log(2)/3600
  return(sum(exp(-.gr*doubling_time))-length(.input)/2)}
.x <- seq(from = 0.1, to = 2, by = 0.01)
.y <- lapply(.x,compute_exp_sum)

plot(.x,.y)+
  abline(h=0)+
  abline(v=(mean(.input)*3600/log(2)))
```

```{r}
## DEBUG
.input <- mycells %>% 
  filter(condition=="glucose") %>% 
  .$alpha
print(mean(.input)*3600/log(2))
result <- unique(dichotomic_search_growth_rate(.input))*3600/log(2)
print(result)
compute_exp_sum <- function(.l){
  doubling_time <- log(2)/.input
  .gr <- .l*log(2)/3600
  return(sum(exp(-.gr*doubling_time))-length(.input)/2)}
.x <- seq(from = 0.1, to = 2, by = 0.01)
.y <- lapply(.x,compute_exp_sum)

plot(.x,.y)+
  abline(h=0)+
  abline(v=(mean(.input)*3600/log(2)))
```

```{r}
## DEBUG
.input <- mycells %>% 
  filter(condition=="glucoseaa") %>% 
  .$alpha
print(mean(.input)*3600/log(2))
result <- unique(dichotomic_search_growth_rate(.input))*3600/log(2)
print(result)
compute_exp_sum <- function(.l){
  doubling_time <- log(2)/.input
  .gr <- .l*log(2)/3600
  return(sum(exp(-.gr*doubling_time))-length(.input)/2)}
.x <- seq(from = 0.1, to = 3, by = 0.01)
.y <- lapply(.x,compute_exp_sum)

plot(.x,.y)+
  abline(h=0)+
  abline(v=(mean(.input)*3600/log(2)))
```
# TRY NOW WITH GENERATION TIME?

```{r}
dichotomic_search_growth_rate <- function(.div_time){
  p <- length(.div_time) #number of observations
  .doubling_time <- .div_time #s
  .gr <- .m_alpha
  .approx_inf <- 1/2*mean(.gr,na.rm=TRUE)
  .approx_sup <- 3*mean(.gr,na.rm=TRUE)
  .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2
  .delta_sup <- sum(exp(-.approx_sup*.doubling_time))-p/2
  while(.delta_inf<0){
  .approx_inf <- 1/2*.approx_inf
  .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2}
  while(.delta_sup>0){
  .approx_sup <- 2*.approx_sup
  .delta_sup <- sum(exp(-.approx_sup*.doubling_time))-p/2}
  #print(c(.approx_inf,.delta_inf,.approx_sup,.delta_sup))
  #print(.approx_inf*3600/log(2))
  #print(.approx_sup*3600/log(2))
  .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
  .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2
  while((.approx_sup-.approx_inf)>0.00000001){
    if(.delta_new<0){
      .approx_sup <- .approx_new
      .delta_sup <- .delta_new
      .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
      .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2}
    else{
      .approx_inf <- .approx_new
      .delta_inf <- sum(exp(-.approx_inf*.doubling_time))-p/2
      .approx_new <- 1/2*(.approx_sup-.approx_inf)+.approx_inf
      .delta_new <- sum(exp(-.approx_new*.doubling_time))-p/2}}
  #print(c(.approx_inf,.delta_inf,.approx_sup,.delta_sup))
  return(rep(c(.approx_sup+.approx_inf)/2,times=p))
}

```

```{r}
## DEBUG
.input <- mycells %>% 
  filter(condition=="acetate") %>% 
  .$div_time

.m_alpha <- mycells %>% 
  filter(condition=="acetate") %>% 
  .$alpha %>% 
  mean()

result <- unique(dichotomic_search_growth_rate(.input))*3600/log(2)
print(result)
print(.m_alpha*3600/log(2))

print(1/result)
print(mean(.input)/3600)
```

Now wondering... what are alpha inference and div_time giving me? 
```{r}
# Predicting population growth rate based on distribution of generation time

## DEBUG
.input <- mycells %>% 
  filter(condition=="acetate") %>% 
  .$div_time

mean(.input)/3600
#Mean generation time of 4.8
#Which gives an exponential growth rate of
mean(.input)/3600/log(2)

.m_alpha <- mycells %>% 
  filter(condition=="acetate") %>% 
  .$alpha %>% 
  mean()

1/(.m_alpha*3600/log(2))
# Gives a totally different generation time now...

result <- unique(dichotomic_search_growth_rate(.input))*3600/log(2)
print(result)
print(.m_alpha*3600/log(2))

print(1/result)
print(mean(.input)/3600)
```


```{r}
## DEBUG
.input <- mycells %>% 
  filter(condition=="glycerol") %>% 
  .$div_time

.m_alpha <- mycells %>% 
  filter(condition=="glycerol") %>% 
  .$alpha %>% 
  mean()

print(mean(.input)/3600)

result <- unique(dichotomic_search_growth_rate(.input))*3600/log(2)
print(result)
print(.m_alpha*3600/log(2))

print(1/result)
print(mean(.input)/3600)
```




The relative changes in terms of growth rate are not that huge... I was expecting to get higher values but, actually I am even getting smaller values too, which are quite unexpected. Due to systematic differences?

```{r}
myalphas <- mycells %>% 
  group_by(condition) %>% 
  mutate(corrected_alpha=dichotomic_search_growth_rate(alpha)*3600/log(2)) %>% 
  mutate(mean_alpha=mean(alpha*3600/log(2),na.rm=TRUE)) %>% 
  mutate(sd_all_alpha=sd(alpha,na.rm=TRUE)) %>% 
  ungroup() %>% 
  distinct(condition,mean_alpha,corrected_alpha,sd_all_alpha)

myalphas_sc <- mycells %>% 
  distinct(condition,cell,alpha_vol,se_alpha_vol) #COMPUTE SE_ALPHA_VOL

myconcentrations <- myframes_to_mycells %>% 
  group_by(condition,promoter,vector) %>% 
  mutate(mean_concentration_volume=mean(concentration_volume,na.rm=TRUE)) %>% 
  ungroup() %>% 
  distinct(condition,promoter,vector,.keep_all = TRUE) %>% 
  select(condition,promoter,vector,mean_concentration_volume,strain)

myconcentrations_sc <- myframes_to_mycells %>% 
  group_by(condition,promoter,vector,cell) %>% 
  mutate(mean_concentration_volume=mean(concentration_volume,na.rm=TRUE)) %>% 
  ungroup() %>% 
  distinct(condition,promoter,vector,cell,.keep_all = TRUE) %>% 
  select(condition,promoter,vector,mean_concentration_volume,strain,cell)
```

# LOADING PACKAGES AND FUNCTIONS

```{r message=FALSE, warning=FALSE}
source("./code/load_packages_functions.R")
source("./code/modeling_functions.R")
source("./code/inference_functions.R")
```

# IMPORTING DATA FROM BULK EXPERIMENTS

```{r message=FALSE, warning=FALSE}
path_to_data_list <- "./dataList.csv"
source("./code/import_data.R")

mydata <- mydata %>% 
  mutate(valid=NA) %>% 
  mutate(well=paste(plate,row,column,strain,sep="_"))

mean_blank_od <- 0.03840125 #Determined in a previous experiment where we looked ad OD of empty wells for entire plates
mydata <- mydata %>% 
  mutate(corrected_od=od-mean_blank_od)

mean_blank_fluo <- 35.3075 #Idem
mydata <- mydata %>% 
  mutate(corrected_fluo=fluo-mean_blank_fluo) %>% 
  filter(!grepl("H_7",well)) #Discarding this well which was problematic anyway

mydata_bad <- readr::read_csv("./manualCuration.csv") #Wells with obviously wrong results (cells not growing, or outliers)
mydata <- mydata %>% 
  mutate(rowcol=paste(row,column,sep=""))

replica_df <- tibble(description=c("20210312constitexpr3.0","20210316constitexpr3.1","20210204Testrun2"),replica=c(2,3,1))
promoters_of_interest <- list("hi1","hi3","med2","med3","rpsB","rpmB","rplN","rrnB")

mydata_curated <-mydata %>% 
  anti_join(mydata_bad,by=c("description","plate","rowcol")) %>% 
  left_join(replica_df,by=c("description")) %>% 
  mutate(well_rep=paste(well,replica,sep="-"))

mydata_curated <- rbind(
  mydata_curated %>% 
    filter((strain %in% c("MG1655","empty"))) %>% 
    mutate(promoter="nopromoter") %>% 
    mutate(vector="novector"),
  
  mydata_curated %>% 
    filter(!(strain %in% c("MG1655","empty"))) %>% 
    group_by(strain) %>% 
    mutate(prom_part1=stringr::str_split(strain,"-")[[1]][[1]],
         prom_part2=stringr::str_split(strain,"-")[[1]][[2]]) %>% 
  mutate(promoter=ifelse(prom_part2 %in% promoters_of_interest,prom_part2,paste(prom_part1,prom_part2,sep=""))) %>% 
  mutate(vector=ifelse(prom_part2 %in% promoters_of_interest,prom_part1,"pl")) %>%
  select(-c(prom_part1,prom_part2,strain)) %>% 
  mutate(strain=paste(vector,promoter,sep="-")) %>% 
    ungroup())
```

# INFERRING SLOPES AND INTERCEPT OF FLUO VS OD

We have defined arbitrarily corrected OD ranges where we fit a linear model (two parameters, slope: $\alpha_{tot}$ and intercept" $\beta$). $\alpha_{tot}$ takes into account the contribution of both GFP and autofluorescence.

```{r}
od_range_df <- tibble(condition=c("acetate","glycerol","glucose","glucoseaa"),
                      min_corrected_od=c(0.05,0.05,0.05,0.05),
                      max_corrected_od=c(0.15,0.2,0.4,0.6))
```

Different wells are characterized by different promoter strength, high ("hi") and medium ("med").

```{r}
hi_or_med_p2 <- tibble(plate=rep(c("pl1","pl3","pl5","pl7"),each=6),strength=rep(rep(c("med","hi"),each=3),times=4),column=rep(c(7,8,9,10,11,12),times=4))
hi_or_med_p3 <- tibble(plate=rep(c("pl2","pl4","pl6","pl8"),each=12),strength=rep(rep(c("med","hi"),each=3),times=8),column=rep(c(1,2,3,4,5,6,7,8,9,10,11,12),times=4))
hi_or_med <- rbind(hi_or_med_p2,hi_or_med_p3)
```

Inferring slopes and intercepts. Output: data_frame with condition,strain (id est, promoter and vector), replica, well, alpha_tot, sd_alpha, beta, strength. One line per well.

```{r}
#conversion_table <- tibble(condition=c("acetate","glycerol","glucose","glucoseaa"),cell_ul_od=c(3557293,3672777,2454829,2241553))

#well_vol <- 200

gr_df_sc <- mycells %>% 
  distinct(cell,alpha_vol,l_birth, w_birth,l_div,w_div)

cell_vol_df <- myframes_to_mycells %>% 
  group_by(condition) %>% 
  mutate(mean_vol=mean(volume_um,na.rm=TRUE)) %>% 
  ungroup() %>% 
  distinct(condition,mean_vol) %>% 
  arrange(mean_vol)

mycells %>%
  #left_join(gr_df_sc,by=c("cell"))
  ggplot()+
  geom_point(aes(log(alpha_vol*3600/log(2)),log(dv),col=condition),alpha=.1)+
  theme_cowplot()+
  xlab("log(growth-rate)")+
  ylab("log(dv)")

mycells %>%
  #left_join(gr_df_sc,by=c("cell"))
  ggplot()+
  geom_point(aes(alpha_vol*3600/log(2),dv,col=condition),alpha=0.1)+
  theme_cowplot()+
  xlab("log(growth-rate)")+
  ylab("log(dv)")

mycells %>%
  #left_join(gr_df_sc,by=c("cell"))
  ggplot()+
  geom_point(aes(log(alpha_vol*3600/log(2)),log(volume_birth),col=condition),alpha=0.1)+
  geom_point(aes(log(alpha_vol*3600/log(2)),log(volume_div),col=condition),alpha=0.1)+
  theme_cowplot()+
  xlab("log(growth-rate)")+
  ylab("log(volume at birth and division)")
```


```{r}
mydata_summary_od <- mydata_curated %>% 
    ungroup() %>%
    left_join(hi_or_med,by=c("plate","column")) %>% 
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>%
    group_by(description,well) %>%
    mutate(p=n(),
           mean_od=mean(corrected_od),
           var_od=1/p*sum((corrected_od-mean_od)**2),
           mean_fluo=mean(fluo),
           var_fluo=1/p*sum((fluo-mean_fluo)**2),
           covar_od_fluo=1/p*sum(corrected_od*fluo-mean_od*mean_fluo),
           alpha_tot=(var_fluo-var_od)/(2*covar_od_fluo)+sqrt(1+((var_fluo-var_od)/(2*covar_od_fluo))**2),#assuming that this is the best slope
           sd_alpha=compute_error(alpha_tot,var_od,var_fluo,covar_od_fluo),
           beta=1/p*sum(fluo-alpha_tot*corrected_od))%>%
    ungroup() %>% 
    distinct(strain, replica, well,.keep_all=TRUE) %>% 
  select(condition,strain,replica,well,alpha_tot,sd_alpha,beta,strength,plate)

```

# TO KEEP FOR LATER
```{r}

mydata_summary_cell_vol <- mydata_curated %>% 
    ungroup() %>%
    left_join(hi_or_med,by=c("plate","column")) %>% 
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    #Here adding the conversion table for num of cells
    left_join(conversion_table,by=c("condition")) %>% 
    left_join(cell_vol_df,by=c("condition")) %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>%
    #Computing c: cell number
    mutate(cell_nb=cell_ul_od*corrected_od*well_vol*mean_vol) %>% 
    #mutate(biomass=cell_ul_od*corrected_od*well_vol*mean_vol)
    group_by(description,well) %>%
    mutate(p=n(),
           mean_cell_nb=mean(cell_nb),
           var_cell_nb=1/p*sum((cell_nb-mean_cell_nb)**2),
           mean_fluo=mean(fluo),
           var_fluo=1/p*sum((fluo-mean_fluo)**2),
           covar_cell_nb_fluo=1/p*sum(cell_nb*fluo-mean_cell_nb*mean_fluo),
           alpha_tot=(var_fluo-var_cell_nb)/(2*covar_cell_nb_fluo)+sqrt(1+((var_fluo-var_cell_nb)/(2*covar_cell_nb_fluo))**2),#assuming that this is the best slope
           sd_alpha=compute_error(alpha_tot,var_cell_nb,var_fluo,covar_cell_nb_fluo),
           beta=1/p*sum(fluo-alpha_tot*cell_nb))%>%
  
    ungroup() %>% 
    distinct(strain, replica, well,.keep_all=TRUE) %>% 
  select(condition,strain,replica,well,alpha_tot,sd_alpha,beta,strength)

mydata_summary_cell_nb <- mydata_curated %>% 
    ungroup() %>%
    left_join(hi_or_med,by=c("plate","column")) %>% 
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    #Here adding the conversion table for num of cells
    left_join(conversion_table,by=c("condition")) %>% 
    left_join(cell_vol_df,by=c("condition")) %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>%
    #Computing c: cell number
    mutate(cell_nb=cell_ul_od*corrected_od*well_vol) %>% 
    #mutate(biomass=cell_ul_od*corrected_od*well_vol*mean_vol)
    group_by(description,well) %>%
    mutate(p=n(),
           mean_cell_nb=mean(cell_nb),
           var_cell_nb=1/p*sum((cell_nb-mean_cell_nb)**2),
           mean_fluo=mean(fluo),
           var_fluo=1/p*sum((fluo-mean_fluo)**2),
           covar_cell_nb_fluo=1/p*sum(cell_nb*fluo-mean_cell_nb*mean_fluo),
           alpha_tot=(var_fluo-var_cell_nb)/(2*covar_cell_nb_fluo)+sqrt(1+((var_fluo-var_cell_nb)/(2*covar_cell_nb_fluo))**2),#assuming that this is the best slope
           sd_alpha=compute_error(alpha_tot,var_cell_nb,var_fluo,covar_cell_nb_fluo),
           beta=1/p*sum(fluo-alpha_tot*cell_nb))%>%
  
    ungroup() %>% 
    distinct(strain, replica, well,.keep_all=TRUE) %>% 
  select(condition,strain,replica,well,alpha_tot,sd_alpha,beta,strength)

```

# COMPUTING GROWTH-RATES IN SINGLE WELLS

Here I fit log(corrected_od) vs time_min.
I am considering here that there is measurement noise only according in the y axis.

```{r}
mydata_growthrates_summary <- mydata_curated %>% 
    ungroup() %>%
    left_join(hi_or_med,by=c("plate","column")) %>% 
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>%
    group_by(description,well) %>%
    mutate(p=n(),
             mean_time=mean(time_min),
             var_time=1/p*sum((time_min-mean_time)**2),
             mean_l_cod=mean(log(corrected_od),na.rm=TRUE),
             var_l_cod=1/p*sum((log(corrected_od)-mean_l_cod)**2,na.rm=TRUE),
             covar_l_cod_time=1/p*sum(time_min*log(corrected_od)-mean_l_cod*mean_time),
             alpha_tot=covar_l_cod_time/var_time,
             sd_alpha=compute_error(alpha_tot,var_time,var_l_cod,covar_l_cod_time),
             beta=1/p*sum(log(corrected_od)-alpha_tot*time_min,na.rm=TRUE))%>%
    
      ungroup() %>% 
      distinct(strain, replica, well,.keep_all=TRUE) %>% 
    select(condition,strain,replica,well,alpha_tot,sd_alpha,beta,strength,plate)
```

```{r}
mydata_growthrates_summary %>% 
  distinct(condition,replica,well,.keep_all = TRUE) %>% 
  group_by(condition,replica) %>% 
  mutate(p=n()) %>% 
  mutate(mean_doubling=mean(alpha_tot,na.rm=TRUE)*60/log(2)) %>% 
  #mutate(sd_doubling=sqrt(1/p*sum(sd_alpha**2,na.rm=TRUE))) %>% 
  mutate(sd_doubling=sd(alpha_tot,na.rm=TRUE)*60/log(2)) %>% 
  ungroup() %>% 
  distinct(condition,replica,.keep_all = TRUE) %>% 
  select(condition,replica,mean_doubling,sd_doubling) %>% 
  arrange(condition,replica)

```


```{r}
mydata_growthrates_summary %>% 
  distinct(condition,replica,well,.keep_all = TRUE) %>% 
  group_by(condition,replica) %>% 
  mutate(p=n()) %>% 
  mutate(mean_doubling=mean(alpha_tot,na.rm=TRUE)*60/log(2)) %>% 
  #mutate(sd_doubling=sqrt(1/p*sum(sd_alpha**2,na.rm=TRUE))) %>% 
  mutate(sd_doubling=sd(alpha_tot,na.rm=TRUE)*60/log(2)) %>% 
  ungroup() %>% 
  distinct(condition,replica,.keep_all = TRUE) %>% 
  select(condition,replica,mean_doubling,sd_doubling) %>% 
  arrange(condition,replica)

```

In spite of day to day variations, growth rates are consistent with mother machine data.

# OD: AUTOFLUORESCENCE VERSUS GROWTH RATE

```{r}
mydata_summary_od$replica <- factor(mydata_summary_od$replica,levels = c(1,2,3))
mydata_growthrates_summary$replica <- factor(mydata_growthrates_summary$replica,levels = c(1,2,3))

mydata_curated_cond_for_plot <- mydata_summary_od %>% 
  distinct(replica,condition,well,alpha_tot,sd_alpha,strain,plate) %>% 
  rename(alpha_tot=alpha_tot,
         sd_alpha_exp=sd_alpha)

mydata_curated_gr_for_plot <- mydata_growthrates_summary %>% 
  distinct(replica,condition,well,alpha_tot,sd_alpha,strain,plate) %>% 
  rename(alpha_tot_gr=alpha_tot,
         sd_alpha_gr=sd_alpha)

conditions <- c("acetate","glycerol","glucose","glucoseaa")

for(c in conditions){print(
mydata_gr_autofluo <- left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain","plate")) %>% 
  filter(strain=="MG1655") %>% 
  filter(condition==c) %>% 
  ggplot()+
  geom_point(aes(alpha_tot_gr*60/log(2),alpha_tot,col=replica))+
  geom_errorbar(aes(x=alpha_tot_gr*60/log(2),ymax=alpha_tot+sd_alpha_exp,ymin=alpha_tot-sd_alpha_exp,col=replica))+
  geom_errorbar(aes(y=alpha_tot,xmin=(alpha_tot_gr-sd_alpha_gr)*60/log(2),xmax=(alpha_tot_gr+sd_alpha_gr)*60/log(2),col=replica))+
  labs(subtitle=c)+
  theme_cowplot()
)}

left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain")) %>% 
  filter(strain=="MG1655") %>% 
  #filter(condition==c) %>% 
  ggplot()+
  geom_point(aes(alpha_tot_gr*60/log(2),alpha_tot,col=replica))+
  geom_errorbar(aes(x=alpha_tot_gr*60/log(2),ymax=alpha_tot+sd_alpha_exp,ymin=alpha_tot-sd_alpha_exp,col=replica))+
  geom_errorbar(aes(y=alpha_tot,xmin=(alpha_tot_gr-sd_alpha_gr)*60/log(2),xmax=(alpha_tot_gr+sd_alpha_gr)*60/log(2),col=replica))+
  labs(subtitle="all")+
  theme_cowplot()+
  xlab("Doublings per hour")+
  ylab("autofluorescence alpha")


left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain")) %>% 
  filter(strain=="MG1655") %>% 
  #filter(condition==c) %>% 
  ggplot()+
  geom_point(aes(log(alpha_tot_gr*60/log(2)),log(alpha_tot),col=replica))+
  geom_errorbar(aes(x=log(alpha_tot_gr*60/log(2)),ymax=log(alpha_tot+sd_alpha_exp),ymin=log(alpha_tot-sd_alpha_exp),col=replica))+
  geom_errorbar(aes(y=log(alpha_tot),xmin=log((alpha_tot_gr-sd_alpha_gr)*60/log(2)),xmax=log((alpha_tot_gr+sd_alpha_gr)*60/log(2)),col=replica))+
  labs(subtitle="all")+
  theme_cowplot()+
  xlab("log(Doublings per hour)")+
  ylab("log(autofluorescence alpha)")
```


# OD: MODELING AUTOFLUORESCENCE VERSUS GROWTH RATES

I am taking into account both noise in X and Y.
And plotting max slope and min slope results.

```{r}
left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain","plate")) %>% 
  filter(strain=="MG1655") %>% 
  mutate(l_gr=log(alpha_tot_gr*60/log(2))) %>% 
  mutate(l_exp=log(alpha_tot)) %>% 
  mutate(a=linear_mod_slope(l_exp,l_gr)) %>% 
  mutate(b=linear_mod_intercept(l_exp,l_gr)) %>%
  mutate(p=n(),
           m_l_gr=mean(l_gr),
           var_l_gr=1/p*sum((l_gr-m_l_gr)**2),
           m_l_exp=mean(l_exp),
           var_l_exp=1/p*sum((l_exp-m_l_exp)**2),
           covar_gr_exp=1/p*sum(l_gr*l_exp-m_l_gr*m_l_exp),
           slope=(var_l_exp-var_l_gr)/(2*covar_gr_exp)-sqrt(1+((var_l_exp-var_l_gr)/(2*covar_gr_exp))**2),#assuming that this is the best slope
           sd_slope=compute_error(slope,var_l_gr,var_l_exp,covar_gr_exp),
           beta=1/p*sum(l_exp-slope*l_gr),
         beta_max=1/p*sum(l_exp-(slope+sd_slope)*l_gr),
         beta_min=1/p*sum(l_exp-(slope-sd_slope)*l_gr))%>%
    ungroup() %>% 
  ggplot()+
  geom_point(aes(log(alpha_tot_gr*60/log(2)),log(alpha_tot),col=replica))+
  geom_line(aes(l_gr,l_gr*slope+beta),col="blue") +
  geom_line(aes(l_gr,l_gr*(slope+sd_slope)+beta_max),col="yellow") +
  geom_line(aes(l_gr,l_gr*(slope-sd_slope)+beta_min),col="green") +
  geom_errorbar(aes(x=log(alpha_tot_gr*60/log(2)),ymax=log(alpha_tot+sd_alpha_exp),ymin=log(alpha_tot-sd_alpha_exp),col=replica))+
  geom_errorbar(aes(y=log(alpha_tot),xmin=log((alpha_tot_gr-sd_alpha_gr)*60/log(2)),xmax=log((alpha_tot_gr+sd_alpha_gr)*60/log(2)),col=replica))+
  labs(subtitle="all")+
  theme_cowplot()+
  xlab("log(Doublings per hour)")+
  ylab("log(autofluorescence alpha)")
```

```{r}
exp_vs_gr_results_df <- left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain","plate")) %>% filter(strain=="MG1655") %>% 
  mutate(l_gr=log(alpha_tot_gr*60/log(2))) %>% 
  mutate(l_exp=log(alpha_tot)) %>% 
  mutate(a=linear_mod_slope(l_exp,l_gr)) %>% 
  mutate(b=linear_mod_intercept(l_exp,l_gr)) %>%
  mutate(p=n(),
           m_l_gr=mean(l_gr),
           var_l_gr=1/p*sum((l_gr-m_l_gr)**2),
           m_l_exp=mean(l_exp),
           var_l_exp=1/p*sum((l_exp-m_l_exp)**2),
           covar_gr_exp=1/p*sum(l_gr*l_exp-m_l_gr*m_l_exp),
           slope=(var_l_exp-var_l_gr)/(2*covar_gr_exp)-sqrt(1+((var_l_exp-var_l_gr)/(2*covar_gr_exp))**2),#assuming that this is the best slope
           sd_slope=compute_error(slope,var_l_gr,var_l_exp,covar_gr_exp),
           beta=1/p*sum(l_exp-slope*l_gr),
         beta_max=1/p*sum(l_exp-(slope+sd_slope)*l_gr),
         beta_min=1/p*sum(l_exp-(slope-sd_slope)*l_gr))%>%
    ungroup() %>% 
  filter(row_number()==1) %>% 
  select(slope,sd_slope,beta,beta_min,beta_max)

exp_vs_gr_results_df
```

So the slope is very clearly very close to 1. With 20% uncertainty. What I am a bit skeptical about, is that, where I have a lot of noise is also relatively close to the center of mass (glycerol and glucose), and that's also where I have the least error it seems.
Intuitively I do not like that much. But for sake of simplicity, I will simply go forward. I guess I could consider the maximum error I am seeing at the ends of my relationship as conservative hypothesis regarding the uncertainty.

# OD: COMPUTING RELEVANT QUANTITIES TO COMPUTE THE AUTOFLUORESCENCE IN DIFFERENT WELLS

Using Erik's notes, section 4., I should compute:
- mean of log(autofluorescence) and log(exponential growth rates)
- standard deviation of log(autofluorescence) and log(exponential growth rate)
- covariance of log(autofluorescence) and log(exponential growth rate)

```{r}
exp_vs_gr_results_df <- left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain","plate")) %>% filter(strain=="MG1655") %>% 
  mutate(l_gr=log(alpha_tot_gr*60/log(2))) %>% #here growth rate is in doublings per hour, which is more intuitive
  mutate(l_exp=log(alpha_tot)) %>% 
  drop_na() %>% 
  mutate(p=n(),
         m_l_gr=mean(l_gr,na.rm=TRUE),
         m_l_exp=mean(l_exp,na.rm=TRUE),
         var_l_gr=var(l_gr,na.rm=TRUE),
         var_l_exp=var(l_exp,na.rm=TRUE),
         cov_l_gr_l_exp=1/p*sum(l_exp*l_gr-m_l_gr*m_l_exp,na.rm=TRUE)) %>% 
  filter(row_number()==1) %>% 
  select(m_l_gr,m_l_exp,var_l_gr,var_l_exp,cov_l_gr_l_exp,p)

exp_vs_gr_results_df
```
# OD: SUBSTRACTING AUTOFLUORESCENCE AND COMPUTING GFP CONTRIBUTION, FOLLOWING ERIK'S NOTES

```{r}
mydata_gr_exp_summary <- left_join(mydata_curated_cond_for_plot,mydata_curated_gr_for_plot ,by=c("replica","condition","well","strain","plate")) %>%
  filter(!(strain %in% c("MG1655","empty"))) %>% 
  mutate(l_x=log(alpha_tot_gr*60/log(2)),
         var_l_x=((sd_alpha_gr*60/log(2))**2)/((alpha_tot_gr*60/log(2))**2)) %>% #here growth rate is in doublings per hour, which is more intuitive
  #mutate(l_exp=log(alpha_tot)) %>% 
  mutate(m_l_gr=unique(exp_vs_gr_results_df$m_l_gr),
         var_l_gr=unique(exp_vs_gr_results_df$var_l_gr),
         m_l_exp=unique(exp_vs_gr_results_df$m_l_exp),
         var_l_exp=unique(exp_vs_gr_results_df$var_l_exp),
         cov_l_gr_l_exp=unique(exp_vs_gr_results_df$cov_l_gr_l_exp),
         p=unique(exp_vs_gr_results_df$p)) %>% 
  mutate(l_y=m_l_exp+cov_l_gr_l_exp/(var_l_gr)*(l_x-m_l_gr),
         r=cov_l_gr_l_exp/(sqrt(var_l_gr*var_l_exp)),
         var_l_y=var_l_x*(cov_l_gr_l_exp**2/(var_l_gr**2))+var_l_exp*(1-r**2)*(1+(var_l_x+(l_x-m_l_gr)**2)/p))
```

# CHECKING THE AUTOFLUORESCENCE FIT

```{r}
mydata_gr_exp_summary %>% 
  mutate(sd_l_y=sqrt(var_l_y)) %>% 
  mutate(sd_l_x=sqrt(var_l_x)) %>% 
  filter(l_x>-2) %>% 
  #filter(sd_l_x<1) %>% 
 ggplot()+
  geom_point(aes(l_x,l_y,col=condition))+
  #geom_line(aes(l_gr,l_gr*slope+beta),col="blue") +
  #geom_line(aes(l_gr,l_gr*(slope+sd_slope)+beta_max),col="yellow") +
  #geom_line(aes(l_gr,l_gr*(slope-sd_slope)+beta_min),col="green") +
  geom_errorbar(aes(x=l_x,ymax=l_y+sd_l_y,ymin=l_y-sd_l_y,col=condition))+
  geom_errorbar(aes(y=l_y,xmin=l_x-sd_l_x,xmax=l_x+sd_l_x,col=condition))+
  #labs(subtitle="all")+
  #theme_cowplot()+
  xlab("log(Doublings per hour)")+
  ylab("log(autofluorescence alpha)")+
  theme_cowplot()
```
I will add another filter on the current data to get rid of the outliers...
Now I can substract the autofluorescence value and propagate the error on the gfp contribution.

```{r}
mydata_gr_exp_summary<- mydata_gr_exp_summary %>%
  mutate(alpha_gfp=alpha_tot-exp(l_y),
         sd_alpha_autofluo=sqrt(l_y**2*var_l_y),
         sd_alpha_gfp=sqrt(sd_alpha_autofluo**2+sd_alpha_exp**2))
```
# OD: NOW PLOT ALL PROMOTERS: ALPHA_GFP VERSUS GROWTH RATE

```{r}
mydata_gr_exp_summary %>%
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
 ggplot()+
  geom_point(aes(log(alpha_tot_gr*60/log(2)),log(alpha_gfp),col=condition))+
  #geom_line(aes(l_gr,l_gr*slope+beta),col="blue") +
  #geom_line(aes(l_gr,l_gr*(slope+sd_slope)+beta_max),col="yellow") +
  #geom_line(aes(l_gr,l_gr*(slope-sd_slope)+beta_min),col="green") +
  geom_errorbar(aes(x=log(alpha_tot_gr*60/log(2)),ymax=log(alpha_gfp+sd_alpha_gfp),ymin=log(alpha_gfp-sd_alpha_gfp),col=condition))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log((alpha_tot_gr-sd_alpha_gr)*60/log(2)),xmax=log((alpha_tot_gr+sd_alpha_gr)*60/log(2)),col=condition))+
  labs(subtitle="all")+
  theme_cowplot()+
  #coord_cartesian(ylim=c(-16,-8))+
  xlab("log(Doublings per hour)")+
  ylab("log(alpha gfp)")
```

Is this concentration correctly seeing what's happening for hi3 or hi1? Between glucose and glucoseaa?

```{r}
mydata_gr_exp_summary %>%
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
 ggplot()+
  geom_point(aes(log(alpha_tot_gr*60/log(2)),log(alpha_gfp),col=condition))+
  #geom_line(aes(l_gr,l_gr*slope+beta),col="blue") +
  #geom_line(aes(l_gr,l_gr*(slope+sd_slope)+beta_max),col="yellow") +
  #geom_line(aes(l_gr,l_gr*(slope-sd_slope)+beta_min),col="green") +
  geom_errorbar(aes(x=log(alpha_tot_gr*60/log(2)),ymax=log(alpha_gfp+sd_alpha_gfp),ymin=log(alpha_gfp-sd_alpha_gfp),col=condition))+
  geom_errorbar(aes(y=log(alpha_gfp),xmin=log((alpha_tot_gr-sd_alpha_gr)*60/log(2)),xmax=log((alpha_tot_gr+sd_alpha_gr)*60/log(2)),col=condition))+
  facet_wrap(~strain,scale="free")+
  labs(subtitle="all")+
  theme_cowplot()+
  #coord_cartesian(ylim=c(-16,-8))+
  xlab("log(Doublings per hour)")+
  ylab("log(alpha gfp)")
```

```{r}
mydata_gr_exp_summary %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
 ggplot()+
  geom_point(aes(log(alpha_tot_gr*60/log(2)),log(alpha_gfp),col=condition))+
  #geom_line(aes(l_gr,l_gr*slope+beta),col="blue") +
  #geom_line(aes(l_gr,l_gr*(slope+sd_slope)+beta_max),col="yellow") +
  #geom_line(aes(l_gr,l_gr*(slope-sd_slope)+beta_min),col="green") +
  #geom_errorbar(aes(x=alpha_tot_gr*60/log(2),ymax=alpha_gfp+sd_alpha_gfp,ymin=alpha_gfp-sd_alpha_gfp,col=condition))+
  #geom_errorbar(aes(y=alpha_gfp,xmin=(alpha_tot_gr-sd_alpha_gr)*60/log(2),xmax=(alpha_tot_gr+sd_alpha_gr)*60/log(2),col=condition))+
  facet_wrap(~strain,scale="free")+
  labs(subtitle="all")+
  theme_cowplot()+
  #coord_cartesian(ylim=c(-16,-8))+
  xlab("log(Doublings per hour)")+
  ylab("log(alpha gfp)")
```

# OD COMPARISON WITH DATA FROM MOTHER MACHINE EXPERIMENTS (glucose and glucose aa only)

```{r}
gr_df_scells <- mycells %>% 
  mutate(alpha_min=alpha*60) %>%  #min
  mutate(doubling_per_hour=alpha*3600/(log(2))) %>% 
  group_by(condition) %>% 
  mutate(mean_alpha=mean(alpha_min,na.rm=TRUE)) %>% 
  mutate(sd_doubling=sd(alpha_min*60/log(2),na.rm=TRUE)) %>% 
  mutate(mean_doubling_time=mean_alpha*60/log(2)) %>% 
  distinct(condition,.keep_all = TRUE ) %>% 
  ungroup() %>% 
  select(condition, mean_doubling_time,sd_doubling,doubling_per_hour,alpha_min,cell) %>% 
  arrange(condition)

gr_df_scells
```

I will assume that, same conditions should give identical results, in the mother machine and in the bulk. And that alpha_gfp and mean_concentration_volume should give the same results.

```{r}
mydata_gr_exp_summary %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  left_join(myconcentrations,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_volume),log(alpha_gfp),col=promoter,shape=replica),size=4)+
  facet_wrap(~condition)+
  theme_cowplot()

mydata_gr_exp_summary %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  left_join(myconcentrations,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(mean_concentration_volume,alpha_gfp,col=promoter,shape=replica),size=4)+
  facet_wrap(~condition)+
  theme_cowplot()

mydata_gr_exp_summary %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  left_join(myconcentrations,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(mean_concentration_volume,alpha_gfp,col=promoter,shape=replica),size=4)+
  #facet_wrap(~condition)+
  theme_cowplot()
```
Correlation is good... but this is not as good as what I would have imagined.
In particular, alpha_gfp seems to be overestimated, compared to the mean_concentration for high expressors.

```{r}
mydata_gr_exp_summary %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  left_join(myconcentrations,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(mean_concentration_volume,alpha_gfp,col=condition,shape=replica),size=4)+
  facet_wrap(~promoter,scale="free")+
  theme_cowplot()
```

This is ok, if we assume that we can relate alpha_gfp to concentration.
Let's take a look at the single fits... for pl-rrnB. Could this be a mistake? With another promoter?

# LOOKING AT SINGLE FITS
Let's take a loot at the controls.
What do they look like?

```{r}
library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
#nb.cols <- 24
#mycolors <- colorRampPalette(brewer.pal(8, "Dark2"))(nb.cols)
mydata_summary_od$replica <- factor(mydata_summary_od$replica,levels = c(1,2,3))
mydata_curated$replica <- factor(mydata_curated$replica,levels = c(1,2,3))

mydata_to_plot <- mydata_curated %>% 
    ungroup() %>%
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>% 
  left_join(mydata_summary_od,by=c("strain","replica","well","condition"))

mydata_to_plot$replica <- factor(mydata_to_plot$replica,levels = c(1,2,3))
mydata_to_plot$condition <- factor(mydata_to_plot$condition,levels = c("acetate","glycerol","glucose","glucoseaa"))

mydata_to_plot %>%
    filter(strain=="pl-rrnB") %>%
    filter(condition %in% c("glucose","glucoseaa")) %>% 
    ggplot() +
    geom_point(aes(corrected_od,fluo,col=condition),alpha=1)+
    geom_line(aes(corrected_od,corrected_od*alpha_tot+beta,group=interaction(replica,well)),col="red",alpha=0.2)+
    geom_text(aes(x = -Inf, y = -Inf, label = "pl-rrnB"),size=5,vjust=-0.2,hjust=-0.2)+
    facet_wrap(~interaction(well,replica))+
    xlab("corrected_od")+
    ylab("fluo")+
    #scale_color_manual(values = mycolors)+
    theme_cowplot()+
    xlab("corrected OD")+
    ylab("GFU (A.U)") 
```

Clearly the slope from experiment 2, are weird. Less number of data points which suggests that the cells where growing much slower. For whatever reason.

So for whatever reason, it seems that we have a lot of fluctuations regarding these growth rates in wells.
Is rrnB growing faster in glucose for whatever reason on that day?

```{r}
mydata_gr_exp_summary %>% 
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  select(condition, strain, replica, alpha_tot_gr) %>% 
  arrange(strain,condition,replica)
```

I can certainly plot for each one of them, the alpha_gfp versus the growth rate. i.e we do not give a fuck about the condition anymore. We only care about the growth rate.

```{r}
mydata_gr_exp_summary %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  #left_join(myconcentrations,by=c("condition","strain")) %>% 
  mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  ggplot()+
  geom_point(aes(alpha_tot_gr,alpha_gfp,col=condition,shape=replica),size=4)+
  facet_wrap(~strain,scale="free")+
  theme_cowplot()
```
How does it look for mother machine data?
These different measurement strongly depend on the growth rate. Which also makes the whole problem more complicated.
Clearly there are some cleaning to do. But other wise, it seems ok. And, for some reason... I need to find a way to calibrate all of that.

I could also certainly improve the measurement of growth rates, and clean the data where cells did not grow correctly. So now... how do I calibrate that?


```{r}
myconcentrations_sc %>%
  left_join(myalphas_sc,by=c("cell","condition")) %>% 
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  #filter(log(alpha_tot_gr*3600/log(2))>-2) %>% 
  #left_join(myconcentrations,by=c("condition","strain")) %>% 
  #mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  ggplot()+
  geom_point(aes(mean_alpha,mean_concentration_volume,col=condition))+
  facet_wrap(~strain,scale="free")+
  theme_cowplot()
```
```{r}
myconcentrations_sc %>%
  left_join(myalphas_sc,by=c("cell","condition")) %>% 
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  #filter(log(alpha_tot_gr*3600/log(2))>-2) %>% 
  #left_join(myconcentrations,by=c("condition","strain")) %>% 
  #mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  ggplot()+
  geom_point(aes(mean_alpha,mean_concentration_volume*mean_alpha,col=condition))+
  facet_wrap(~strain,scale="free")+
  theme_cowplot()
```
```{r}
myconcentrations_sc %>%
  left_join(myalphas_sc,by=c("cell","condition")) %>% 
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("ch-hi1","ch-hi3","ch-rrnB","pl-hi1","pl-hi3","pl-rrnB","ch-med2","ch-med3")) %>% 
  #filter(log(alpha_tot_gr*3600/log(2))>-2) %>% 
  #left_join(myconcentrations,by=c("condition","strain")) %>% 
  #mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  ggplot()+
  geom_point(aes(log(mean_alpha),log(mean_concentration_volume*mean_alpha),col=vector))+
  facet_wrap(~promoter,scale="free")+
  theme_cowplot()
```

I think this is the sign that two things might have been happening: 
- 1) Behaviour is roughly the same. Log fold changes are similar.
- 2) Some discreprancies either due to lamp not that bright on that day? Other?
- 3) Glucose aa for chromosomal is below what is expected. Or... glucose is higher.

But most importantly, these data are legit and production can quite dramatically go down. Why?

```{r}
mydata_gr_exp_summary %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("ch-hi1","ch-hi3","ch-rrnB","pl-hi1","pl-hi3","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  #left_join(myconcentrations,by=c("condition","strain")) %>% 
  #mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  ggplot()+
  geom_point(aes(log(alpha_tot_gr),log(alpha_gfp*alpha_tot_gr),col=condition,shape=replica),size=4)+
  facet_wrap(~promoter,scale="free")+
  theme_cowplot()
```






# INVESTIGATING VARIATIONS IN GROWTH RATES IN SINGLE WELLS

What is driving the variations in growth rate in a single condition.
- Day? (aka replicate, are same day plate more likely to look alike than different days?)
- Well? (are identical wells more likely to look alike than different wells, across replicates?)
- Plate? (are different wells belonging to the same plate more likely to be alike?)


```{r}
# Look at overall distibutions: what is the magnitude of fluctuations? Are outliers non sensical meant to be discarded? In other words, what are fluctuations that are sensical.
mydata_gr_exp_summary %>% 
  mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  ggplot()+
  geom_freqpoly(aes(x=alpha_tot_gr,col=replica),size=3)+
  facet_wrap(~condition,scale="free")+
  theme_cowplot()
```
Overall, experiments seem to be reproducible.
But, for some reason, in each conditions there are outliers.
Fit with a Gaussian each experiment, isolate outliers and look at single fits for these. That would be a good exercise... but complex now.

The best estimate is simply: mean = mean(values)
Standard deviation of the gaussian distribution = sd/sqrt(n)

Let's represent that. And take a threshold.

```{r}
# Look at overall distibutions: what is the magnitude of fluctuations? Are outliers non sensical meant to be discarded? In other words, what are fluctuations that are sensical.
.n <- 151
.delta <- .01
gaussian_fitting_gr <- mydata_gr_exp_summary %>% 
  group_by(condition,replica) %>% 
  mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  mutate(mean_d=mean(alpha_tot_gr,na.rm=TRUE),
         p=n(),
         sd_d=sd(alpha_tot_gr,na.rm=TRUE)) %>% 
  distinct(condition,replica,mean_d,sd_d,p) %>% 
  slice(rep(row_number(), .n)) %>%
  mutate(x=(row_number()-(.n-1)/2)*.delta+mean_d,
         y=exp(-(mean_d-x)**2/(2*sd_d**2))) %>% 
  ungroup()
  
mydata_gr_exp_summary %>% 
  mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  ggplot()+
  geom_freqpoly(aes(y=..ncount..,x=alpha_tot_gr,col=replica,binwidth=100),size=3)+
  geom_line(data=gaussian_fitting_gr,aes(x,y,col=replica),lty=2)+
  facet_wrap(~condition,scale="free")+
  theme_cowplot()
```
The gaussians, as fitted, seem to correctly encompass the variability (here scaled to 1).

```{r}
gaussian_fitting_gr_summary <- mydata_gr_exp_summary %>% 
  group_by(condition,replica) %>% 
  mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  mutate(mean_d=mean(alpha_tot_gr,na.rm=TRUE),
         p=n(),
         sd_d=sd(alpha_tot_gr,na.rm=TRUE)) %>% 
  distinct(condition,replica,mean_d,sd_d,p) %>% 
  arrange(condition)
```

Then I can discard outliers, +/- 2x standard deviation.

```{r}
mydata_gr_exp_summary_no_outliers <- mydata_gr_exp_summary %>% 
  mutate(d=alpha_tot_gr*60/log(2)) %>% 
  group_by(condition,replica) %>% 
  mutate(mean_d=mean(d,na.rm=TRUE),
         p=n(),
         sd_d=sd(d,na.rm=TRUE)) %>% 
  ungroup() %>% 
  filter(d<mean_d+2*sd_d) %>% 
  filter(d>mean_d-2*sd_d)
```

```{r}
# Look at overall distibutions: what is the magnitude of fluctuations? Are outliers non sensical meant to be discarded? In other words, what are fluctuations that are sensical.
.n <- 151
.delta <- .01
gaussian_fitting_gr <- mydata_gr_exp_summary_no_outliers %>% 
  group_by(condition,replica) %>% 
  mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  mutate(mean_d=mean(alpha_tot_gr,na.rm=TRUE),
         p=n(),
         sd_d=sd(alpha_tot_gr,na.rm=TRUE)) %>% 
  distinct(condition,replica,mean_d,sd_d,p) %>% 
  slice(rep(row_number(), .n)) %>%
  mutate(x=(row_number()-(.n-1)/2)*.delta+mean_d,
         y=exp(-(mean_d-x)**2/(2*sd_d**2))) %>% 
  ungroup()
  
mydata_gr_exp_summary_no_outliers %>% 
  mutate(alpha_tot_gr=alpha_tot_gr*60/log(2)) %>% 
  ggplot()+
  geom_freqpoly(aes(y=..ncount..,x=alpha_tot_gr,col=replica,binwidth=100),size=3)+
  geom_line(data=gaussian_fitting_gr,aes(x,y,col=replica),lty=2)+
  facet_wrap(~condition,scale="free")+
  theme_cowplot()
```
```{r}
mydata_gr_exp_summary_no_outliers %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-p3F9","pl-p3F3","pl-p3C6","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  left_join(myconcentrations,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(mean_concentration_volume,alpha_gfp,col=promoter,shape=replica),size=4)+
  #facet_wrap(~condition)+
  theme_cowplot()
```

```{r}
mydata_gr_exp_summary_no_outliers %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-hi1","pl-hi3","pl-rrnB")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  left_join(myconcentrations,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_volume),log(alpha_gfp),col=promoter,shape=replica),size=4)+
  #facet_wrap(~condition)+
  theme_cowplot()
```
```{r}
mydata_gr_exp_summary_no_outliers %>%
  filter(condition %in% c("glucose","glucoseaa")) %>% 
  filter(strain %in% c("pl-p3F9","pl-p3F3","pl-p3C6")) %>% 
  filter(log(alpha_tot_gr*60/log(2))>-2) %>% 
  left_join(myconcentrations,by=c("condition","strain")) %>% 
  ggplot()+
  geom_point(aes(log(mean_concentration_volume),log(alpha_gfp),col=promoter,shape=replica),size=4)+
  #facet_wrap(~condition)+
  theme_cowplot()
```
Which actually means that, most of them are not, outliers. I could even be more strict there.
But that does not change the fact that I have quite a lot of variability there.
In this plot, rrnB seems to be an outlier: it is clearly higher than the rest.
I do not understand why.

```{r}
mydata_gr_exp_summary %>% 
  mutate(d=alpha_tot_gr*60/log(2)) %>% 
  filter(strain=="pl-rrnB") %>% 
  select(condition,well,replica,d) %>% 
  arrange(condition,replica)
```

Is it for instance, that pl-rrnB data are not as "comparable with mother machine data than others"?
i.e: hi3?

```{r}
mydata_gr_exp_summary %>% 
  mutate(d=alpha_tot_gr*60/log(2)) %>% 
  filter(strain=="pl-hi3") %>% 
  select(condition,well,replica,d) %>% 
  arrange(condition,replica)
```

pl_hi3 from replicate 1 are pretty bad in terms of growth rate.
Bad fit?

```{r}
library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
#nb.cols <- 24
#mycolors <- colorRampPalette(brewer.pal(8, "Dark2"))(nb.cols)
mydata_growthrates_summary$replica <- factor(mydata_growthrates_summary$replica,levels = c(1,2,3))
mydata_curated$replica <- factor(mydata_curated$replica,levels = c(1,2,3))

mydata_to_plot <- mydata_curated %>% 
    ungroup() %>%
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>% 
  left_join(mydata_growthrates_summary,by=c("strain","replica","well","condition"))

mydata_to_plot$replica <- factor(mydata_to_plot$replica,levels = c(1,2,3))
mydata_to_plot$condition <- factor(mydata_to_plot$condition,levels = c("acetate","glycerol","glucose","glucoseaa"))

s <- "pl-hi3"
mydata_to_plot %>%
    filter(strain==s) %>%
    ggplot() +
    geom_point(aes(time_min,log(corrected_od),col=condition),alpha=1)+
    geom_line(aes(time_min,time_min*alpha_tot+beta,group=interaction(replica,well)),col="red",alpha=0.2)+
    geom_text(aes(x = -Inf, y = -Inf, label = s),size=5,vjust=-0.2,hjust=-0.2)+
    facet_wrap(~interaction(well,replica))+
    xlab("time (min)")+
    ylab("log(corrected od)")+
    scale_color_manual(values = mycolors)+
    theme_cowplot()
```
No the fit are not even that bad.


```{r}
library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
#nb.cols <- 24
#mycolors <- colorRampPalette(brewer.pal(8, "Dark2"))(nb.cols)
mydata_growthrates_summary$replica <- factor(mydata_growthrates_summary$replica,levels = c(1,2,3))
mydata_curated$replica <- factor(mydata_curated$replica,levels = c(1,2,3))

mydata_to_plot <- mydata_curated %>% 
    ungroup() %>%
    filter(!grepl("empty",strain)) %>% #filter out empty wells
    left_join(od_range_df,by=c("condition")) %>%
    filter(max(corrected_od)>min_corrected_od) %>% #to get rid of wells in which there are no growth at all
    group_by(description,plate,well) %>%
    arrange(time_min) %>% 
    mutate(above_max_time=ifelse(corrected_od>=max_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=min(c(above_max_time,Inf),na.rm=TRUE)) %>% 
    filter(time_min<time_limit) %>% 
    mutate(below_min_time=ifelse(corrected_od<=min_corrected_od,time_min,NA)) %>% 
    mutate(time_limit=max(c(below_min_time,-Inf),na.rm=TRUE)) %>% 
    filter(time_min>time_limit) %>% 
    ungroup() %>% 
    select(-c(above_max_time,time_limit,below_min_time)) %>% 
  left_join(mydata_growthrates_summary,by=c("strain","replica","well","condition"))

mydata_to_plot$replica <- factor(mydata_to_plot$replica,levels = c(1,2,3))
mydata_to_plot$condition <- factor(mydata_to_plot$condition,levels = c("acetate","glycerol","glucose","glucoseaa"))

s <- "pl-rrnB"
mydata_to_plot %>%
    filter(strain==s) %>%
    ggplot() +
    geom_point(aes(time_min,log(corrected_od),col=condition),alpha=1)+
    geom_line(aes(time_min,time_min*alpha_tot+beta,group=interaction(replica,well)),col="red",alpha=0.2)+
    geom_text(aes(x = -Inf, y = -Inf, label = s),size=5,vjust=-0.2,hjust=-0.2)+
    facet_wrap(~interaction(well,replica))+
    xlab("time (min)")+
    ylab("log(corrected od)")+
    #scale_color_manual(values = mycolors)+
    theme_cowplot()
```

So pl-rrnB does not seem to be growing faster, or not as fast as the others.
The fits look alright.
There is quite some variability between wells, and it seems to be TRUE variability.
FACS data might depend on the growth rate to.
We need to go to simpler stuff.
Why would rrnB behave differently than the others...

Anyway, let's try to stick everything into Erik's model.

# IMPLEMENTING ERIK'S MODEL FOR CALIBRATION

All data are currently saved in:
"mydata_gr_exp_summary_no_outliers"
alpha_gfp
mean_concentration_volume

I did not add yet the error bars that are going with it.
But there is:

Slope GFU/OD
alpha_gfp
sd_alpha_gfp

Doublings per hour:
d
sd_d

Concentration in mother machine
mean_concentration_volume

Outliers characterized by crazy growth rates are discarded.

```{r}



```









```{r}

for(s in unique(mydata_to_plot$strain)[1:10]){
print(mydata_to_plot %>%
    filter(strain==s) %>%
    ggplot() +
    geom_point(aes(corrected_od,fluo,col=condition),alpha=1)+
    geom_line(aes(corrected_od,corrected_od*alpha_tot+beta,group=interaction(replica,well)),col="red",alpha=0.2)+
    geom_text(aes(x = -Inf, y = -Inf, label = s),size=5,vjust=-0.2,hjust=-0.2)+
    facet_wrap(~replica)+
    xlab("corrected_od")+
    ylab("fluo")+
    scale_color_manual(values = mycolors)+
    theme_cowplot()+
    xlab("corrected OD")+
    ylab("GFU (A.U)") 
)}

for(c in unique(mydata_to_plot$condition)){
print(mydata_to_plot %>%
    filter(condition==c) %>% 
    filter(strain=="MG1655") %>%
    ggplot() +
    geom_point(aes(corrected_od,fluo,col=condition),alpha=1)+
    geom_line(aes(corrected_od,corrected_od*alpha_tot+beta,group=interaction(replica,well)),col="red",alpha=0.2)+
    #geom_text(aes(x = -Inf, y = -Inf, label = "MG1655"),size=5,vjust=-0.2,hjust=-0.2)+
    facet_wrap(~replica)+
    xlab("corrected_od")+
    ylab("fluo")+
    scale_color_manual(values = mycolors)+
    theme_cowplot()+
    xlab("corrected OD")+
    ylab("GFU (A.U)") )}

for(c in unique(mydata_to_plot$condition)){
print(mydata_to_plot %>%
    filter(condition==c) %>% 
    filter(strain=="MG1655") %>%
    ggplot() +
    geom_point(aes(corrected_od,fluo,col=condition),alpha=1)+
    geom_line(aes(corrected_od,corrected_od*alpha_tot+beta,group=interaction(replica,well)),col="red",alpha=0.2)+
    #geom_text(aes(x = -Inf, y = -Inf, label = "MG1655"),size=5,vjust=-0.2,hjust=-0.2)+
    facet_wrap(~replica)+
    xlab("corrected_od")+
    ylab("fluo")+
    scale_color_manual(values = mycolors)+
    theme_cowplot()+
      xlab("corrected OD")+
    ylab("GFU (A.U)") )}

for(c in unique(mydata_to_plot$condition)){
print(mydata_to_plot %>%
    filter(condition==c) %>% 
    filter(strain=="MG1655") %>%
    ggplot() +
    geom_point(aes(corrected_od,fluo,col=condition),alpha=1)+
    geom_line(aes(corrected_od,corrected_od*alpha_tot+beta,group=interaction(replica,well)),col="red",alpha=0.2)+
    #geom_text(aes(x = -Inf, y = -Inf, label = "MG1655"),size=5,vjust=-0.2,hjust=-0.2)+
    facet_wrap(~interaction(replica,well))+
    xlab("corrected_od")+
    ylab("fluo")+
    scale_color_manual(values = mycolors)+
    theme_cowplot()+
      xlab("corrected OD")+
    ylab("GFU (A.U)") )}

for(c in unique(mydata_to_plot$condition)){
print(mydata_to_plot %>%
    filter(condition==c) %>% 
    filter(strain=="MG1655") %>%
    distinct(replica,well,.keep_all=TRUE) %>% 
    ggplot() +
    geom_boxplot(aes(replica,alpha_tot),alpha=1,width=0.1)+
    geom_jitter(aes(replica,alpha_tot,group=interaction(replica),col=row),width=0.1)+
    #geom_text(aes(x = -Inf, y = -Inf, label = "MG1655"),size=5,vjust=-0.2,hjust=-0.2)+
    #facet_wrap(~interaction(replica,well))+
    xlab("Replica")+
    ylab("alpha_tot")+
    scale_color_manual(values = mycolors)+
    labs(subtitle=c)+
    theme_cowplot()+
      xlab("replica")+
    ylab("GFU (A.U)") )}
```









```{r}
library(RColorBrewer)
# DÃ©finissez le nombre de couleurs que vous voulez
nb.cols <- 18
mycolors <- colorRampPalette(brewer.pal(8, "Set2"))(nb.cols)

#myframes_to_mycells
#mycells
myframes_to_mycells <- myframes_to_mycells %>% 
  mutate(volume_um=((length_um-width_um)*(width_um/2)**2*3.14)+4/3*3.14*(width_um/2)**3) %>%
  mutate(concentration_length=gfp_nb/length_um) %>% 
  mutate(concentration_volume=gfp_nb/volume_um) %>% 
  group_by(cell) %>% 
  mutate(sc_mean_concentration_length=mean(concentration_length,na.rm=TRUE)) %>% 
  mutate(sc_mean_concentration_volume=mean(concentration_volume,na.rm=TRUE)) %>% 
  mutate(sc_sd_concentration_length=sd(concentration_length,na.rm=TRUE)) %>% 
  mutate(sc_sd_concentration_volume=sd(concentration_volume,na.rm=TRUE)) %>% 
  ungroup() %>% 
  group_by(promoter,condition) %>% 
  mutate(mean_concentration_length=mean(concentration_length,na.rm=TRUE)) %>% 
  mutate(mean_concentration_volume=mean(concentration_volume,na.rm=TRUE)) %>% 
  mutate(sd_concentration_length=sd(concentration_length,na.rm=TRUE)) %>% 
  mutate(sd_concentration_volume=sd(concentration_volume,na.rm=TRUE))

gr_df <- mycells %>% 
  mutate(alpha_min=alpha*60) %>%  #min
  group_by(condition,promoter,vector) %>% 
  mutate(mean_alpha=mean(alpha_min,na.rm=TRUE)) %>% 
  mutate(sd_alpha=sd(alpha_min,na.rm=TRUE)) %>% 
  mutate(mean_doubling_time=mean_alpha*3600/log(2)) %>% 
  distinct(condition,promoter,.keep_all = TRUE ) %>% 
  select(condition, promoter, mean_doubling_time,mean_alpha,sd_alpha,vector) %>% 
  ungroup()

gr_df_scells <- mycells %>% 
  mutate(alpha_min=alpha*60) %>%  #min
  mutate(doubling_per_hour=alpha*3600/(log(2))) %>% 
  group_by(condition,promoter,vector) %>% 
  mutate(mean_alpha=mean(alpha_min,na.rm=TRUE)) %>% 
  mutate(sd_alpha=sd(alpha_min,na.rm=TRUE)) %>% 
  mutate(mean_doubling_time=mean_alpha*60/log(2)) %>% 
  #distinct(condition,promoter,.keep_all = TRUE ) %>% 
  ungroup() %>% 
  select(condition, promoter, mean_doubling_time,mean_alpha,sd_alpha,doubling_per_hour,alpha_min,cell,vector)

```


```{r}
myframes_to_mycells %>% 
  filter(vector=="pl") %>% 
  left_join(gr_df_scells,by=c("condition","promoter","cell","vector")) %>% 
  #distinct(promoter,condition,.keep_all=TRUE) %>%
  ggplot()+
  #geom_point(aes(mean_doubling_time,mean_concentration_volume,col=condition))+
  geom_point(aes(doubling_per_hour,sc_mean_concentration_volume,col=condition),alpha=0.01)+
  geom_line(aes(mean_doubling_time,mean_concentration_volume,col=condition))+
  scale_fill_manual(values = mycolors) +
  facet_wrap(~promoter,scale="free")+
  #scale_color_manual(values = mycolors) +
  theme_cowplot()+
  xlab("Doublings per hour")+
  ylab("<Concentration> (volume based)")

myframes_to_mycells %>% 
  filter(vector=="pl") %>% 
  left_join(gr_df_scells,by=c("condition","promoter","cell","vector")) %>% 
  #distinct(promoter,condition,.keep_all=TRUE) %>%
  ggplot()+
  #geom_point(aes(mean_doubling_time,mean_concentration_volume,col=condition))+
  geom_point(aes(log(doubling_per_hour),log(sc_mean_concentration_volume),col=condition),alpha=0.01)+
  geom_line(aes(log(mean_doubling_time),log(mean_concentration_volume),col=condition))+
  scale_fill_manual(values = mycolors) +
  facet_wrap(~promoter,scale="free")+
  #scale_color_manual(values = mycolors) +
  theme_cowplot()+
  xlab("log(Doublings per hour)")+
  ylab("log(<Concentration>) (volume based)")

myframes_to_mycells %>% 
  filter(vector=="pl") %>% 
  left_join(gr_df_scells,by=c("condition","promoter","cell","vector")) %>% 
  #distinct(promoter,condition,.keep_all=TRUE) %>%
  ggplot()+
  #geom_point(aes(mean_doubling_time,mean_concentration_volume,col=condition))+
  geom_point(aes(log(doubling_per_hour),log(sc_mean_concentration_volume),col=condition),alpha=0.01)+
  geom_line(aes(log(mean_doubling_time),log(mean_concentration_volume),col=condition))+
  scale_fill_manual(values = mycolors) +
  facet_wrap(~promoter,scale="free")+
  #scale_color_manual(values = mycolors) +
  theme_cowplot()+
  xlab("log(Doublings per hour)")+
  ylab("log(<Concentration>) (volume based)")

myframes_to_mycells %>% 
  filter(vector=="pl") %>% 
  left_join(gr_df_scells,by=c("condition","promoter","cell")) %>% 
  #distinct(promoter,condition,.keep_all=TRUE) %>%
  ggplot()+
  #geom_point(aes(log(mean_doubling_time),log(mean_concentration_volume*mean_alpha),col=condition))+
  geom_point(aes(log(doubling_per_hour),log(sc_mean_concentration_volume*alpha_min),col=condition),alpha=0.01)+
  geom_line(aes(log(mean_doubling_time),log(mean_concentration_volume*mean_alpha),col=condition))+
  scale_fill_manual(values = mycolors) +
  facet_wrap(~promoter,scale="free")+
  #scale_color_manual(values = mycolors) +
  theme_cowplot()+
  xlab("log(Doublings per hour))")+
  ylab("log(<Production>) (volume based)")
```

# OD COMPARING DATA PER CONDITION (GLUCOSE AND GLUCOSEAA)

```{r}
myframes_to_mycells %>% 
  filter(vector=="pl") %>% 
  left_join(gr_df_scells,by=c("condition","promoter","cell","vector")) %>% 
  group_by(promoter) %>%
  mutate(mean_concentration_volume=mean(concentration_volume)) %>% 
  mutate(mean_doubling_per_hour=mean(doubling_))
  ggplot()+
  #geom_point(aes(log(mean_doubling_time),log(mean_concentration_volume*mean_alpha),col=condition))+
  geom_point(aes(log(doubling_per_hour),log(sc_mean_concentration_volume*alpha_min),col=condition),alpha=0.01)+
  geom_line(aes(log(mean_doubling_time),log(mean_concentration_volume*mean_alpha),col=condition))+
  scale_fill_manual(values = mycolors) +
  facet_wrap(~promoter,scale="free")+
  #scale_color_manual(values = mycolors) +
  theme_cowplot()+
  xlab("log(Doublings per hour))")+
  ylab("log(<Production>) (volume based)")
  
```




