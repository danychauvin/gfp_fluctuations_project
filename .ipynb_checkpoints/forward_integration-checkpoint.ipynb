{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "SMALL_SIZE = 13\n",
    "MEDIUM_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================== #\n",
    "# =============== CELL CLASS =============== #\n",
    "# ========================================== #\n",
    "class Cell:\n",
    "    def __init__(self, log_length0, gfp0, lambda0, q0, time0=0., cell_id = 0, parent_id=-1):\n",
    "        self.parent_id = parent_id\n",
    "        self.cell_id = cell_id\n",
    "        self.length = [np.exp(log_length0)]  # s(t)\n",
    "        self.log_length = [log_length0]      # x(t) = x0 + int lambda dt\n",
    "        self.gfp = [gfp0]\n",
    "        self.lt = [lambda0]\n",
    "        self.qt = [q0]\n",
    "        self.time = [time0]\n",
    "        self.segment = []\n",
    "\n",
    "    def to_df(self, n=1, start=0):\n",
    "        df = pd.DataFrame({   \"cell_id\": ([self.cell_id]*len(self.time))[start::n],\n",
    "                                \"time_min\": self.time[start::n],\n",
    "                                \"parent_id\": ([self.parent_id]*len(self.time))[start::n],\n",
    "                                \"log_length\": self.log_length[start::n], \n",
    "                                \"gfp\": self.gfp[start::n],\n",
    "                                \"lt\": self.lt[start::n],\n",
    "                                \"qt\": self.qt[start::n]})\n",
    "        if len(self.segment)>0:\n",
    "            df['segment']=self.segment[start::n]\n",
    "        return df\n",
    "\n",
    "\n",
    "def ggp_df2cells(dataset, time=\"time\", \n",
    "            log_length=\"mean_x\", gfp=\"mean_g\", \n",
    "            lt=\"mean_l\", qt=\"mean_q\",\n",
    "            cov_xx=\"cov_xx\",\n",
    "            cov_gg=\"cov_gg\",\n",
    "            cov_ll=\"cov_ll\",\n",
    "            cov_qq=\"cov_qq\",\n",
    "            cell_id=\"cell_id\", \n",
    "            parent_id=\"parent_id\", \n",
    "            lane=None):\n",
    "    \"\"\" \n",
    "    dataset (pandas data frame as read from csv file) to list of Cell instances, m\n",
    "    written for ggp output\n",
    "    \"\"\"\n",
    "    cell_list = []\n",
    "    last_cell = \"\"\n",
    "    for _, row in dataset.iterrows(): \n",
    "        if row[cell_id] != last_cell:\n",
    "            c = str(row[cell_id])\n",
    "            p = str(row[parent_id])\n",
    "\n",
    "            lambda0 = row[lt]\n",
    "            q0 = row[qt]\n",
    "\n",
    "            new_cell = Cell(row[log_length], row[gfp], \n",
    "                        lambda0, q0, \n",
    "                        time0=row[time],\n",
    "                        cell_id=c, \n",
    "                        parent_id=p)\n",
    "            cell_list.append(new_cell)\n",
    "            cell_list[-1].cov_xx = []\n",
    "            cell_list[-1].cov_gg = []\n",
    "            cell_list[-1].cov_ll = []\n",
    "            cell_list[-1].cov_qq = []\n",
    "\n",
    "        else:\n",
    "            cell_list[-1].log_length.append(row[log_length])\n",
    "            cell_list[-1].gfp.append(row[gfp])\n",
    "            cell_list[-1].time.append(row[time])\n",
    "\n",
    "            cell_list[-1].lt.append(row[lt])\n",
    "            cell_list[-1].qt.append(row[qt])\n",
    "\n",
    "        cell_list[-1].cov_xx.append(row[cov_xx])\n",
    "        cell_list[-1].cov_gg.append(row[cov_gg])\n",
    "        cell_list[-1].cov_ll.append(row[cov_ll])\n",
    "        cell_list[-1].cov_qq.append(row[cov_qq])\n",
    "\n",
    "        last_cell = row[cell_id]\n",
    "    return cell_list\n",
    "\n",
    "\n",
    "# ========================================== #\n",
    "# =============== READING    =============== #\n",
    "# ========================================== #\n",
    "def header_lines(filename, until=\"cell_id\"):\n",
    "    with open(filename,'r') as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            if line.startswith(until):\n",
    "                return i\n",
    "    return None\n",
    "\n",
    "def is_emptystr(s):\n",
    "    return len(s.strip())==0\n",
    "\n",
    "def read_header(filename, epsilon_err=0.05, read_state=\"final\"):\n",
    "    param_lines = header_lines(filename, until=\"10\")+1\n",
    "    parameters_arr = np.genfromtxt(filename, delimiter=',', dtype=str, max_rows=param_lines)\n",
    "    param_dict = {}\n",
    "    if read_state==\"final\":\n",
    "        idx = 7\n",
    "    elif read_state==\"init\":\n",
    "        idx = 3\n",
    "    for param in parameters_arr[1:]:\n",
    "        if not is_emptystr(param[4]) and not is_emptystr(param[5]) and not is_emptystr(param[6]):\n",
    "            param_dict[param[1]] = [\"bound\", float(param[idx])]\n",
    "        elif not is_emptystr(param[4]):\n",
    "            param_dict[param[1]] = [\"free\", float(param[idx])]\n",
    "        else:\n",
    "            param_dict[param[1]] = [\"fixed\", float(param[idx])]\n",
    "\n",
    "    if (filename[:-4].endswith(\"final\")):\n",
    "        with open(filename,'r') as fin:\n",
    "            for i, line in enumerate(fin):\n",
    "                if line.startswith(\"epsilon\"):\n",
    "                    param_error_colums = line.strip().split(',')[1:]\n",
    "                elif line.strip().split(',')[0] == str(epsilon_err):\n",
    "                    param_error = np.sqrt(np.array(line.strip().split(',')[1:]).astype(float))\n",
    "        for i, k in enumerate(param_error_colums):\n",
    "            param_dict[k].append(param_error[i])\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================== #\n",
    "# =============== HELPERS    =============== #\n",
    "# ========================================== #\n",
    "\n",
    "def get_parent(cell, all_cells):\n",
    "    for i, c in enumerate(all_cells):\n",
    "        if c.cell_id == cell.parent_id:\n",
    "            return i, c\n",
    "    return None, None\n",
    "\n",
    "def get_path_from_leaf(cells, idx0=0, rev=True):\n",
    "    idx = []\n",
    "    last_cell = cells[idx0]\n",
    "    i = idx0\n",
    "    while last_cell != None:\n",
    "        idx.append(i)        \n",
    "        i, last_cell = get_parent(last_cell, cells)\n",
    "    if rev:\n",
    "        return idx[::-1]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def get_leafs(cells):\n",
    "    idx = []\n",
    "    parent_ids = [cells[i].parent_id for i, _ in enumerate(cells)]\n",
    "    for i, _ in enumerate(cells):\n",
    "        if cells[i].cell_id not in parent_ids:\n",
    "            idx.append(i)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def get_longest_path(cells):\n",
    "    idx = get_leafs(cells)\n",
    "    longest_path = []\n",
    "    for i in idx: \n",
    "#         path = get_path_idx(cells, i)\n",
    "        path = get_path_from_leaf(cells, i)\n",
    "        if len(path) > len(longest_path):\n",
    "            longest_path = path\n",
    "    return longest_path\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================== #\n",
    "# =============== INTEGRATION =============== #\n",
    "# ========================================== #\n",
    "def get_cell_by_id(cell_id, cells):\n",
    "    for cell in cells:\n",
    "        if cell.cell_id == cell_id:\n",
    "            return cell\n",
    "\n",
    "def get_roots(cells):\n",
    "    idx = []\n",
    "    cell_ids = [cells[i].cell_id for i, _ in enumerate(cells)]\n",
    "    for i, _ in enumerate(cells):\n",
    "        if cells[i].parent_id not in cell_ids:\n",
    "            idx.append(i)\n",
    "    return idx\n",
    "\n",
    "def get_daughters(cell, all_cells):\n",
    "    \"\"\" \n",
    "    Get the daugter cells\n",
    "  \n",
    "    Parameters:\n",
    "    cell (Cell): current cell\n",
    "    all_cells (list of Cell): all cells\n",
    "    \n",
    "    Returns:\n",
    "    list of daughter cells, 2 long, entries are None if there is no daugher cell(s)\n",
    "    \"\"\"\n",
    "    ds = [None, None]\n",
    "    for c in all_cells:\n",
    "        if c.parent_id == cell.cell_id:\n",
    "            if ds[0]==None:\n",
    "                ds[0] = c\n",
    "            elif ds[1] == None:\n",
    "                ds[1] = c\n",
    "            else:\n",
    "                print(\"More than 2 daughters\")\n",
    "    return ds\n",
    "\n",
    "def get_daughters_idx(cell, all_cells):\n",
    "    \"\"\" Same as get_daughters but returns indices\n",
    "    \"\"\"\n",
    "    ds = [None, None]\n",
    "    for i, c in enumerate(all_cells):\n",
    "        if c.parent_id == cell.cell_id:\n",
    "            if ds[0]==None:\n",
    "                ds[0] = i\n",
    "            elif ds[1] == None:\n",
    "                ds[1] = i\n",
    "            else:\n",
    "                print(\"More than 2 daughters\")\n",
    "    return ds\n",
    "\n",
    "def get_q(cell, t):\n",
    "    t -= 1\n",
    "#     if cell.cov_qq[t]<0:\n",
    "#         print(\"cell.cov_qq[t]\", cell.cov_qq[t])\n",
    "#     q = np.random.normal(cell.qt[t], np.sqrt(cell.cov_qq[t]))\n",
    "#     return q\n",
    "    return cell.qt[t]\n",
    "\n",
    "def get_lambda(cell, t):\n",
    "    t -= 1\n",
    "#     l = np.random.normal(cell.lt[t], np.sqrt(cell.cov_ll[t]))\n",
    "#     return l\n",
    "    try:\n",
    "        return cell.lt[t]\n",
    "    except:\n",
    "        print(cell.cell_id)\n",
    "\n",
    "\n",
    "def cell_division_binomial(cell, cells, var_dx, var_dg, mean_lambda, mean_q, growth_noise=False, q_noise=False):\n",
    "    \"\"\" \n",
    "    Calculates the first x and g for the daughter cells of the cell and overwrites the values in the respective cells\n",
    "    Parameters:\n",
    "    cell (Cell): current cell\n",
    "    cells (list of Cell): all cells\n",
    "    var_dx (float): as in ggp, 'None' to turn noise off\n",
    "    var_dg (float): as in ggp, 'None' to turn noise off\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # growth and production\n",
    "    if growth_noise:\n",
    "        lt = get_lambda(cell, -1)\n",
    "    else:\n",
    "        lt = mean_lambda\n",
    "    if q_noise:\n",
    "        qt = get_q(cell, -1)\n",
    "    else:\n",
    "        qt = mean_q\n",
    "    \n",
    "    cell.lt[-1] = lt\n",
    "    cell.qt[-1] = qt\n",
    "    \n",
    "    dt = cell.time[-1]-cell.time[-2] # not quite accurate\n",
    "    \n",
    "    x = cell.log_length[-1] + lt*dt\n",
    "    g = cell.gfp[-1] + np.exp(cell.log_length[-1])*qt*dt\n",
    "\n",
    "#     x = cell.log_length[-1]\n",
    "#     g = cell.gfp[-1]\n",
    "    \n",
    "    \n",
    "    ## actual cell division\n",
    "    if var_dx==None:\n",
    "        x_d1 = x-np.log(2)\n",
    "    else:\n",
    "        x_d1 = np.random.normal(loc=x-np.log(2), scale=np.sqrt(var_dx)) \n",
    "        if x_d1 > x + np.log(0.9):\n",
    "            x_d1 = x + np.log(0.9)\n",
    "\n",
    "    \n",
    "    if var_dg==None:\n",
    "        g_d1 = g * np.exp(x_d1 - x)\n",
    "    else:\n",
    "#         g_indep = np.max([g/var_dg,1])\n",
    "#         upscale = g/g_indep\n",
    "        g_d1 = np.random.binomial(g/var_dg, np.exp(x_d1 - x))*var_dg\n",
    "\n",
    "    x_d2 = np.log(np.exp(x)-np.exp(x_d1))\n",
    "    g_d2 = g - g_d1\n",
    "    d_cells = get_daughters_idx(cell, cells)\n",
    "    \n",
    "    if d_cells[0] != None:\n",
    "        cells[d_cells[0]].log_length[0] = x_d1\n",
    "        cells[d_cells[0]].gfp[0] = g_d1\n",
    "    if d_cells[1] != None:\n",
    "        cells[d_cells[1]].log_length[0] = x_d2\n",
    "        cells[d_cells[1]].gfp[0] = g_d2\n",
    "    return cell\n",
    "\n",
    "\n",
    "def cell_division_data(cell, cells, cells_prediction, \n",
    "                       growth_noise, q_noise):\n",
    "    \"\"\" \n",
    "    Calculates the first x and g for the daughter cells of the cell and overwrites the values in the respective cells\n",
    "    \n",
    "    Returns:\n",
    "    cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # growth and production\n",
    "#     if growth_noise:\n",
    "#         lt = get_lambda(cell, -1)\n",
    "#     else:\n",
    "#         lt = mean_lambda\n",
    "#     if q_noise:\n",
    "#         qt = get_q(cell, -1)\n",
    "#     else:\n",
    "#         qt = mean_q\n",
    "    \n",
    "#     cell.lt[-1] = lt\n",
    "#     cell.qt[-1] = qt\n",
    "    \n",
    "#     dt = cell.time[-1]-cell.time[-2] # not quite accurate\n",
    "    \n",
    "    m_pred = get_cell_by_id(cell.cell_id, cells_prediction)  # mother cell with prediction values\n",
    "    d_cells = get_daughters_idx(cell, cells) # daughter cell(s) with prediction values, can be 0,1 or 2 entries\n",
    "    \n",
    "    # calculate first daughter cell if present\n",
    "    if d_cells[0] != None:\n",
    "        d1_pred = get_cell_by_id(cells[d_cells[0]].cell_id, cells_prediction) # fetch the daughter cell from the \"prediction\" cells\n",
    "        x_ratio = d1_pred.log_length[0] - m_pred.log_length[-1]                 # ratio of daughter/mother cell lengths\n",
    "        g_ratio = d1_pred.gfp[0] / m_pred.gfp[-1]                               # ratio of daughter/mother cell gfp\n",
    "        \n",
    "        cells[d_cells[0]].log_length[0] = cell.log_length[-1] + x_ratio \n",
    "        cells[d_cells[0]].gfp[0] = cell.gfp[-1] * g_ratio \n",
    "\n",
    "    if d_cells[1] != None:\n",
    "        d2_pred = get_cell_by_id(cells[d_cells[1]].cell_id, cells_prediction)\n",
    "        x_ratio = d2_pred.log_length[0] - m_pred.log_length[-1]                 # ratio of daughter/mother cell lengths\n",
    "        g_ratio = d2_pred.gfp[0] / m_pred.gfp[-1]                               # ratio of daughter/mother cell gfp\n",
    "        \n",
    "        cells[d_cells[1]].log_length[0] = cell.log_length[-1] + x_ratio \n",
    "        cells[d_cells[1]].gfp[0] = cell.gfp[-1] * g_ratio \n",
    "    return cell\n",
    "\n",
    "        \n",
    "\n",
    "## For a given cell do the actual integration\n",
    "def single_cell_integration(cell, mean_lambda, mean_q, growth_noise=False, q_noise=False):\n",
    "    for i, t in enumerate(cell.time):\n",
    "        if growth_noise:\n",
    "            lt = get_lambda(cell, i)\n",
    "        else:\n",
    "            lt = mean_lambda\n",
    "        if q_noise:\n",
    "            qt = get_q(cell, i)\n",
    "        else:\n",
    "            qt = mean_q\n",
    "            \n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            dt = cell.time[i] - cell.time[i-1]  \n",
    "            x = cell.log_length[i-1] + lt*dt\n",
    "            gfp = cell.gfp[i-1] + np.exp(cell.log_length[i-1])*qt*dt\n",
    "            cell.log_length[i] = x\n",
    "            cell.gfp[i] = gfp\n",
    "            cell.lt[i-1] = lt\n",
    "            cell.qt[i-1] = qt\n",
    "    return cell\n",
    "         \n",
    "    \n",
    "## recursicvely go through the cells starting at a root \n",
    "def go_through_cell_tree(cell, cells, cells_prediction, mean_lambda, mean_q, \n",
    "                         growth_noise, q_noise,\n",
    "                         var_dx,\n",
    "                         var_dg):\n",
    "    if cell == None:\n",
    "        return None\n",
    "    d_cells = get_daughters(cell, cells)\n",
    "    \n",
    "    cell = single_cell_integration(cell, mean_lambda, mean_q, \n",
    "                                                      growth_noise=growth_noise, \n",
    "                                                      q_noise=q_noise)\n",
    "    if var_dx==\"data\" and var_dg==\"data\":\n",
    "        #cell = cell_division_data(cell, cells, cells_prediction, mean_lambda, mean_q, growth_noise, q_noise)\n",
    "        cell = cell_division_data(cell, cells, cells_prediction, growth_noise, q_noise)\n",
    "    else:\n",
    "        cell = cell_division_binomial(cell, cells, var_dx, var_dg, mean_lambda, mean_q, growth_noise, q_noise)\n",
    "              \n",
    "\n",
    "    go_through_cell_tree(d_cells[0], cells, cells_prediction, mean_lambda, mean_q, growth_noise, q_noise, var_dx, var_dg)\n",
    "    go_through_cell_tree(d_cells[1], cells, cells_prediction, mean_lambda, mean_q, growth_noise, q_noise, var_dx, var_dg)\n",
    "    \n",
    "    \n",
    "# ## set initial x and g \n",
    "# def get_x0(cells):\n",
    "#     x = []\n",
    "#     for cell in cells:\n",
    "#         x.append(cell.log_length[0])\n",
    "#     return np.mean(x)\n",
    "\n",
    "\n",
    "# def get_gfp0(cells):\n",
    "#     gfp = []\n",
    "#     for cell in cells:\n",
    "#         gfp.append(cell.gfp[0])\n",
    "#     return np.mean(gfp)\n",
    "\n",
    "\n",
    "\n",
    "## Integration \"main\" \n",
    "def forward_integration(cells_prediction, parameters, \n",
    "                        growth_noise=False, q_noise=False, \n",
    "                        var_dx=None, var_dg=None):\n",
    "    \"\"\" \n",
    "    Forward integration using the lambda and q from a data set\n",
    "    \n",
    "    Parameters:\n",
    "    cells_prediction (list Cell): cells read from a prediction file\n",
    "    parameters (dict): parameters read from prediction file for mean_lambda and mean_q\n",
    "    growth_noise (bool): if True, use the inferred lambda, if False lambda is fixed to mean_lambda\n",
    "    q_noise (bool): if True, use the inferred q, if False lambda is fixed to mean_q\n",
    "    var_dx (float or None): None turns off noise in cell size split at division. \n",
    "                            If float value, var_dx is variance of Gaussian \n",
    "    var_dg (float or None): None turns off binomial sampling at division.\n",
    "                            If float value, var_dg is scaling binomial variance \n",
    "    \n",
    "    Returns:\n",
    "    list of cells as input, but with overwritten log_length, gfp, lt, and qt\n",
    "    \"\"\"\n",
    "    mean_lambda = parameters[\"mean_lambda\"][1]\n",
    "    mean_q =  parameters[\"mean_q\"][1]\n",
    "    cells_integrated = copy.deepcopy(cells_prediction)\n",
    "    idx_roots = get_roots(cells_prediction)\n",
    "    \n",
    "\n",
    "    for i in idx_roots: \n",
    "        # these 2 lines are a reminder how i initialise x and g\n",
    "        cells_integrated[i].log_length[0] = cells_integrated[i].log_length[0]\n",
    "        cells_integrated[i].gfp[0] = cells_integrated[i].gfp[0]\n",
    "        go_through_cell_tree(cells_integrated[i], \n",
    "                             cells_integrated,\n",
    "                             cells_prediction, \n",
    "                             mean_lambda, \n",
    "                             mean_q, \n",
    "                             growth_noise=growth_noise, \n",
    "                             q_noise=q_noise,\n",
    "                             var_dx=var_dx,\n",
    "                             var_dg=var_dg)\n",
    "    return cells_integrated\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### PLOTTING ###\n",
    "    \n",
    "def plot_concentration(cells_integrated, cells, path, plot_file=None, cells_raw=None, label_i=None):\n",
    "    fig = plt.figure(figsize=(8.3,4.8))\n",
    "        \n",
    "    ax = plt.axes()\n",
    "    \n",
    "    ax.set_xlabel(\"time (min)\")\n",
    "    ax.set_ylabel(\"concentration\")\n",
    "\n",
    "    for a in [ax]:\n",
    "        a.spines[\"top\"].set_visible(False)\n",
    "        a.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        a.spines['right'].set_color('none')\n",
    "        a.yaxis.tick_left()\n",
    "\n",
    "        a.spines['top'].set_color('none')\n",
    "        a.xaxis.tick_bottom()\n",
    "        \n",
    "    label_p = \"prediction\"\n",
    "    label_i = label_i\n",
    "    label_r = \"raw\"\n",
    "    \n",
    "    for j, i in enumerate(path):\n",
    "        plt.plot(cells_integrated[i].time, np.array(cells_integrated[i].gfp)/np.exp(cells_integrated[i].log_length), \n",
    "                 color=\"tab:blue\", label=label_i)\n",
    "        plt.plot(cells[i].time, np.array(cells[i].gfp)/np.exp(cells[i].log_length), \n",
    "                 color=\"tab:red\", label=label_p)    \n",
    "        if cells_raw!=None:\n",
    "            plt.plot(cells_raw[i].time, np.array(cells_raw[i].gfp)/np.exp(cells_raw[i].log_length), \n",
    "                     '-o', markersize=2, lw=0.5, \n",
    "                     color=\"tab:green\", label=label_r)    \n",
    "        label_p = None\n",
    "        label_i = None\n",
    "        label_r = None\n",
    "    ax.legend(loc='upper left', ncol=1)\n",
    "    if plot_file!=None:\n",
    "        plt.savefig(plot_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "        \n",
    "def plot_concentration_hist(cells_integrated, cells, plot_file=None, label_i=None, log=True):\n",
    "    \n",
    "    conc_real = np.array([])\n",
    "    conc_int = np.array([])\n",
    "    for i, _ in enumerate(cells_integrated):\n",
    "        conc_real = np.append(conc_real, \n",
    "                              np.array(cells[i].gfp)/np.exp(cells[i].log_length))\n",
    "        conc_int = np.append(conc_int, \n",
    "                             np.array(cells_integrated[i].gfp)/np.exp(cells_integrated[i].log_length))\n",
    "        \n",
    "    fig = plt.figure(figsize=(8.3,4.8))\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    ax.set_xlabel(\"concentration\")\n",
    "    ax.set_ylabel(\"frequency\")\n",
    "\n",
    "    for a in [ax]:\n",
    "        a.spines[\"top\"].set_visible(False)\n",
    "        a.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        a.spines['right'].set_color('none')\n",
    "        a.yaxis.tick_left()\n",
    "\n",
    "        a.spines['top'].set_color('none')\n",
    "        a.xaxis.tick_bottom()\n",
    "        \n",
    "\n",
    "    def get_label(label, dat):\n",
    "        return label + r', $\\mu$={:.1E} $\\sigma=${:.1E}'.format(np.mean(dat), np.std(dat))\n",
    "    \n",
    "    hist, bin_edges = np.histogram(conc_real, density=False, bins=100)\n",
    "    hist= np.array(hist)/(np.sum(hist))\n",
    "    ax.bar(bin_edges[:-1], hist, width=np.diff(bin_edges),\n",
    "            edgecolor=None, align=\"edge\", color=\"tab:red\", alpha=0.5, label=get_label(\"data\",conc_real))\n",
    "    \n",
    "    hist, bin_edges = np.histogram(conc_int, density=False, bins=bin_edges)\n",
    "    hist= np.array(hist)/(np.sum(hist))\n",
    "    ax.bar(bin_edges[:-1], hist, width=np.diff(bin_edges),\n",
    "            edgecolor=None, align=\"edge\", color=\"tab:blue\", alpha=0.5, label=get_label(label_i,conc_int))\n",
    "    ax.legend(loc='lower left', ncol=1, bbox_to_anchor=(0,1))\n",
    "    if log:\n",
    "        ax.set_xscale('log')\n",
    "\n",
    "    if plot_file!=None:\n",
    "        plt.savefig(plot_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def plot_x_g(cells_integrated, cells, path, plot_file=None, cells_raw=None, label_i=None):\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(8.3,4.8), sharex=True)\n",
    "    \n",
    "    ax = axs.ravel()\n",
    "    ax[1].set_xlabel(\"time (min)\")\n",
    "    ax[0].set_ylabel(\"log length\")\n",
    "    ax[1].set_ylabel(\"gfp\")\n",
    "\n",
    "    for a in ax:\n",
    "        a.spines[\"top\"].set_visible(False)\n",
    "        a.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        a.spines['right'].set_color('none')\n",
    "        a.yaxis.tick_left()\n",
    "\n",
    "        a.spines['top'].set_color('none')\n",
    "        a.xaxis.tick_bottom()\n",
    "        \n",
    "    label_p = \"prediction\"\n",
    "    label_i = label_i\n",
    "    label_r = \"raw\"\n",
    "    \n",
    "    for j, i in enumerate(path):\n",
    "        ax[0].plot(cells_integrated[i].time, cells_integrated[i].log_length, \n",
    "                 color=\"tab:blue\", label=label_i)\n",
    "        ax[0].plot(cells[i].time, cells[i].log_length, \n",
    "                 color=\"tab:red\", label=label_p)    \n",
    "                   \n",
    "        ax[1].plot(cells_integrated[i].time, cells_integrated[i].gfp, \n",
    "                 color=\"tab:blue\", label=label_i)\n",
    "        ax[1].plot(cells[i].time, cells[i].gfp, \n",
    "                 color=\"tab:red\", label=label_p) \n",
    "                   \n",
    "        if cells_raw!=None:\n",
    "            ax[0].plot(cells_raw[i].time, cells_raw[i].log_length, \n",
    "                     '-o', markersize=2, lw=0.5, \n",
    "                     color=\"tab:green\", label=label_r)    \n",
    "            ax[1].plot(cells_raw[i].time, cells_raw[i].gfp, \n",
    "                     '-o', markersize=2, lw=0.5, \n",
    "                     color=\"tab:green\", label=label_r)  \n",
    "        \n",
    "        label_p = None\n",
    "        label_i = None\n",
    "        label_r = None\n",
    "    ax[0].legend(loc='upper left', ncol=1)\n",
    "    if plot_file!=None:\n",
    "        plt.savefig(plot_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save cells (as csv)\n",
    "def save_cells(cells, outfile):\n",
    "    dataset = pd.DataFrame()\n",
    "    for i in range(len(cells)):\n",
    "        next_celldf = cells[i].to_df(1)\n",
    "        dataset = dataset.append(next_celldf)\n",
    "    dataset.to_csv(outfile)\n",
    "    \n",
    "def mk_missing_dir(directory, depth=0):\n",
    "    if depth>len(directory.split('/'))-1:\n",
    "        depth = len(directory.split('/'))-1\n",
    "    while depth>0:\n",
    "        dir_temp = os.path.join(*directory.split('/')[:-depth])\n",
    "        depth-=1\n",
    "        if not os.path.exists(dir_temp):\n",
    "            os.mkdir(dir_temp) \n",
    "    if not os.path.exists(directory):\n",
    "            os.mkdir(directory)\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scicore/home/nimwegen/rocasu25/Documents/Projects/biozentrum/gfp_fluctuations_project/ggp_notebooks/notebooks_simulations'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_input_files(directory, keyword=None, ext=\".csv\"):\n",
    "    entries = os.listdir(directory)\n",
    "    final_files = []\n",
    "    if keyword == None:\n",
    "        for e in entries:\n",
    "            if e.endswith(ext):\n",
    "                final_files.append(os.path.join(directory,e))\n",
    "    else:\n",
    "        for e in entries:\n",
    "            if e.endswith(ext) and keyword in e:\n",
    "                final_files.append(os.path.join(directory,e))   \n",
    "    return sorted(final_files)   \n",
    "\n",
    "### get data and set output dir\n",
    "#data_files = get_input_files('../../experimental_data/data_dany/data_dany_old_data_output_20221215/', keyword='prediction.csv')\n",
    "#len(data_files)\n",
    "\n",
    "dpath='../../denoising_raw_data/denoising_20230124135727/'\n",
    "#dpath=\"../../initial_concentration_at_ss_data\"\n",
    "data_files = get_input_files(dpath, keyword='prediction.csv')\n",
    "len(data_files)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../denoising_raw_data/denoising_20230124135727/hi1_acetate005_rawdata_f01234578910_b_prediction.csv',\n",
       " '../../denoising_raw_data/denoising_20230124135727/hi1_acetate020_rawdata_f01234578910_b_prediction.csv',\n",
       " '../../denoising_raw_data/denoising_20230124135727/hi1_glucose020_rawdata_f01234578910_b_prediction.csv',\n",
       " '../../denoising_raw_data/denoising_20230124135727/hi1_glucoseaa020_rawdata_f01234578910_b_prediction.csv',\n",
       " '../../denoising_raw_data/denoising_20230124135727/hi1_glycerol040_rawdata_f01234578910_b_prediction.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_files.remove(data_files.pop(3))\n",
    "#data_files = [data_files[3]]\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integrating: hi1_acetate005\n",
      "integrating: hi1_acetate020\n",
      "integrating: hi1_glucose020\n",
      "integrating: hi1_glucoseaa020\n",
      "integrating: hi1_glycerol040\n"
     ]
    }
   ],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "\n",
    "\"\"\"\n",
    "HOW TO SET THE SETTING PARAMAETERS\n",
    "----------------------------------\n",
    "\n",
    "- growth_noise and q_noise can be either True or False, \n",
    "where True will take the inferred lambda/q traces and False takes the mean growth/production rate\n",
    "\n",
    "-var_dx and var_dg can be either a float, None or \"data\":\n",
    "        - float: will enable the binomial sampling noise in gfp and gaussian sampling in log_length with therespective parameters\n",
    "        - None: will turn off the noise source\n",
    "        - \"data\": will 'measure' the ratio in length and gfp of mother and daughter cell in the data and transfer it to the simulation\n",
    "\n",
    "\"\"\"\n",
    "for data_file in sorted(data_files):\n",
    "    sample = '_'.join(data_file.split('/')[-1].split('_')[:2])\n",
    "    print(\"integrating:\", sample)\n",
    "    cells = ggp_df2cells(pd.read_csv(data_file, skiprows=header_lines(data_file)))\n",
    "    cells_raw = ggp_df2cells(pd.read_csv(data_file, skiprows=header_lines(data_file)), log_length=\"log_length\", gfp=\"fp\")\n",
    "    params = read_header(data_file)\n",
    "    params = read_header(data_file.replace(\"prediction\", \"final\"))\n",
    "\n",
    "    out_dir = mk_missing_dir(os.path.join(*data_file.split('/')[:-1], 'integration', sample), depth=1)\n",
    "\n",
    "\n",
    "    #### inferred var_dx, var_dg\n",
    "    var_dx = params[\"var_dx\"][1]\n",
    "    var_dg = params[\"var_dg\"][1]\n",
    "    \n",
    "    \n",
    "\n",
    "    # keys gives a name (for labels, file names) to the integration variant\n",
    "    settings = {\"allnoisesources\": {\"growth_noise\": True, \n",
    "                                      \"q_noise\": True, \n",
    "                                      \"var_dx\": \"data\", \n",
    "                                      \"var_dg\": \"data\"},\n",
    "               \"nogrowthnoise\": {\"growth_noise\": False, \n",
    "                                     \"q_noise\": True, \n",
    "                                      \"var_dx\": \"data\", \n",
    "                                      \"var_dg\": \"data\"},\n",
    "               \"noprodnoise\": {\"growth_noise\": True, \n",
    "                                      \"q_noise\": False, \n",
    "                                      \"var_dx\": \"data\", \n",
    "                                      \"var_dg\": \"data\"},\n",
    "               \"nodivisionnoise\": {\"growth_noise\": True, \n",
    "                                      \"q_noise\": True, \n",
    "                                      \"var_dx\": None, \n",
    "                                      \"var_dg\": None},\n",
    "                \"nonoise\": {\"growth_noise\": False, \n",
    "                                      \"q_noise\": False, \n",
    "                                      \"var_dx\": None, \n",
    "                                      \"var_dg\": None},\n",
    "                \"onlyprodnoise\": {\"growth_noise\": False, \n",
    "                                      \"q_noise\": True, \n",
    "                                      \"var_dx\": None, \n",
    "                                      \"var_dg\": None},\n",
    "                \"onlygrowthnoise\": {\"growth_noise\": True, \n",
    "                                      \"q_noise\": False, \n",
    "                                      \"var_dx\": None, \n",
    "                                      \"var_dg\": None},\n",
    "                \"onlydivisionnoise\": {\"growth_noise\": False, \n",
    "                                      \"q_noise\": False, \n",
    "                                      \"var_dx\": \"data\", \n",
    "                                      \"var_dg\": \"data\"}\n",
    "               }\n",
    "\n",
    "\n",
    "    # r\n",
    "    for s in settings.keys():\n",
    "        out_dir = mk_missing_dir(os.path.join(*data_file.split('/')[:-1], 'integration', sample, s), depth=1)\n",
    "        cells_integrated = forward_integration(cells, params, \n",
    "                                               growth_noise=settings[s][\"growth_noise\"], \n",
    "                                               q_noise=settings[s][\"q_noise\"], \n",
    "                                               var_dx=settings[s][\"var_dx\"], \n",
    "                                               var_dg=settings[s][\"var_dg\"])\n",
    "\n",
    "        outfile_base = os.path.join(out_dir, sample)+'_'+s\n",
    "        outfile_base = '_'.join(outfile_base.split()) # remove whitespaces\n",
    "\n",
    "        save_cells(cells_integrated, outfile_base+'.csv')\n",
    "        # plots\n",
    "        plot_concentration(cells_integrated, cells,  get_longest_path(cells_integrated), cells_raw=None,\n",
    "                           label_i=s,\n",
    "                          plot_file = outfile_base+'.pdf')\n",
    "        plot_concentration_hist(cells_integrated, cells,\n",
    "                           label_i=s,\n",
    "                          plot_file = outfile_base+'_hist.pdf')\n",
    "        plot_x_g(cells_integrated, cells,  get_longest_path(cells_integrated), cells_raw=None,\n",
    "                           label_i=s,\n",
    "                          plot_file = outfile_base+'_x_g.pdf')\n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
